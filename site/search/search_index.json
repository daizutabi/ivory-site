{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Ivory Documentation Ivory is a lightweight framework for machine learning. It integrates model design, hyperparmeter tuning, and tracking. Ivory uses Optuna for hyperparmeter tuning and MLflow Tracking for tracking. The relationship of these libraries is like below: Ivory's Experiment = Optuna's Study = MLflow's Experiment Ivory's Run = Optuna's Trial = MLflow's Run Using Ivory, you can obtain the both tuning and tracking workflow at one place. Another key feature of Ivory is its model design. You can write down all of your model structure and tuning/tracking process in one YAML file. It allows us to understand the whole process at a glance. Get started using the Quickstart","title":"Ivory Documentation"},{"location":"#ivory-documentation","text":"Ivory is a lightweight framework for machine learning. It integrates model design, hyperparmeter tuning, and tracking. Ivory uses Optuna for hyperparmeter tuning and MLflow Tracking for tracking. The relationship of these libraries is like below: Ivory's Experiment = Optuna's Study = MLflow's Experiment Ivory's Run = Optuna's Trial = MLflow's Run Using Ivory, you can obtain the both tuning and tracking workflow at one place. Another key feature of Ivory is its model design. You can write down all of your model structure and tuning/tracking process in one YAML file. It allows us to understand the whole process at a glance. Get started using the Quickstart","title":"Ivory Documentation"},{"location":"quickstart/","text":"Quickstart Installing Ivory You install Ivory by pip command. $ pip install ivory Using the Ivory Client Ivory has the Client class that manages the workflow of any machine learning. Let's create your first Client instance. In this quickstart, we are working with examples under the examples directory. import numpy as np import ivory client = ivory.create_client(\"examples\") client [1] 2020-05-19 18:09:42 ( 1.14s ) python3 ( 1.15s ) Client(num_objects=2) The representation of the client shows that it has two objects. Objects that a client has can be accessed by index notation or dot notation . client[0] # or client['tracker'], or client.tracker [2] 2020-05-19 18:09:43 ( 4.00ms ) python3 ( 1.16s ) Tracker(tracking_uri='file:///C:/Users/daizu/Documents/github/ivory/docs/examples/mlruns', artifact_location=None) The first object is a Tracker instance which connects Ivory to MLFlow Tracking . You can get all of the objects. Because a Client insctance is an iterable, you can apply list to get the objects. list(client) [3] 2020-05-19 18:09:43 ( 7.00ms ) python3 ( 1.16s ) ['tracker', 'tuner'] The second objects is named 'tuner'. client.tuner [4] 2020-05-19 18:09:43 ( 3.00ms ) python3 ( 1.17s ) Tuner(storage='sqlite://', sampler=None, pruner=None, load_if_exists=True) A Tuner instance connects Ivory to Optuna: A hyperparameter optimization framework We can customize these objects with a YAML file named client.yml under the woking directory. In our case, the file just contains the minimum settings. File 1 client.yml client: tracker: tuner: Note A YAML file for client is not required. If there is no file for client, Ivory creates a default client with a tracker and without a tuner. If you don't need a tracker, use ivory.create_client(tracker=False) . Example Creating NumPy data In this quickstart, we try to predict rectangles area from thier width and height using PyTorch . First, prepare the data as NumPy arrays. In example.py under the working directory, a create_data() function is defined. The ivory.create_client() function automatically inserts the working directory, so that we can import the module. import example [5] 2020-05-19 18:09:43 ( 278ms ) python3 ( 1.45s ) Let's check the create_data() function definition and an example output: Code 1 example.create_data def create_data(num_samples=1000): xy = 4 * np.random.rand(num_samples, 2) + 1 xy = xy.astype(np.float32) dx = 0.1 * (np.random.rand(num_samples) - 0.5) dy = 0.1 * (np.random.rand(num_samples) - 0.5) z = ((xy[:, 0] + dx) * (xy[:, 1] + dy)).astype(np.float32) z = z.reshape(-1, 1) return xy, z xy, z = example.create_data(4) xy [7] 2020-05-19 18:09:43 ( 4.00ms ) python3 ( 1.46s ) array([[4.8599873, 4.9035373], [2.2044 , 4.6271234], [1.5120602, 3.9817734], [2.8079617, 2.0833135]], dtype=float32) z [8] 2020-05-19 18:09:43 ( 3.00ms ) python3 ( 1.47s ) array([[24.145058 ], [10.034531 ], [ 6.059511 ], [ 5.9882655]], dtype=float32) Set of Data classes Ivory defines a set of Data classes ( Data , Dataset , Datasets , DataLoaders ). First one is ivory.core.data.Data . Our own Data class inherits it. Code 2 example.Data @dataclass class Data(ivory.core.data.Data): n_splits: int = 5 DATA = create_data(1000) def init(self): self.input, self.target = self.DATA self.index = np.arange(len(self.input)) self.fold = kfold_split(self.input, n_splits=self.n_splits) self.fold = np.where(self.fold == 4, -1, self.fold) Here, kfold_split function creates a fold-array. In Ivory, fold number = -1 means their samples are the test set. from ivory.utils.fold import kfold_split kfold_split(np.arange(10), n_splits=3) [10] 2020-05-19 18:09:43 ( 6.00ms ) python3 ( 1.49s ) array([2, 1, 0, 2, 0, 2, 1, 1, 0, 0], dtype=int8) Now, we can get a Data instance. data = example.Data() data [11] 2020-05-19 18:09:43 ( 5.00ms ) python3 ( 1.49s ) Data(n_splits=5) Second class Dataset is a class for one fold dataset. We can use a default Dataset for this simple example. import ivory.core.data dataset = ivory.core.data.Dataset(data, mode=\"train\", fold=1) dataset [12] 2020-05-19 18:09:43 ( 4.00ms ) python3 ( 1.50s ) Dataset(mode='train', num_samples=600) Using get(index) method, you can get a list of (index, input, target). dataset.get(0) [13] 2020-05-19 18:09:43 ( 3.00ms ) python3 ( 1.50s ) [0, array([3.9967277, 2.3258421], dtype=float32), array([9.455848], dtype=float32)] Next, Datasets is a collection class which has train , val , and test dataset. datasets = ivory.core.data.Datasets(data, ivory.core.data.Dataset, fold=0) for mode in datasets: print(datasets[mode]) [14] 2020-05-19 18:09:43 ( 7.00ms ) python3 ( 1.51s ) Dataset(mode='train', num_samples=600) Dataset(mode='val', num_samples=200) Dataset(mode='test', num_samples=200) Finally, DataLoaders is prepared for PyTorch. import ivory.torch.data dataloaders = ivory.torch.data.DataLoaders( data, ivory.torch.data.Dataset, fold=0, batch_size=16 ) for mode in dataloaders: print(mode, dataloaders[mode]) [15] 2020-05-19 18:09:43 ( 8.00ms ) python3 ( 1.51s ) train <torch.utils.data.dataloader.DataLoader object at 0x000001CD59BACF08> val <torch.utils.data.dataloader.DataLoader object at 0x000001CD59BACFC8> test <torch.utils.data.dataloader.DataLoader object at 0x000001CD59BA1708> Defining data by a YAML file One of the Ivory features is to define everything in a YAML file. File 2 data.yaml library: torch dataloaders: data: class: example.Data n_splits: 5 dataset: batch_size: 10 fold: 0 Each dictionary value needs to have one of class , call , def key to create an object. If they are not found, Ivory uses the default classes according to the dictionary key and library value ( torch in this case). Therfore, dataloaders and dataset are created by the default class ivory.torch.data.DataLoaders and ivory.torch.data.Dataset . Defining a model We use a simple MLP model here. Code 3 example.Model class Model(nn.Module): def __init__(self, hidden_sizes): super().__init__() layers = [] for in_features, out_features in zip([2] + hidden_sizes, hidden_sizes + [1]): layers.append(nn.Linear(in_features, out_features)) self.layers = nn.ModuleList(layers) def forward(self, x): for layer in self.layers[:-1]: x = F.relu(layer(x)) return self.layers[-1](x) Defining and training a run Ivory defines a run by a YAML file. Here is a full example. File 3 torch.yaml library: torch dataloaders: data: class: example.Data n_splits: 5 dataset: batch_size: 10 fold: 0 model: class: example.Model hidden_sizes: [100, 100] optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 1e-3 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: metrics: criterion: def: torch.nn.functional.mse_loss monitor: metric: val_loss early_stopping: patience: 10 trainer: epochs: 10 verbose: 2 Let's creata a run by client.create_run run = client.create_run('torch') run [17] 2020-05-19 18:09:43 ( 295ms ) python3 ( 1.82s ) [I 200519 18:09:43 tracker:48] A new experiment created with name: torch Run(id='5ac430ef2f1d4c3c8794a28194726cf9', name='run#0', num_objects=12) Once you get a run instance, then all you need is to start it. run.start() [18] 2020-05-19 18:11:40 ( 1.43s ) python3 ( 3.27s ) [epoch#0] loss=13.58 val_loss=9.378 lr=0.001 best [epoch#1] loss=6.472 val_loss=6.849 lr=0.001 best [epoch#2] loss=5.042 val_loss=5.088 lr=0.001 best [epoch#3] loss=3.565 val_loss=3.415 lr=0.001 best [epoch#4] loss=2.487 val_loss=2.533 lr=0.001 best [epoch#5] loss=1.589 val_loss=2.133 lr=0.001 best [epoch#6] loss=1.157 val_loss=1.638 lr=0.001 best [epoch#7] loss=0.9969 val_loss=0.9716 lr=0.001 best [epoch#8] loss=0.7363 val_loss=0.913 lr=0.001 best [epoch#9] loss=0.6834 val_loss=1.007 lr=0.001 You can get a history of metrics run.metrics.history [19] 2020-05-19 18:14:02 ( 4.00ms ) python3 ( 3.28s ) {'loss': {0: 13.578895473480225, 1: 6.47150728503863, 2: 5.042469129959742, 3: 3.565085874001185, 4: 2.4874604493379593, 5: 1.5887325555086136, 6: 1.1567507199943066, 7: 0.9969329769412677, 8: 0.7362574823200703, 9: 0.6833893636862437}, 'val_loss': {0: 9.377516520023345, 1: 6.849217140674591, 2: 5.087719428539276, 3: 3.414623647928238, 4: 2.533419558405876, 5: 2.133155971765518, 6: 1.63829305768013, 7: 0.9716287076473236, 8: 0.9129781320691108, 9: 1.006829033792019}, 'lr': {0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001}} Also model output and target. run.results.val.output[:5] [20] 2020-05-19 18:15:29 ( 6.00ms ) python3 ( 3.33s ) array([[ 0.9674609], [ 8.910875 ], [ 7.507467 ], [11.987841 ], [ 7.7928557]], dtype=float32) run.results.val.target[:5] [21] 2020-05-19 18:15:29 ( 4.00ms ) python3 ( 3.33s ) array([[ 1.532435 ], [ 7.5503845], [ 6.0588183], [10.4058895], [ 6.2033644]], dtype=float32)","title":"Quickstart"},{"location":"quickstart/#quickstart","text":"","title":"Quickstart"},{"location":"quickstart/#installing-ivory","text":"You install Ivory by pip command. $ pip install ivory","title":"Installing Ivory"},{"location":"quickstart/#using-the-ivory-client","text":"Ivory has the Client class that manages the workflow of any machine learning. Let's create your first Client instance. In this quickstart, we are working with examples under the examples directory. import numpy as np import ivory client = ivory.create_client(\"examples\") client [1] 2020-05-19 18:09:42 ( 1.14s ) python3 ( 1.15s ) Client(num_objects=2) The representation of the client shows that it has two objects. Objects that a client has can be accessed by index notation or dot notation . client[0] # or client['tracker'], or client.tracker [2] 2020-05-19 18:09:43 ( 4.00ms ) python3 ( 1.16s ) Tracker(tracking_uri='file:///C:/Users/daizu/Documents/github/ivory/docs/examples/mlruns', artifact_location=None) The first object is a Tracker instance which connects Ivory to MLFlow Tracking . You can get all of the objects. Because a Client insctance is an iterable, you can apply list to get the objects. list(client) [3] 2020-05-19 18:09:43 ( 7.00ms ) python3 ( 1.16s ) ['tracker', 'tuner'] The second objects is named 'tuner'. client.tuner [4] 2020-05-19 18:09:43 ( 3.00ms ) python3 ( 1.17s ) Tuner(storage='sqlite://', sampler=None, pruner=None, load_if_exists=True) A Tuner instance connects Ivory to Optuna: A hyperparameter optimization framework We can customize these objects with a YAML file named client.yml under the woking directory. In our case, the file just contains the minimum settings. File 1 client.yml client: tracker: tuner: Note A YAML file for client is not required. If there is no file for client, Ivory creates a default client with a tracker and without a tuner. If you don't need a tracker, use ivory.create_client(tracker=False) .","title":"Using the Ivory Client"},{"location":"quickstart/#example","text":"","title":"Example"},{"location":"quickstart/#creating-numpy-data","text":"In this quickstart, we try to predict rectangles area from thier width and height using PyTorch . First, prepare the data as NumPy arrays. In example.py under the working directory, a create_data() function is defined. The ivory.create_client() function automatically inserts the working directory, so that we can import the module. import example [5] 2020-05-19 18:09:43 ( 278ms ) python3 ( 1.45s ) Let's check the create_data() function definition and an example output: Code 1 example.create_data def create_data(num_samples=1000): xy = 4 * np.random.rand(num_samples, 2) + 1 xy = xy.astype(np.float32) dx = 0.1 * (np.random.rand(num_samples) - 0.5) dy = 0.1 * (np.random.rand(num_samples) - 0.5) z = ((xy[:, 0] + dx) * (xy[:, 1] + dy)).astype(np.float32) z = z.reshape(-1, 1) return xy, z xy, z = example.create_data(4) xy [7] 2020-05-19 18:09:43 ( 4.00ms ) python3 ( 1.46s ) array([[4.8599873, 4.9035373], [2.2044 , 4.6271234], [1.5120602, 3.9817734], [2.8079617, 2.0833135]], dtype=float32) z [8] 2020-05-19 18:09:43 ( 3.00ms ) python3 ( 1.47s ) array([[24.145058 ], [10.034531 ], [ 6.059511 ], [ 5.9882655]], dtype=float32)","title":"Creating NumPy data"},{"location":"quickstart/#set-of-data-classes","text":"Ivory defines a set of Data classes ( Data , Dataset , Datasets , DataLoaders ). First one is ivory.core.data.Data . Our own Data class inherits it. Code 2 example.Data @dataclass class Data(ivory.core.data.Data): n_splits: int = 5 DATA = create_data(1000) def init(self): self.input, self.target = self.DATA self.index = np.arange(len(self.input)) self.fold = kfold_split(self.input, n_splits=self.n_splits) self.fold = np.where(self.fold == 4, -1, self.fold) Here, kfold_split function creates a fold-array. In Ivory, fold number = -1 means their samples are the test set. from ivory.utils.fold import kfold_split kfold_split(np.arange(10), n_splits=3) [10] 2020-05-19 18:09:43 ( 6.00ms ) python3 ( 1.49s ) array([2, 1, 0, 2, 0, 2, 1, 1, 0, 0], dtype=int8) Now, we can get a Data instance. data = example.Data() data [11] 2020-05-19 18:09:43 ( 5.00ms ) python3 ( 1.49s ) Data(n_splits=5) Second class Dataset is a class for one fold dataset. We can use a default Dataset for this simple example. import ivory.core.data dataset = ivory.core.data.Dataset(data, mode=\"train\", fold=1) dataset [12] 2020-05-19 18:09:43 ( 4.00ms ) python3 ( 1.50s ) Dataset(mode='train', num_samples=600) Using get(index) method, you can get a list of (index, input, target). dataset.get(0) [13] 2020-05-19 18:09:43 ( 3.00ms ) python3 ( 1.50s ) [0, array([3.9967277, 2.3258421], dtype=float32), array([9.455848], dtype=float32)] Next, Datasets is a collection class which has train , val , and test dataset. datasets = ivory.core.data.Datasets(data, ivory.core.data.Dataset, fold=0) for mode in datasets: print(datasets[mode]) [14] 2020-05-19 18:09:43 ( 7.00ms ) python3 ( 1.51s ) Dataset(mode='train', num_samples=600) Dataset(mode='val', num_samples=200) Dataset(mode='test', num_samples=200) Finally, DataLoaders is prepared for PyTorch. import ivory.torch.data dataloaders = ivory.torch.data.DataLoaders( data, ivory.torch.data.Dataset, fold=0, batch_size=16 ) for mode in dataloaders: print(mode, dataloaders[mode]) [15] 2020-05-19 18:09:43 ( 8.00ms ) python3 ( 1.51s ) train <torch.utils.data.dataloader.DataLoader object at 0x000001CD59BACF08> val <torch.utils.data.dataloader.DataLoader object at 0x000001CD59BACFC8> test <torch.utils.data.dataloader.DataLoader object at 0x000001CD59BA1708>","title":"Set of Data classes"},{"location":"quickstart/#defining-data-by-a-yaml-file","text":"One of the Ivory features is to define everything in a YAML file. File 2 data.yaml library: torch dataloaders: data: class: example.Data n_splits: 5 dataset: batch_size: 10 fold: 0 Each dictionary value needs to have one of class , call , def key to create an object. If they are not found, Ivory uses the default classes according to the dictionary key and library value ( torch in this case). Therfore, dataloaders and dataset are created by the default class ivory.torch.data.DataLoaders and ivory.torch.data.Dataset .","title":"Defining data by a YAML file"},{"location":"quickstart/#defining-a-model","text":"We use a simple MLP model here. Code 3 example.Model class Model(nn.Module): def __init__(self, hidden_sizes): super().__init__() layers = [] for in_features, out_features in zip([2] + hidden_sizes, hidden_sizes + [1]): layers.append(nn.Linear(in_features, out_features)) self.layers = nn.ModuleList(layers) def forward(self, x): for layer in self.layers[:-1]: x = F.relu(layer(x)) return self.layers[-1](x)","title":"Defining a model"},{"location":"quickstart/#defining-and-training-a-run","text":"Ivory defines a run by a YAML file. Here is a full example. File 3 torch.yaml library: torch dataloaders: data: class: example.Data n_splits: 5 dataset: batch_size: 10 fold: 0 model: class: example.Model hidden_sizes: [100, 100] optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 1e-3 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: metrics: criterion: def: torch.nn.functional.mse_loss monitor: metric: val_loss early_stopping: patience: 10 trainer: epochs: 10 verbose: 2 Let's creata a run by client.create_run run = client.create_run('torch') run [17] 2020-05-19 18:09:43 ( 295ms ) python3 ( 1.82s ) [I 200519 18:09:43 tracker:48] A new experiment created with name: torch Run(id='5ac430ef2f1d4c3c8794a28194726cf9', name='run#0', num_objects=12) Once you get a run instance, then all you need is to start it. run.start() [18] 2020-05-19 18:11:40 ( 1.43s ) python3 ( 3.27s ) [epoch#0] loss=13.58 val_loss=9.378 lr=0.001 best [epoch#1] loss=6.472 val_loss=6.849 lr=0.001 best [epoch#2] loss=5.042 val_loss=5.088 lr=0.001 best [epoch#3] loss=3.565 val_loss=3.415 lr=0.001 best [epoch#4] loss=2.487 val_loss=2.533 lr=0.001 best [epoch#5] loss=1.589 val_loss=2.133 lr=0.001 best [epoch#6] loss=1.157 val_loss=1.638 lr=0.001 best [epoch#7] loss=0.9969 val_loss=0.9716 lr=0.001 best [epoch#8] loss=0.7363 val_loss=0.913 lr=0.001 best [epoch#9] loss=0.6834 val_loss=1.007 lr=0.001 You can get a history of metrics run.metrics.history [19] 2020-05-19 18:14:02 ( 4.00ms ) python3 ( 3.28s ) {'loss': {0: 13.578895473480225, 1: 6.47150728503863, 2: 5.042469129959742, 3: 3.565085874001185, 4: 2.4874604493379593, 5: 1.5887325555086136, 6: 1.1567507199943066, 7: 0.9969329769412677, 8: 0.7362574823200703, 9: 0.6833893636862437}, 'val_loss': {0: 9.377516520023345, 1: 6.849217140674591, 2: 5.087719428539276, 3: 3.414623647928238, 4: 2.533419558405876, 5: 2.133155971765518, 6: 1.63829305768013, 7: 0.9716287076473236, 8: 0.9129781320691108, 9: 1.006829033792019}, 'lr': {0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001}} Also model output and target. run.results.val.output[:5] [20] 2020-05-19 18:15:29 ( 6.00ms ) python3 ( 3.33s ) array([[ 0.9674609], [ 8.910875 ], [ 7.507467 ], [11.987841 ], [ 7.7928557]], dtype=float32) run.results.val.target[:5] [21] 2020-05-19 18:15:29 ( 4.00ms ) python3 ( 3.33s ) array([[ 1.532435 ], [ 7.5503845], [ 6.0588183], [10.4058895], [ 6.2033644]], dtype=float32)","title":"Defining and training a run"},{"location":"examples/example/","text":"Skipped.","title":"Example"},{"location":"tutorial/client_experiment_run/","text":"Skipped.","title":"Client experiment run"},{"location":"tutorial/overview/","text":"Skipped.","title":"Overview"},{"location":"tutorial_old/data/","text":"Skipped.","title":"Data"},{"location":"tutorial_old/metrics/","text":"Skipped.","title":"Metrics"},{"location":"tutorial_old/model/","text":"Skipped.","title":"Model"}]}