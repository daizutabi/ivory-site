{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Ivory Documentation Ivory is a lightweight framework for machine learning. It integrates model design, tracking, and hyperparmeter tuning. Ivory uses MLflow Tracking for tracking and Optuna for hyperparmeter tuning. Using Ivory, you can tackle both tracking and tuning workflow at one place. Another key feature of Ivory is its workflow design. You can write down all of your workflow such as model structure or tracking/tuning process in one YAML file. It allows us to understand the whole process at a glance. Ivory is library-agnostic. You can use it with any machine learning library. Get started using the Quickstart. Quickstart","title":"<span class=\"pheasant-header\"><span class=\"header\"><span class=\"title\">Ivory Documentation</span></span></span>"},{"location":"#ivory-documentation","text":"Ivory is a lightweight framework for machine learning. It integrates model design, tracking, and hyperparmeter tuning. Ivory uses MLflow Tracking for tracking and Optuna for hyperparmeter tuning. Using Ivory, you can tackle both tracking and tuning workflow at one place. Another key feature of Ivory is its workflow design. You can write down all of your workflow such as model structure or tracking/tuning process in one YAML file. It allows us to understand the whole process at a glance. Ivory is library-agnostic. You can use it with any machine learning library. Get started using the Quickstart. Quickstart","title":"Ivory Documentation"},{"location":"quickstart/","text":"Quickstart Installation Install Ivory using pip . $ pip install ivory Using an Ivory Client Ivory has the Client class that manages the workflow of machine learning. Let's create your first Client instance. In this quickstart, we are working with examples under the examples directory. import ivory client = ivory.create_client(\"examples\") client [3] 2020-05-30 16:20:38 ( 1.02s ) python3 ( 1.06s ) Client(num_objects=2) The representation of the client shows that it has two objects. These objects can be accessed by index notation or dot notation . client[0] # or client['tracker'], or client.tracker [4] 2020-05-30 16:20:39 ( 5.00ms ) python3 ( 1.06s ) Tracker(tracking_uri='file:///C:/Users/daizu/Documents/github/ivory/examples/mlruns', artifact_location=None) The first object is a Tracker instance which connects Ivory to MLFlow Tracking . Because a Client instance is an iterable, you can get all of the objects by applying list() to it. list(client) [5] 2020-05-30 16:20:39 ( 4.00ms ) python3 ( 1.07s ) ['tracker', 'tuner'] The second objects is named tuner . client.tuner [6] 2020-05-30 16:20:39 ( 3.00ms ) python3 ( 1.07s ) Tuner(storage='sqlite://', sampler=None, pruner=None, load_if_exists=True) A Tuner instance connects Ivory to Optuna: A hyperparameter optimization framework . We can customize these objects with a YAML file named client.yml under the woking directory. In our case, the file just contains the minimum settings. File 1 client.yml client: tracker: tuner: Note A YAML file for client is not required. If there is no file for client, Ivory creates a default client with a tracker and without a tuner. If you don't need a tracker, for example in debugging, use ivory.create_client(tracker=False) . Create NumPy data In this quickstart, we try to predict rectangles area from thier width and height using PyTorch . First, prepare the data as NumPy arrays. In rectangle/data.py under the working directory, a create_data() function is defined. The ivory.create_client() function automatically inserts the working directory to sys.path , so that we can import the module regardless of the current directory. Let's check the create_data() function defined in rectangle/data.py and an example output: File 2 rectangle/data.py from dataclasses import dataclass import numpy as np import ivory.core.data from ivory.utils.fold import kfold_split def create_data(num_samples=1000): xy = 4 * np.random.rand(num_samples, 2) + 1 xy = xy.astype(np.float32) dx = 0.1 * (np.random.rand(num_samples) - 0.5) dy = 0.1 * (np.random.rand(num_samples) - 0.5) z = ((xy[:, 0] + dx) * (xy[:, 1] + dy)).astype(np.float32) return xy, z @dataclass(repr=False) class Data(ivory.core.data.Data): n_splits: int = 4 DATA = create_data(1000) # Shared by each run. def init(self): # Called from self.__post_init__() self.input, self.target = self.DATA self.index = np.arange(len(self.input)) # Extra fold for test data. self.fold = kfold_split(self.input, n_splits=self.n_splits + 1) # Creating dummy test data just for demonstration. is_test = self.fold == self.n_splits # Use an extra fold. self.fold[is_test] = -1 # -1 for test data. self.target = self.target.copy() # n_splits may be different among runs. self.target[is_test] = np.nan # Delete target for test data. self.target = self.target.reshape(-1, 1) # (sample, class) def transform(mode, input, target): return input, target.reshape(-1) import rectangle.data xy, z = rectangle.data.create_data(4) xy [8] 2020-05-30 16:20:39 ( 5.00ms ) python3 ( 1.08s ) array([[3.9385965, 4.358432 ], [4.2360554, 3.944485 ], [1.4794189, 3.9337072], [2.0614476, 2.6825428]], dtype=float32) z [9] 2020-05-30 16:20:39 ( 4.00ms ) python3 ( 1.09s ) array([17.543365 , 17.063057 , 5.7714915, 5.600619 ], dtype=float32) Set of Data classes Ivory defines a set of Data classes ( Data , Dataset , Datasets ). But now, we use the Data class only. In the above file, the kfold_split() function creates a fold array. import numpy as np from ivory.utils.fold import kfold_split kfold_split(np.arange(10), n_splits=3) [10] 2020-05-30 16:20:39 ( 5.00ms ) python3 ( 1.09s ) array([2, 1, 0, 2, 0, 2, 1, 1, 0, 0], dtype=int8) Now, we can get a Data instance. data = rectangle.data.Data() data [11] 2020-05-30 16:20:39 ( 4.00ms ) python3 ( 1.10s ) Data(train_size=800, test_size=200) data.get(0) # get data of index = 0. [12] 2020-05-30 16:20:39 ( 5.00ms ) python3 ( 1.10s ) (0, array([4.8919764, 1.1556569], dtype=float32), array([5.668457], dtype=float32)) This returned value is a tuple of (index, input, target). Ivory always keeps data index so that we can know where a sample comes from. Define a model We use a simple MLP model here. File 3 rectangle/torch.py import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self, hidden_sizes): super().__init__() layers = [] for in_features, out_features in zip([2] + hidden_sizes, hidden_sizes + [1]): layers.append(nn.Linear(in_features, out_features)) self.layers = nn.ModuleList(layers) def forward(self, x): for layer in self.layers[:-1]: x = F.relu(layer(x)) return self.layers[-1](x) Parameter file for Run Ivory configures a run using a YAML file. Here is a full example. File 4 torch.yaml library: torch datasets: data: class: rectangle.data.Data n_splits: 4 dataset: fold: 0 model: class: rectangle.torch.Model hidden_sizes: [20, 30] optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 1e-3 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: metrics: monitor: metric: val_loss early_stopping: patience: 10 trainer: loss: torch.nn.functional.mse_loss batch_size: 10 epochs: 10 verbose: 2 Let's create a run by Client.create_run() run = client.create_run('torch') run [14] 2020-05-30 16:20:40 ( 290ms ) python3 ( 1.68s ) [I 200530 16:20:40 tracker:48] A new experiment created with name: 'torch' Run(id='ed7daae64ed148b984bf2d00c21fa446', name='run#0', num_objects=12) Note Client.create_run(<name>) creates an experiment named <name> if it hasn't existed yet. By cliking an icon ( ) in the above cell, you can see the log. Or you can directly create an experiment then make the experiment create a run: experiment = client . create_experiment ( 'torch' ) run = experiment . create_run () A Run instance have a params attribute that holds the parameters for the run. import yaml print(yaml.dump(run.params, sort_keys=False)) [15] 2020-05-30 16:20:40 ( 9.71ms ) python3 ( 1.69s ) run: datasets: data: class: rectangle.data.Data n_splits: 4 dataset: def: ivory.torch.data.Dataset fold: 0 class: ivory.core.data.Datasets model: class: rectangle.torch.Model hidden_sizes: - 20 - 30 optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 0.001 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: class: ivory.torch.results.Results metrics: class: ivory.torch.metrics.Metrics monitor: metric: val_loss class: ivory.callbacks.monitor.Monitor early_stopping: patience: 10 class: ivory.callbacks.early_stopping.EarlyStopping trainer: loss: torch.nn.functional.mse_loss batch_size: 10 epochs: 10 verbose: 2 class: ivory.torch.trainer.Trainer class: ivory.torch.run.Run name: run#0 id: ed7daae64ed148b984bf2d00c21fa446 experiment: name: torch class: ivory.core.base.Experiment id: '1' This is similar to the YAML file we read before, but is slightly changed by the Ivory Client. Run and experiment sections are inserted. ExperimentID and RunID are assigned by MLFlow Tracking. Default classes are specified, for example ivory.torch.trainer.Trainer for a trainer instance. The Client.create_run() method can take keyword arguments to modify these parameters: run = client.create_run( 'torch', fold=3, hidden_sizes=[40, 50, 60], ) print('[datasets]') print(yaml.dump(run.params['run']['datasets'], sort_keys=False)) print('[model]') print(yaml.dump(run.params['run']['model'], sort_keys=False)) [16] 2020-05-30 16:20:40 ( 46.0ms ) python3 ( 1.74s ) [datasets] data: class: rectangle.data.Data n_splits: 4 dataset: def: ivory.torch.data.Dataset fold: 3 class: ivory.core.data.Datasets [model] class: rectangle.torch.Model hidden_sizes: - 40 - 50 - 60 Train a model Once you got a run instance, then all you need is to start it. run = client.create_run('torch') # Back to the default settings. run.start() [17] 2020-05-30 16:20:40 ( 1.32s ) python3 ( 3.06s ) [epoch#0] loss=18.56 val_loss=6.65 lr=0.001 best [epoch#1] loss=6.703 val_loss=5.85 lr=0.001 best [epoch#2] loss=6.011 val_loss=5.861 lr=0.001 [epoch#3] loss=5.226 val_loss=5.16 lr=0.001 best [epoch#4] loss=4.51 val_loss=3.728 lr=0.001 best [epoch#5] loss=3.735 val_loss=3.058 lr=0.001 best [epoch#6] loss=3.021 val_loss=2.386 lr=0.001 best [epoch#7] loss=2.477 val_loss=1.891 lr=0.001 best [epoch#8] loss=1.871 val_loss=1.349 lr=0.001 best [epoch#9] loss=1.362 val_loss=1.013 lr=0.001 best The history of metrics is saved as the history attribute of a run.metrics instance. run.metrics.history [18] 2020-05-30 16:20:41 ( 5.00ms ) python3 ( 3.06s ) Dict(['loss', 'val_loss', 'lr']) run.metrics.history.val_loss [19] 2020-05-30 16:20:41 ( 4.00ms ) python3 ( 3.07s ) {0: 6.649628221988678, 1: 5.849701488018036, 2: 5.8606742262840275, 3: 5.160243093967438, 4: 3.728123116493225, 5: 3.058417332172394, 6: 2.386374127864838, 7: 1.8913944214582443, 8: 1.3491209745407104, 9: 1.0127072617411614} Also the model output and target are automatically collected in a run.results instance. run.results [20] 2020-05-30 16:20:41 ( 4.00ms ) python3 ( 3.07s ) Results(['train', 'val']) run.results.val.output[:5] [21] 2020-05-30 16:20:41 ( 4.00ms ) python3 ( 3.08s ) array([[7.0327463], [7.550438 ], [8.292342 ], [5.107143 ], [3.296762 ]], dtype=float32) run.results.val.target[:5] [22] 2020-05-30 16:20:41 ( 5.00ms ) python3 ( 3.08s ) array([[6.287244 ], [7.2876472], [7.7266474], [4.315375 ], [3.6494932]], dtype=float32) Test a model Testing a model is as simple as training. Just call run.start('test') instead of a (default) 'train' argument. run.start('test') run.results [23] 2020-05-30 16:20:41 ( 39.0ms ) python3 ( 3.12s ) Results(['train', 'val', 'test']) As you can see, test results were added. run.results.test.output[:5] [24] 2020-05-30 16:20:41 ( 4.00ms ) python3 ( 3.12s ) array([[ 5.390642 ], [14.77002 ], [ 6.9549603], [ 6.9801884], [ 5.6758666]], dtype=float32) Off course the target values for the test data are np.nan . run.results.test.target[:5] [25] 2020-05-30 16:20:41 ( 5.00ms ) python3 ( 3.13s ) array([[nan], [nan], [nan], [nan], [nan]], dtype=float32) Task for multiple runs Ivory implements a special run type called Task which controls multiple nested runs. A task is useful for parameter search or cross validation. task = client.create_task('torch') task [26] 2020-05-30 16:20:41 ( 44.0ms ) python3 ( 3.17s ) Task(id='c721c909bb234c64977e3180e4f5bedd', name='task#0', num_objects=3) The Task class has two methods to generate multiple runs: Task.prodcut() and Task.chain() . These two methods have the same functionality as itertools of Python starndard library. Let's try to perform cross validation. runs = task.product(fold=range(4), verbose=0, epochs=3) runs [27] 2020-05-30 16:20:42 ( 4.00ms ) python3 ( 3.18s ) <generator object Task.product at 0x000002683115EDC8> Like itertools 's functions, Task.prodcut() and Task.chain() return a generator, which yields runs that are configured by different parameters you specify. In this case, this generator will yield 4 runs with a fold number ranging from 0 to 3 for each. A task instance doesn't start any training by itself. In addtion, you can pass fixed parameters to update the original parameters in the YAML file. Then start 4 runs by a for loop including run.start('both') . Here 'both' means execution of test after training. for run in runs: run.start('both') [28] 2020-05-30 16:20:42 ( 2.12s ) python3 ( 5.30s ) [run#3] epochs=3 fold=0 [run#4] epochs=3 fold=1 [run#5] epochs=3 fold=2 [run#6] epochs=3 fold=3 Collect runs Our client has a Tracker instance. It stores the state of runs in background using MLFlow Tracking. The Client class provides several methods to access the stored runs. For example, Client.search_run_ids() returns a generator which yields RunID created by MLFlow Tracking. # A helper function. def print_run_info(run_ids): for run_id in run_ids: print(run_id[:5], client.get_run_name(run_id)) [29] 2020-05-30 16:20:44 ( 4.00ms ) python3 ( 5.30s ) run_ids = client.search_run_ids('torch') # Yields all runs of `torch`. print_run_info(run_ids) [30] 2020-05-30 16:20:44 ( 84.7ms ) python3 ( 5.39s ) 820fc run#6 b9d0d run#5 059fe run#4 28911 run#3 c721c task#0 c4793 run#2 d68fe run#1 ed7da run#0 For filtering, add key-value pairs. # If `exclude_parent` is True, parent runs are excluded. run_ids = client.search_run_ids('torch', fold=0, exclude_parent=True) print_run_info(run_ids) [31] 2020-05-30 16:20:44 ( 160ms ) python3 ( 5.55s ) 28911 run#3 c4793 run#2 ed7da run#0 # If `parent_run_id` is specified, nested runs having the parent are returned. run_ids = client.search_run_ids('torch', parent_run_id=task.id) print_run_info(run_ids) [32] 2020-05-30 16:20:44 ( 46.0ms ) python3 ( 5.60s ) 820fc run#6 b9d0d run#5 059fe run#4 28911 run#3 Client.get_run_id() and Client.get_run_ids() fetch RunID from run name, more strictly, (run class name in lower case) plus (run number). run_ids = [client.get_run_id('torch', run=0), client.get_run_id('torch', task=0)] print_run_info(run_ids) [33] 2020-05-30 16:20:44 ( 52.0ms ) python3 ( 5.65s ) ed7da run#0 c721c task#0 run_ids = client.get_run_ids('torch', run=range(2, 4)) print_run_info(run_ids) [34] 2020-05-30 16:20:44 ( 56.0ms ) python3 ( 5.70s ) c4793 run#2 28911 run#3 Load runs and results The Client instance can load runs. First select RunID(s) to load. We want to perform cross validation here, so that we need a run collection created by the task#0 . In this case, we can use Client.get_nested_run_ids() . Why don't we use Client.search_run_ids() as we did above? Because we don't have an easy way to get a very long RunID after we restart a Python session and lose the Task instance. On the ohter hand, a run name is easy to manage and write. # Assume that we restart a session so we have no run instances now. run_ids = list(client.get_nested_run_ids('torch', task=0)) print_run_info(run_ids) [35] 2020-05-30 16:20:44 ( 76.7ms ) python3 ( 5.78s ) 820fc run#6 b9d0d run#5 059fe run#4 28911 run#3 Let's load the latest run. run = client.load_run(run_ids[0]) run [36] 2020-05-30 16:20:44 ( 41.0ms ) python3 ( 5.82s ) Run(id='820fc44165654562a65c684daf0606c0', name='run#6', num_objects=11) Note that the Client.load_run() function doesn't require an experiment name because RunID is UUID . As you expected, the fold number is 3. run.datasets.fold [37] 2020-05-30 16:20:44 ( 3.00ms ) python3 ( 5.82s ) 3 By loading a run, we obtain the pretrained model. run.model.eval() [38] 2020-05-30 16:20:44 ( 3.00ms ) python3 ( 5.83s ) Model( (layers): ModuleList( (0): Linear(in_features=2, out_features=20, bias=True) (1): Linear(in_features=20, out_features=30, bias=True) (2): Linear(in_features=30, out_features=1, bias=True) ) ) import torch index, input, target = run.datasets.val[:5] with torch.no_grad(): output = run.model(torch.tensor(input)) print('[output]') print(output.numpy()) print('[target]') print(target) [39] 2020-05-30 16:20:44 ( 9.00ms ) python3 ( 5.84s ) [output] [[ 4.1013646] [ 8.760274 ] [ 8.455029 ] [11.647578 ] [10.107115 ]] [target] [[ 1.8680166] [ 6.1457186] [ 6.816285 ] [12.231698 ] [ 8.306013 ]] If you don't need a whole run instance, the Client.load_instance() function is a better choice to save time and memory. results = client.load_instance(run_ids[0], 'results') results [40] 2020-05-30 16:20:44 ( 28.0ms ) python3 ( 5.86s ) Results(['train', 'val', 'test']) for mode in results: # Yield a mode. print(mode, results[mode].output.shape) [41] 2020-05-30 16:20:44 ( 7.00ms ) python3 ( 5.87s ) train (600, 1) val (200, 1) test (200, 1) For cross validation, we need 4 runs. In order to load multiple run's results at the same time, the Ivory Client provides a convenient method. results = client.load_results(run_ids, verbose=False) # No progress bar. results [42] 2020-05-30 16:20:44 ( 111ms ) python3 ( 5.98s ) Results(['val', 'test']) for mode, result in results.items(): # Yield a (mode, result). print(mode, result.output.shape) [43] 2020-05-30 16:20:44 ( 7.00ms ) python3 ( 5.99s ) val (800, 1) test (800, 1) Note Client.load_results() drops train data for saving memory. The lengths of validation data and test data are both 800 (200 times 4). But be careful about the test data. The length of unique samples is 200 (one fold size). import numpy as np len(np.unique(results.val.index)), len(np.unique(results.test.index)) [44] 2020-05-30 16:20:44 ( 5.00ms ) python3 ( 5.99s ) (800, 200) Usually, duplicated samples in test data are averaged for ensembling. The Results.mean() function performs this mean reduction and returns a newly created Rusults instance. reduced_results = results.mean() for mode, result in reduced_results.items(): print(mode, result.output.shape) [45] 2020-05-30 16:20:44 ( 16.0ms ) python3 ( 6.01s ) val (800, 1) test (200, 1) Compare these results. index = results.test.index index_0 = index[0] x = results.test.output[index == index_0] print('[results]') print(x) print(\"-> mean:\", np.mean(x)) index = reduced_results.test.index x = reduced_results.test.output[index == index_0] print('[reduced_results]') print(x) [46] 2020-05-30 16:20:44 ( 13.0ms ) python3 ( 6.02s ) [results] [[7.0976806] [7.5276694] [6.748764 ] [7.8637958]] -> mean: 7.309478 [reduced_results] [[7.3094773]] For convenience, The Client.load_results() function has a reduction keyword argument. results = client.load_results(run_ids, reduction='mean', verbose=False) results [47] 2020-05-30 16:20:44 ( 100ms ) python3 ( 6.12s ) Results(['val', 'test']) for mode, result in results.items(): print(mode, result.output.shape) [48] 2020-05-30 16:20:45 ( 6.00ms ) python3 ( 6.13s ) val (800, 1) test (200, 1) A cross validation (CV) score can be calculated as follows: true = results.val.target pred = results.val.output np.mean(np.sqrt((true - pred) ** 2)) # Use any function for your metric. [49] 2020-05-30 16:20:45 ( 4.00ms ) python3 ( 6.13s ) 2.267669 And we got a prediction for the test data using 4 MLP models. results.test.output[:5] [50] 2020-05-30 16:20:45 ( 4.00ms ) python3 ( 6.14s ) array([[ 7.3094773], [13.318664 ], [ 8.795811 ], [ 8.329647 ], [ 8.197912 ]], dtype=float32) Summary In this quickstart, we learned how to use the Ivory library to perform machine learning workflow. For more details see the Tutorial.","title":"<span class=\"pheasant-header\"><span class=\"header\"><span class=\"title\">Quickstart</span></span></span>"},{"location":"quickstart/#quickstart","text":"","title":"Quickstart"},{"location":"quickstart/#installation","text":"Install Ivory using pip . $ pip install ivory","title":"Installation"},{"location":"quickstart/#using-an-ivory-client","text":"Ivory has the Client class that manages the workflow of machine learning. Let's create your first Client instance. In this quickstart, we are working with examples under the examples directory. import ivory client = ivory.create_client(\"examples\") client [3] 2020-05-30 16:20:38 ( 1.02s ) python3 ( 1.06s ) Client(num_objects=2) The representation of the client shows that it has two objects. These objects can be accessed by index notation or dot notation . client[0] # or client['tracker'], or client.tracker [4] 2020-05-30 16:20:39 ( 5.00ms ) python3 ( 1.06s ) Tracker(tracking_uri='file:///C:/Users/daizu/Documents/github/ivory/examples/mlruns', artifact_location=None) The first object is a Tracker instance which connects Ivory to MLFlow Tracking . Because a Client instance is an iterable, you can get all of the objects by applying list() to it. list(client) [5] 2020-05-30 16:20:39 ( 4.00ms ) python3 ( 1.07s ) ['tracker', 'tuner'] The second objects is named tuner . client.tuner [6] 2020-05-30 16:20:39 ( 3.00ms ) python3 ( 1.07s ) Tuner(storage='sqlite://', sampler=None, pruner=None, load_if_exists=True) A Tuner instance connects Ivory to Optuna: A hyperparameter optimization framework . We can customize these objects with a YAML file named client.yml under the woking directory. In our case, the file just contains the minimum settings. File 1 client.yml client: tracker: tuner: Note A YAML file for client is not required. If there is no file for client, Ivory creates a default client with a tracker and without a tuner. If you don't need a tracker, for example in debugging, use ivory.create_client(tracker=False) .","title":"Using an Ivory Client"},{"location":"quickstart/#create-numpy-data","text":"In this quickstart, we try to predict rectangles area from thier width and height using PyTorch . First, prepare the data as NumPy arrays. In rectangle/data.py under the working directory, a create_data() function is defined. The ivory.create_client() function automatically inserts the working directory to sys.path , so that we can import the module regardless of the current directory. Let's check the create_data() function defined in rectangle/data.py and an example output: File 2 rectangle/data.py from dataclasses import dataclass import numpy as np import ivory.core.data from ivory.utils.fold import kfold_split def create_data(num_samples=1000): xy = 4 * np.random.rand(num_samples, 2) + 1 xy = xy.astype(np.float32) dx = 0.1 * (np.random.rand(num_samples) - 0.5) dy = 0.1 * (np.random.rand(num_samples) - 0.5) z = ((xy[:, 0] + dx) * (xy[:, 1] + dy)).astype(np.float32) return xy, z @dataclass(repr=False) class Data(ivory.core.data.Data): n_splits: int = 4 DATA = create_data(1000) # Shared by each run. def init(self): # Called from self.__post_init__() self.input, self.target = self.DATA self.index = np.arange(len(self.input)) # Extra fold for test data. self.fold = kfold_split(self.input, n_splits=self.n_splits + 1) # Creating dummy test data just for demonstration. is_test = self.fold == self.n_splits # Use an extra fold. self.fold[is_test] = -1 # -1 for test data. self.target = self.target.copy() # n_splits may be different among runs. self.target[is_test] = np.nan # Delete target for test data. self.target = self.target.reshape(-1, 1) # (sample, class) def transform(mode, input, target): return input, target.reshape(-1) import rectangle.data xy, z = rectangle.data.create_data(4) xy [8] 2020-05-30 16:20:39 ( 5.00ms ) python3 ( 1.08s ) array([[3.9385965, 4.358432 ], [4.2360554, 3.944485 ], [1.4794189, 3.9337072], [2.0614476, 2.6825428]], dtype=float32) z [9] 2020-05-30 16:20:39 ( 4.00ms ) python3 ( 1.09s ) array([17.543365 , 17.063057 , 5.7714915, 5.600619 ], dtype=float32)","title":"Create NumPy data"},{"location":"quickstart/#set-of-data-classes","text":"Ivory defines a set of Data classes ( Data , Dataset , Datasets ). But now, we use the Data class only. In the above file, the kfold_split() function creates a fold array. import numpy as np from ivory.utils.fold import kfold_split kfold_split(np.arange(10), n_splits=3) [10] 2020-05-30 16:20:39 ( 5.00ms ) python3 ( 1.09s ) array([2, 1, 0, 2, 0, 2, 1, 1, 0, 0], dtype=int8) Now, we can get a Data instance. data = rectangle.data.Data() data [11] 2020-05-30 16:20:39 ( 4.00ms ) python3 ( 1.10s ) Data(train_size=800, test_size=200) data.get(0) # get data of index = 0. [12] 2020-05-30 16:20:39 ( 5.00ms ) python3 ( 1.10s ) (0, array([4.8919764, 1.1556569], dtype=float32), array([5.668457], dtype=float32)) This returned value is a tuple of (index, input, target). Ivory always keeps data index so that we can know where a sample comes from.","title":"Set of Data classes"},{"location":"quickstart/#define-a-model","text":"We use a simple MLP model here. File 3 rectangle/torch.py import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self, hidden_sizes): super().__init__() layers = [] for in_features, out_features in zip([2] + hidden_sizes, hidden_sizes + [1]): layers.append(nn.Linear(in_features, out_features)) self.layers = nn.ModuleList(layers) def forward(self, x): for layer in self.layers[:-1]: x = F.relu(layer(x)) return self.layers[-1](x)","title":"Define a model"},{"location":"quickstart/#parameter-file-for-run","text":"Ivory configures a run using a YAML file. Here is a full example. File 4 torch.yaml library: torch datasets: data: class: rectangle.data.Data n_splits: 4 dataset: fold: 0 model: class: rectangle.torch.Model hidden_sizes: [20, 30] optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 1e-3 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: metrics: monitor: metric: val_loss early_stopping: patience: 10 trainer: loss: torch.nn.functional.mse_loss batch_size: 10 epochs: 10 verbose: 2 Let's create a run by Client.create_run() run = client.create_run('torch') run [14] 2020-05-30 16:20:40 ( 290ms ) python3 ( 1.68s ) [I 200530 16:20:40 tracker:48] A new experiment created with name: 'torch' Run(id='ed7daae64ed148b984bf2d00c21fa446', name='run#0', num_objects=12) Note Client.create_run(<name>) creates an experiment named <name> if it hasn't existed yet. By cliking an icon ( ) in the above cell, you can see the log. Or you can directly create an experiment then make the experiment create a run: experiment = client . create_experiment ( 'torch' ) run = experiment . create_run () A Run instance have a params attribute that holds the parameters for the run. import yaml print(yaml.dump(run.params, sort_keys=False)) [15] 2020-05-30 16:20:40 ( 9.71ms ) python3 ( 1.69s ) run: datasets: data: class: rectangle.data.Data n_splits: 4 dataset: def: ivory.torch.data.Dataset fold: 0 class: ivory.core.data.Datasets model: class: rectangle.torch.Model hidden_sizes: - 20 - 30 optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 0.001 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: class: ivory.torch.results.Results metrics: class: ivory.torch.metrics.Metrics monitor: metric: val_loss class: ivory.callbacks.monitor.Monitor early_stopping: patience: 10 class: ivory.callbacks.early_stopping.EarlyStopping trainer: loss: torch.nn.functional.mse_loss batch_size: 10 epochs: 10 verbose: 2 class: ivory.torch.trainer.Trainer class: ivory.torch.run.Run name: run#0 id: ed7daae64ed148b984bf2d00c21fa446 experiment: name: torch class: ivory.core.base.Experiment id: '1' This is similar to the YAML file we read before, but is slightly changed by the Ivory Client. Run and experiment sections are inserted. ExperimentID and RunID are assigned by MLFlow Tracking. Default classes are specified, for example ivory.torch.trainer.Trainer for a trainer instance. The Client.create_run() method can take keyword arguments to modify these parameters: run = client.create_run( 'torch', fold=3, hidden_sizes=[40, 50, 60], ) print('[datasets]') print(yaml.dump(run.params['run']['datasets'], sort_keys=False)) print('[model]') print(yaml.dump(run.params['run']['model'], sort_keys=False)) [16] 2020-05-30 16:20:40 ( 46.0ms ) python3 ( 1.74s ) [datasets] data: class: rectangle.data.Data n_splits: 4 dataset: def: ivory.torch.data.Dataset fold: 3 class: ivory.core.data.Datasets [model] class: rectangle.torch.Model hidden_sizes: - 40 - 50 - 60","title":"Parameter file for Run"},{"location":"quickstart/#train-a-model","text":"Once you got a run instance, then all you need is to start it. run = client.create_run('torch') # Back to the default settings. run.start() [17] 2020-05-30 16:20:40 ( 1.32s ) python3 ( 3.06s ) [epoch#0] loss=18.56 val_loss=6.65 lr=0.001 best [epoch#1] loss=6.703 val_loss=5.85 lr=0.001 best [epoch#2] loss=6.011 val_loss=5.861 lr=0.001 [epoch#3] loss=5.226 val_loss=5.16 lr=0.001 best [epoch#4] loss=4.51 val_loss=3.728 lr=0.001 best [epoch#5] loss=3.735 val_loss=3.058 lr=0.001 best [epoch#6] loss=3.021 val_loss=2.386 lr=0.001 best [epoch#7] loss=2.477 val_loss=1.891 lr=0.001 best [epoch#8] loss=1.871 val_loss=1.349 lr=0.001 best [epoch#9] loss=1.362 val_loss=1.013 lr=0.001 best The history of metrics is saved as the history attribute of a run.metrics instance. run.metrics.history [18] 2020-05-30 16:20:41 ( 5.00ms ) python3 ( 3.06s ) Dict(['loss', 'val_loss', 'lr']) run.metrics.history.val_loss [19] 2020-05-30 16:20:41 ( 4.00ms ) python3 ( 3.07s ) {0: 6.649628221988678, 1: 5.849701488018036, 2: 5.8606742262840275, 3: 5.160243093967438, 4: 3.728123116493225, 5: 3.058417332172394, 6: 2.386374127864838, 7: 1.8913944214582443, 8: 1.3491209745407104, 9: 1.0127072617411614} Also the model output and target are automatically collected in a run.results instance. run.results [20] 2020-05-30 16:20:41 ( 4.00ms ) python3 ( 3.07s ) Results(['train', 'val']) run.results.val.output[:5] [21] 2020-05-30 16:20:41 ( 4.00ms ) python3 ( 3.08s ) array([[7.0327463], [7.550438 ], [8.292342 ], [5.107143 ], [3.296762 ]], dtype=float32) run.results.val.target[:5] [22] 2020-05-30 16:20:41 ( 5.00ms ) python3 ( 3.08s ) array([[6.287244 ], [7.2876472], [7.7266474], [4.315375 ], [3.6494932]], dtype=float32)","title":"Train a model"},{"location":"quickstart/#test-a-model","text":"Testing a model is as simple as training. Just call run.start('test') instead of a (default) 'train' argument. run.start('test') run.results [23] 2020-05-30 16:20:41 ( 39.0ms ) python3 ( 3.12s ) Results(['train', 'val', 'test']) As you can see, test results were added. run.results.test.output[:5] [24] 2020-05-30 16:20:41 ( 4.00ms ) python3 ( 3.12s ) array([[ 5.390642 ], [14.77002 ], [ 6.9549603], [ 6.9801884], [ 5.6758666]], dtype=float32) Off course the target values for the test data are np.nan . run.results.test.target[:5] [25] 2020-05-30 16:20:41 ( 5.00ms ) python3 ( 3.13s ) array([[nan], [nan], [nan], [nan], [nan]], dtype=float32)","title":"Test a model"},{"location":"quickstart/#task-for-multiple-runs","text":"Ivory implements a special run type called Task which controls multiple nested runs. A task is useful for parameter search or cross validation. task = client.create_task('torch') task [26] 2020-05-30 16:20:41 ( 44.0ms ) python3 ( 3.17s ) Task(id='c721c909bb234c64977e3180e4f5bedd', name='task#0', num_objects=3) The Task class has two methods to generate multiple runs: Task.prodcut() and Task.chain() . These two methods have the same functionality as itertools of Python starndard library. Let's try to perform cross validation. runs = task.product(fold=range(4), verbose=0, epochs=3) runs [27] 2020-05-30 16:20:42 ( 4.00ms ) python3 ( 3.18s ) <generator object Task.product at 0x000002683115EDC8> Like itertools 's functions, Task.prodcut() and Task.chain() return a generator, which yields runs that are configured by different parameters you specify. In this case, this generator will yield 4 runs with a fold number ranging from 0 to 3 for each. A task instance doesn't start any training by itself. In addtion, you can pass fixed parameters to update the original parameters in the YAML file. Then start 4 runs by a for loop including run.start('both') . Here 'both' means execution of test after training. for run in runs: run.start('both') [28] 2020-05-30 16:20:42 ( 2.12s ) python3 ( 5.30s ) [run#3] epochs=3 fold=0 [run#4] epochs=3 fold=1 [run#5] epochs=3 fold=2 [run#6] epochs=3 fold=3","title":"Task for multiple runs"},{"location":"quickstart/#collect-runs","text":"Our client has a Tracker instance. It stores the state of runs in background using MLFlow Tracking. The Client class provides several methods to access the stored runs. For example, Client.search_run_ids() returns a generator which yields RunID created by MLFlow Tracking. # A helper function. def print_run_info(run_ids): for run_id in run_ids: print(run_id[:5], client.get_run_name(run_id)) [29] 2020-05-30 16:20:44 ( 4.00ms ) python3 ( 5.30s ) run_ids = client.search_run_ids('torch') # Yields all runs of `torch`. print_run_info(run_ids) [30] 2020-05-30 16:20:44 ( 84.7ms ) python3 ( 5.39s ) 820fc run#6 b9d0d run#5 059fe run#4 28911 run#3 c721c task#0 c4793 run#2 d68fe run#1 ed7da run#0 For filtering, add key-value pairs. # If `exclude_parent` is True, parent runs are excluded. run_ids = client.search_run_ids('torch', fold=0, exclude_parent=True) print_run_info(run_ids) [31] 2020-05-30 16:20:44 ( 160ms ) python3 ( 5.55s ) 28911 run#3 c4793 run#2 ed7da run#0 # If `parent_run_id` is specified, nested runs having the parent are returned. run_ids = client.search_run_ids('torch', parent_run_id=task.id) print_run_info(run_ids) [32] 2020-05-30 16:20:44 ( 46.0ms ) python3 ( 5.60s ) 820fc run#6 b9d0d run#5 059fe run#4 28911 run#3 Client.get_run_id() and Client.get_run_ids() fetch RunID from run name, more strictly, (run class name in lower case) plus (run number). run_ids = [client.get_run_id('torch', run=0), client.get_run_id('torch', task=0)] print_run_info(run_ids) [33] 2020-05-30 16:20:44 ( 52.0ms ) python3 ( 5.65s ) ed7da run#0 c721c task#0 run_ids = client.get_run_ids('torch', run=range(2, 4)) print_run_info(run_ids) [34] 2020-05-30 16:20:44 ( 56.0ms ) python3 ( 5.70s ) c4793 run#2 28911 run#3","title":"Collect runs"},{"location":"quickstart/#load-runs-and-results","text":"The Client instance can load runs. First select RunID(s) to load. We want to perform cross validation here, so that we need a run collection created by the task#0 . In this case, we can use Client.get_nested_run_ids() . Why don't we use Client.search_run_ids() as we did above? Because we don't have an easy way to get a very long RunID after we restart a Python session and lose the Task instance. On the ohter hand, a run name is easy to manage and write. # Assume that we restart a session so we have no run instances now. run_ids = list(client.get_nested_run_ids('torch', task=0)) print_run_info(run_ids) [35] 2020-05-30 16:20:44 ( 76.7ms ) python3 ( 5.78s ) 820fc run#6 b9d0d run#5 059fe run#4 28911 run#3 Let's load the latest run. run = client.load_run(run_ids[0]) run [36] 2020-05-30 16:20:44 ( 41.0ms ) python3 ( 5.82s ) Run(id='820fc44165654562a65c684daf0606c0', name='run#6', num_objects=11) Note that the Client.load_run() function doesn't require an experiment name because RunID is UUID . As you expected, the fold number is 3. run.datasets.fold [37] 2020-05-30 16:20:44 ( 3.00ms ) python3 ( 5.82s ) 3 By loading a run, we obtain the pretrained model. run.model.eval() [38] 2020-05-30 16:20:44 ( 3.00ms ) python3 ( 5.83s ) Model( (layers): ModuleList( (0): Linear(in_features=2, out_features=20, bias=True) (1): Linear(in_features=20, out_features=30, bias=True) (2): Linear(in_features=30, out_features=1, bias=True) ) ) import torch index, input, target = run.datasets.val[:5] with torch.no_grad(): output = run.model(torch.tensor(input)) print('[output]') print(output.numpy()) print('[target]') print(target) [39] 2020-05-30 16:20:44 ( 9.00ms ) python3 ( 5.84s ) [output] [[ 4.1013646] [ 8.760274 ] [ 8.455029 ] [11.647578 ] [10.107115 ]] [target] [[ 1.8680166] [ 6.1457186] [ 6.816285 ] [12.231698 ] [ 8.306013 ]] If you don't need a whole run instance, the Client.load_instance() function is a better choice to save time and memory. results = client.load_instance(run_ids[0], 'results') results [40] 2020-05-30 16:20:44 ( 28.0ms ) python3 ( 5.86s ) Results(['train', 'val', 'test']) for mode in results: # Yield a mode. print(mode, results[mode].output.shape) [41] 2020-05-30 16:20:44 ( 7.00ms ) python3 ( 5.87s ) train (600, 1) val (200, 1) test (200, 1) For cross validation, we need 4 runs. In order to load multiple run's results at the same time, the Ivory Client provides a convenient method. results = client.load_results(run_ids, verbose=False) # No progress bar. results [42] 2020-05-30 16:20:44 ( 111ms ) python3 ( 5.98s ) Results(['val', 'test']) for mode, result in results.items(): # Yield a (mode, result). print(mode, result.output.shape) [43] 2020-05-30 16:20:44 ( 7.00ms ) python3 ( 5.99s ) val (800, 1) test (800, 1) Note Client.load_results() drops train data for saving memory. The lengths of validation data and test data are both 800 (200 times 4). But be careful about the test data. The length of unique samples is 200 (one fold size). import numpy as np len(np.unique(results.val.index)), len(np.unique(results.test.index)) [44] 2020-05-30 16:20:44 ( 5.00ms ) python3 ( 5.99s ) (800, 200) Usually, duplicated samples in test data are averaged for ensembling. The Results.mean() function performs this mean reduction and returns a newly created Rusults instance. reduced_results = results.mean() for mode, result in reduced_results.items(): print(mode, result.output.shape) [45] 2020-05-30 16:20:44 ( 16.0ms ) python3 ( 6.01s ) val (800, 1) test (200, 1) Compare these results. index = results.test.index index_0 = index[0] x = results.test.output[index == index_0] print('[results]') print(x) print(\"-> mean:\", np.mean(x)) index = reduced_results.test.index x = reduced_results.test.output[index == index_0] print('[reduced_results]') print(x) [46] 2020-05-30 16:20:44 ( 13.0ms ) python3 ( 6.02s ) [results] [[7.0976806] [7.5276694] [6.748764 ] [7.8637958]] -> mean: 7.309478 [reduced_results] [[7.3094773]] For convenience, The Client.load_results() function has a reduction keyword argument. results = client.load_results(run_ids, reduction='mean', verbose=False) results [47] 2020-05-30 16:20:44 ( 100ms ) python3 ( 6.12s ) Results(['val', 'test']) for mode, result in results.items(): print(mode, result.output.shape) [48] 2020-05-30 16:20:45 ( 6.00ms ) python3 ( 6.13s ) val (800, 1) test (200, 1) A cross validation (CV) score can be calculated as follows: true = results.val.target pred = results.val.output np.mean(np.sqrt((true - pred) ** 2)) # Use any function for your metric. [49] 2020-05-30 16:20:45 ( 4.00ms ) python3 ( 6.13s ) 2.267669 And we got a prediction for the test data using 4 MLP models. results.test.output[:5] [50] 2020-05-30 16:20:45 ( 4.00ms ) python3 ( 6.14s ) array([[ 7.3094773], [13.318664 ], [ 8.795811 ], [ 8.329647 ], [ 8.197912 ]], dtype=float32)","title":"Load runs and results"},{"location":"quickstart/#summary","text":"In this quickstart, we learned how to use the Ivory library to perform machine learning workflow. For more details see the Tutorial.","title":"Summary"},{"location":"api/ivory.core.client/","text":"MODULE ivory.core.client This module provides the Ivory Client class which is one of the main classes of Ivory library. To create an Client instance: import ivory client = ivory.create_client() Here, the current directory becomes the working directory in which experiment YAML files exist. If you want to refer other directory, use: client = ivory.create_client('path/to/working_directory') CLASS ivory.core.client. Client (params=None, **objects) The Ivory Client class. Attributes tracker (Tracker) \u2014 A Tracker instance for tracking run process. tuner (Tuner) \u2014 A Tuner instance for hyperparameter tuning. METHOD create_experiment (name, *args, **kwargs) \u2192 Experiment Creates an Experiment according to the YAML file specified by name . Parameters name (str) \u2014 Experiment name. *args \u2014 Additional parameter files. **kwargs \u2014 Additional parameter files. A YAML file named <name>.yml or <name>.yaml should exist under the working directory. Any additionanl parameter files are added through *args and/or **kwargs . Examples Positional argument style : experiment = client.create_experiment('example', 'study') In this case, study.yml is like this: study: tuner: pruner: class: optuna.pruners.MedianPruner objective: lr: example.suggest_lr Keyword argument style : experiment = client.create_experiment('example', study='study') In this case, study.yml is like this: tuner: pruner: class: optuna.pruners.MedianPruner objective: lr: example.suggest_lr METHOD create_run (name, args=None, **kwargs) \u2192 Run Creates a Run . Parameters name (str) \u2014 Experiment name. args (dict, optional) \u2014 Parameter dictionary to update the default values of Experiment . **kwargs \u2014 Additional parameters. Examples To update a fold number: run = client.create_run('example', fold=3) To update a model class: run = client.create_run('example', {'model.class': 'your.new.Model'}) METHOD create_task (name, run_number=None) \u2192 Task Creates a Task for multiple runs. Parameters name (str) \u2014 Experiment name. run_number (int, optional) \u2014 If specified, load an existing task instead of creating a new one. See Also Multiple Runs METHOD create_study (name, args=None, run_number=None, **suggests) \u2192 Study Creates a Study for hyperparameter tuning. Parameters name (str) \u2014 Experiment name. args (str or dict) \u2014 Suggest name (str) or parametric optimization (dict). run_number (int, optional) \u2014 If specified, load an existing study instead of creating a new one. **suggests \u2014 Parametric optimization. Examples To use a suggest function: study = client.create_study('example', 'lr') For parametric optimization: study = client.create_study('example', lr=(1e-5, 1e-3)) If a parameter includes dots: study = client.create_study('example', {'hidden_sizes.0': range(5, 20)}) See Also Hyperparameter Tuning METHOD get_run_id (name, **kwargs) \u2192 str Returns a RunID. Parameters name (str) \u2014 Experiment name. Examples To get a RunID of run#4. client.get_run_id('example', run=4) To get a RunID of task#10. client.get_run_id('example', task=10) GENERATOR get_run_ids (name, **kwargs) \u2192 Iterator[str] Returns an iterator that yields RunIDs. Parameters name (str) \u2014 Experiment name. Examples To get an iterator that yields RunIDs for Runs. client.get_run_id('example', run=[1, 2, 3]) To get an iterator that yields RunIDs for Tasks. client.get_run_id('example', task=range(3, 8)) METHOD get_parent_run_id (name, **kwargs) \u2192 str Returns a parent RunID of a nested run. Parameters name (str) \u2014 Experiment name. Examples To get a prarent RunID of run#5. client.get_parent_run_id('example', run=5) GENERATOR get_nested_run_ids (name, **kwargs) \u2192 Iterator[str] Returns an iterator that yields nested RunIDs of parent runs. Parameters name (str) \u2014 Experiment name. Examples To get an iterator that yields RunIDs of runs whose parent is task#2. client.get_nested_run_ids('example', task=2) Multiple parents can be specified. client.get_nested_run_ids('example', task=range(3, 8)) METHOD set_parent_run_id (name, **kwargs) Sets parent RunID to runs. Parameters name (str) \u2014 Experiment name. Examples To set task#2 as a parant for run#4. client.set_parent_run_id('example', task=2, run=4) Multiple nested runs can be specified. client.set_parent_run_id('example', task=2, run=range(3)) METHOD get_run_name (run_id) \u2192 str Returns a run name ( run#XXX , task#XXX , etc .) for RunID. Parameters run_id (str) \u2014 RunID METHOD get_run_name_tuple (run_id) \u2192 (str, int) Returns a run name as a tuple of (run class name, run number). Parameters run_id (str) \u2014 RunID GENERATOR search_run_ids (name='', run_name='', parent_run_id='', parent_only=False, nested_only=False, exclude_parent=False, best_score_limit=None, **query) \u2192 Iterator[str] Returns an iterator that yields matching RunIDs. Parameters name (str, optional) \u2014 Experiment name pattern for filtering. run_name (str, optional) \u2014 Run name pattern for filtering. parent_run_id (str or iterable of str) \u2014 If specified, search from runs which have the parent id(s). parent_only (bool, optional) \u2014 If True, search from parent runs. nested_only (bool, optional) \u2014 If True, search from nested runs. exclude_parent (bool, optional) \u2014 If True, skip parent runs. best_score_limit (Union[float, NoneType], optional) \u2014 Yields runs with the best score better than this value. **query \u2014 Key-value pairs for filtering. GENERATOR search_parent_run_ids (name='', **query) \u2192 Iterator[str] Returns an iterator that yields matching parent RunIDs. Parameters name (str, optional) \u2014 Experiment name pattern for filtering. **query \u2014 Key-value pairs for filtering. GENERATOR search_nested_run_ids (name='', **query) \u2192 Iterator[str] Returns an iterator that yields matching nested RunIDs. Parameters name (str, optional) \u2014 Experiment name pattern for filtering. **query \u2014 Key-value pairs for filtering. METHOD set_terminated (name, status=None, **kwargs) Sets runs' status to terminated. Parameters status (Union[str, NoneType], optional) \u2014 A string value of mlflow.entities.RunStatus . Defaults to \u201cFINISHED\u201d. Examples To terminate a run: client.set_terminated('example', run=5) To kill multiple runs: client.set_terminated('example', 'KILLED', run=[3, 5, 7]) METHOD set_terminated_all (name='') Sets all runs' status to terminated. Parameters status \u2014 A string value of mlflow.entities.RunStatus . Defaults to \u201cFINISHED\u201d. Examples To terminate all of the runs of the example experiment: client.set_terminated_all('example') To terminate all of the runs globally: client.set_terminated_all() METHOD load_params (run_id) \u2192 Dict[str, Any] Returns a parameter dictionary loaded from MLFlow Tracking. Parameters run_id (str) \u2014 RunID for a run to be loaded. METHOD load_run (run_id, mode='test') \u2192 Run Returns a Run instance created using parameters loaded from MLFlow Tracking. Parameters run_id (str) \u2014 RunID for a run to be loaded. mode (str, optional) \u2014 Mode name: 'current' , 'best' , or 'test' . Default is 'test' . METHOD load_run_by_name (name, mode='test', **kwargs) \u2192 Run Returns a Run instance created using parameters loaded from MLFlow Tracking. Parameters name (str) \u2014 Experiment name pattern for filtering. mode (str, optional) \u2014 Mode name: 'current' , 'best' , or 'test' . Examples To load run#4 of the example experiment. client.load_run_by_name('example', run=4) METHOD load_instance (run_id, instance_name, mode='test') \u2192 Any Returns a member of a Run created using parameters loaded from MLFlow Tracking. Parameters run_id (str) \u2014 RunID for a run to be loaded. instance_name (str) \u2014 Instance name. mode (str, optional) \u2014 Mode name: 'current' , 'best' , or 'test' . METHOD load_results (run_ids, callback=None, reduction='none', verbose=True) Loads results from multiple runs and concatenates them. Parameters run_ids (Union[str, Iterable[str]]) \u2014 Multiple run ids to load. callback (callable) \u2014 Callback function for each run. This function must take a (index, output, target) and return a tuple with the same signature. verbose (bool, optional) \u2014 If True , tqdm progress bar is displayed. Returns (Results) A concatenated results instance. METHOD remove_deleted_runs (name='') Removes deleted runs from a local file system. Parameters name (str, optional) \u2014 Experiment name pattern for filtering. Returns (int) Number of removed runs. FUNCTION ivory.core.client. create_client (directory='', name='client', tracker=True) Creates an Ivory Client instance. Parameters directory (str, optional) \u2014 A working directory. If a YAML file specified by the name parameter exists, the file is loaded to configure the client. In addition, this directory is automatically inserted to sys.path . name (str, optional) \u2014 A YAML config file name. tracker (bool, optional) \u2014 If true, the client instance has a tracker. Returns (Client) An created client. Note If tracker is True (default value), a mlruns directory is made under the working directory by MLFlow Tracking.","title":"Ivory.core.client"},{"location":"api/ivory.core.data/","text":"MODULE ivory.core.data Ivory uses three classes for data presentation: Data , Dataset , and Datasets . Basically, you only need to define a class that is a subclass of Data and use original Dataset and Datasets . An example parameter YAML file is: datasets: data: class: your.Data # a subclass of ivory.core.data.Data dataset: fold: 0 But if you need, you can define your Dataset and/or Datasets . datasets: class: your.Datasets data: class: your.Data # a subclass of ivory.core.data.Data dataset: def: your.Dataset fold: 0 Note Use a 'def' key for dataset instead of 'class' . See Tutorial DATACLASS ivory.core.data. Data () Base class to provide data to a Dataset instance. To make a subclass, you need to assign the following attributes in the Data.init() method: index : Index of samples. input : Input data. target : Target data. fold : Fold number. METHOD init () Initializes index , input , target , and fold attributes. The fold number of test data must be -1 . Examples For regression def init(self): self.index = np.range(100) self.input = np.random.randn(100, 5) self.target = np.random.randn(100) self.fold = np.random.randint(5) self.fold[80:] = -1 For classification def init(self): self.index = np.range(100) self.input = np.random.randn(100, 5) self.target = np.random.randint(100, 10) self.fold = np.random.randint(5) self.fold[80:] = -1 METHOD get_index (mode, fold) \u2192 ndarray Returns index according to the mode and fold. Parameters mode (str) \u2014 Mode name: 'train' , 'val' , or 'test' . fold (int) \u2014 Fold number. METHOD get_input (index) Returns input data. By default, this method returns self.input[index] . You can override this behavior in a subclass. Parameters index (int or 1D-array) \u2014 Index. METHOD get_target (index) Returns target data. By default, this method returns self.target[index] . You can override this behavior in a subclass. Parameters index (int or 1D-array) \u2014 Index. METHOD get (index) \u2192 tuple Returns a tuple of ( index , input , target ) according to the index. Parameters index (int or 1D-array) \u2014 Index. DATACLASS ivory.core.data. Dataset (data, mode, fold, transform=None) Dataset class represents a set of data for a mode and fold. Parameters data (Data) \u2014 Data instance that provides data to Dataset instance. mode (str) \u2014 Mode name: 'train' , 'val' , or 'test' . fold (int) \u2014 Fold number. transform (callable, optional) \u2014 Callable to transform the data. The transform must take 2 or 3 arguments: ( mode , input , optional target ) and return a tuple of ( input , optional target ). METHOD init () Called at initialization. You can add any process in a subclass. METHOD get (index=None) \u2192 tuple Returns a tuple of ( index , input , target ) according to the index. If index is None , reutrns all of the data. Parameters index (int or 1D-array, optional) \u2014 Index. METHOD sample (n=0, frac=0.0) \u2192 tuple Returns a tuple of ( index , input , target ) randomly sampled. Parameters n (int, optional) \u2014 Size of sampling. frac (float, optional) \u2014 Ratio of sampling. DATACLASS ivory.core.data. Datasets (data, dataset, fold) Dataset class represents a collection of Dataset for a fold. Parameters data (Data) \u2014 Data instance that provides data to Dataset instance. dataset (Callable) \u2014 Dataset factory. fold (int) \u2014 Fold number. Attributes train (Dataset) \u2014 Train dataset. val (Dataset) \u2014 Validation dataset. test (Dataset) \u2014 Test dataset. fold (int) \u2014 Fold number.","title":"Ivory.core.data"},{"location":"tutorial/callback/","text":"Callback System Basics Ivory implements a simple but powerful callback system. Here is the list of callback functions in the order of invocation: import ivory.core.base ivory.core.base.Callback.METHODS [2] 2020-05-30 16:20:45 ( 4.00ms ) python3 ( 6.16s ) ['on_init_begin', 'on_init_end', 'on_fit_begin', 'on_epoch_begin', 'on_train_begin', 'on_train_end', 'on_val_begin', 'on_val_end', 'on_epoch_end', 'on_fit_end', 'on_test_begin', 'on_test_end'] Any class that defines these functions can be a callback instance. class SimpleCallback: # No base class is needed. # You don't have to define all of the callback functions def on_fit_begin(self, run): # Must have an only `run` argument. print(f'on_fit_begin is called from id={id(run)}') # Do something with `run`. [3] 2020-05-30 16:20:45 ( 3.00ms ) python3 ( 6.17s ) To invoke callback functions, create a CallbackCaller instance. caller = ivory.core.base.CallbackCaller(simple=SimpleCallback()) caller [4] 2020-05-30 16:20:45 ( 4.00ms ) python3 ( 6.17s ) CallbackCaller(num_objects=1) The number of registered instances is 1. list(caller) [5] 2020-05-30 16:20:45 ( 5.00ms ) python3 ( 6.18s ) ['simple'] Then call the CallbackCaller.create_callbacks() method to build a callback network. caller.create_callbacks() caller [6] 2020-05-30 16:20:45 ( 5.00ms ) python3 ( 6.18s ) CallbackCaller(num_objects=13) The number of instances increased up to 13. list(caller) [7] 2020-05-30 16:20:45 ( 3.00ms ) python3 ( 6.18s ) ['simple', 'on_init_begin', 'on_init_end', 'on_fit_begin', 'on_epoch_begin', 'on_train_begin', 'on_train_end', 'on_val_begin', 'on_val_end', 'on_epoch_end', 'on_fit_end', 'on_test_begin', 'on_test_end'] Callback functions are added to the caller instance. Let's inspect some callback funtions. caller.on_init_begin [8] 2020-05-30 16:20:45 ( 4.00ms ) python3 ( 6.19s ) Callback([]) This is an empty callback because the caller has no instances that define the on_init_begin() function. On the other hand, caller.on_fit_begin [9] 2020-05-30 16:20:45 ( 3.00ms ) python3 ( 6.19s ) Callback(['simple']) The simple instance is registered as a receiver of the on_fit_begin() function. We can call this. caller.on_fit_begin() [10] 2020-05-30 16:20:45 ( 4.00ms ) python3 ( 6.19s ) on_fit_begin is called from id=2646624679752 id(caller) [11] 2020-05-30 16:20:45 ( 4.00ms ) python3 ( 6.20s ) 2646624679752 This caller-receiver network among arbitrary instance collection builds a complex machine learning workflow. The Run class is a subclass of the CallbackCaller class and performs more library-specific process. We uses this Run class below. Example Callback: Results To work with the Results callback, we create a set of data and a model. For more details about the following code, see Creating Instance section. import yaml from ivory.core.instance import create_instance # A helper function. def create(doc, name, **kwargs): params = yaml.safe_load(doc) return create_instance(params, name, **kwargs) doc = \"\"\" library: torch datasets: data: class: rectangle.data.Data n_splits: 5 dataset: fold: 0 model: class: rectangle.torch.Model hidden_sizes: [3, 4, 5] \"\"\" datasets = create(doc, 'datasets') model = create(doc, 'model') [12] 2020-05-30 16:20:45 ( 8.00ms ) python3 ( 6.21s ) The Results callback stores index, output, and target data. To save memory, a Results instance ignores input data. # import ivory.callbacks.results # For Scikit-learn or TensorFlow. import ivory.torch.results results = ivory.torch.results.Results() results [13] 2020-05-30 16:20:45 ( 4.00ms ) python3 ( 6.21s ) Results([]) import ivory.core.run run = ivory.core.run.Run( datasets=datasets, model=model, results=results ) run.create_callbacks() run [14] 2020-05-30 16:20:45 ( 4.00ms ) python3 ( 6.21s ) Run(num_objects=15) # A helper function def print_callbacks(obj): for func in ivory.core.base.Callback.METHODS: if hasattr(obj, func) and callable(getattr(obj, func)): print(func) print_callbacks(results) [15] 2020-05-30 16:20:45 ( 7.00ms ) python3 ( 6.22s ) on_train_begin on_train_end on_val_end on_test_begin on_test_end Let's play with the Results callback. The Results.step() method records the current index, output, and target. import torch # For simplicity, just one epoch with some batches. run.on_train_begin() dataset = run.datasets.train for k in range(3): index, input, target = dataset[4 * k : 4 * (k + 1)] input, target = torch.tensor(input), torch.tensor(target) output = run.model(input) run.results.step(index, output, target) # Do something for example parameter update or early stopping. run.on_train_end() run.on_val_begin() # Can call even if there is no callback. dataset = run.datasets.val for k in range(2): index, input, target = dataset[4 * k : 4 * (k + 1)] input, target = torch.tensor(input), torch.tensor(target) output = run.model(input) run.results.step(index, output, target) run.on_val_end() run.on_epoch_end() results [16] 2020-05-30 16:20:45 ( 9.00ms ) python3 ( 6.23s ) Results(['train', 'val']) We performed a train and validation loop so that the Results instance has these data, but doesn't have test data. We can get data by nested dot-notation. results.train [17] 2020-05-30 16:20:45 ( 3.00ms ) python3 ( 6.23s ) Dict(['index', 'output', 'target']) results.train.index # The length is 4 x 3. [18] 2020-05-30 16:20:45 ( 3.00ms ) python3 ( 6.24s ) array([ 0, 2, 3, 4, 5, 6, 7, 10, 12, 13, 15, 16]) results.val.index # The length is 4 x 2. [19] 2020-05-30 16:20:45 ( 3.00ms ) python3 ( 6.24s ) array([ 1, 8, 14, 27, 30, 31, 34, 45]) results.val.output [20] 2020-05-30 16:20:45 ( 3.00ms ) python3 ( 6.24s ) array([[ 0.04275503], [ 0.102089 ], [-0.01715643], [-0.01133138], [ 0.239229 ], [ 0.13918285], [ 0.25804442], [-0.00105576]], dtype=float32) results.val.target [21] 2020-05-30 16:20:45 ( 4.00ms ) python3 ( 6.25s ) array([[ 6.287244 ], [ 7.7266474], [ 4.315375 ], [ 3.6494932], [ 7.128242 ], [ 9.64248 ], [12.528889 ], [ 4.4612327]], dtype=float32) Other Callback There are several callback such as Metrics , Monitor , etc . We will learn about them in next Training a Model tutorial.","title":"<span class=\"pheasant-header\"><span class=\"header\"><span class=\"title\">Callback System</span></span></span>"},{"location":"tutorial/callback/#callback-system","text":"","title":"Callback System"},{"location":"tutorial/callback/#basics","text":"Ivory implements a simple but powerful callback system. Here is the list of callback functions in the order of invocation: import ivory.core.base ivory.core.base.Callback.METHODS [2] 2020-05-30 16:20:45 ( 4.00ms ) python3 ( 6.16s ) ['on_init_begin', 'on_init_end', 'on_fit_begin', 'on_epoch_begin', 'on_train_begin', 'on_train_end', 'on_val_begin', 'on_val_end', 'on_epoch_end', 'on_fit_end', 'on_test_begin', 'on_test_end'] Any class that defines these functions can be a callback instance. class SimpleCallback: # No base class is needed. # You don't have to define all of the callback functions def on_fit_begin(self, run): # Must have an only `run` argument. print(f'on_fit_begin is called from id={id(run)}') # Do something with `run`. [3] 2020-05-30 16:20:45 ( 3.00ms ) python3 ( 6.17s ) To invoke callback functions, create a CallbackCaller instance. caller = ivory.core.base.CallbackCaller(simple=SimpleCallback()) caller [4] 2020-05-30 16:20:45 ( 4.00ms ) python3 ( 6.17s ) CallbackCaller(num_objects=1) The number of registered instances is 1. list(caller) [5] 2020-05-30 16:20:45 ( 5.00ms ) python3 ( 6.18s ) ['simple'] Then call the CallbackCaller.create_callbacks() method to build a callback network. caller.create_callbacks() caller [6] 2020-05-30 16:20:45 ( 5.00ms ) python3 ( 6.18s ) CallbackCaller(num_objects=13) The number of instances increased up to 13. list(caller) [7] 2020-05-30 16:20:45 ( 3.00ms ) python3 ( 6.18s ) ['simple', 'on_init_begin', 'on_init_end', 'on_fit_begin', 'on_epoch_begin', 'on_train_begin', 'on_train_end', 'on_val_begin', 'on_val_end', 'on_epoch_end', 'on_fit_end', 'on_test_begin', 'on_test_end'] Callback functions are added to the caller instance. Let's inspect some callback funtions. caller.on_init_begin [8] 2020-05-30 16:20:45 ( 4.00ms ) python3 ( 6.19s ) Callback([]) This is an empty callback because the caller has no instances that define the on_init_begin() function. On the other hand, caller.on_fit_begin [9] 2020-05-30 16:20:45 ( 3.00ms ) python3 ( 6.19s ) Callback(['simple']) The simple instance is registered as a receiver of the on_fit_begin() function. We can call this. caller.on_fit_begin() [10] 2020-05-30 16:20:45 ( 4.00ms ) python3 ( 6.19s ) on_fit_begin is called from id=2646624679752 id(caller) [11] 2020-05-30 16:20:45 ( 4.00ms ) python3 ( 6.20s ) 2646624679752 This caller-receiver network among arbitrary instance collection builds a complex machine learning workflow. The Run class is a subclass of the CallbackCaller class and performs more library-specific process. We uses this Run class below.","title":"Basics"},{"location":"tutorial/callback/#example-callback-results","text":"To work with the Results callback, we create a set of data and a model. For more details about the following code, see Creating Instance section. import yaml from ivory.core.instance import create_instance # A helper function. def create(doc, name, **kwargs): params = yaml.safe_load(doc) return create_instance(params, name, **kwargs) doc = \"\"\" library: torch datasets: data: class: rectangle.data.Data n_splits: 5 dataset: fold: 0 model: class: rectangle.torch.Model hidden_sizes: [3, 4, 5] \"\"\" datasets = create(doc, 'datasets') model = create(doc, 'model') [12] 2020-05-30 16:20:45 ( 8.00ms ) python3 ( 6.21s ) The Results callback stores index, output, and target data. To save memory, a Results instance ignores input data. # import ivory.callbacks.results # For Scikit-learn or TensorFlow. import ivory.torch.results results = ivory.torch.results.Results() results [13] 2020-05-30 16:20:45 ( 4.00ms ) python3 ( 6.21s ) Results([]) import ivory.core.run run = ivory.core.run.Run( datasets=datasets, model=model, results=results ) run.create_callbacks() run [14] 2020-05-30 16:20:45 ( 4.00ms ) python3 ( 6.21s ) Run(num_objects=15) # A helper function def print_callbacks(obj): for func in ivory.core.base.Callback.METHODS: if hasattr(obj, func) and callable(getattr(obj, func)): print(func) print_callbacks(results) [15] 2020-05-30 16:20:45 ( 7.00ms ) python3 ( 6.22s ) on_train_begin on_train_end on_val_end on_test_begin on_test_end Let's play with the Results callback. The Results.step() method records the current index, output, and target. import torch # For simplicity, just one epoch with some batches. run.on_train_begin() dataset = run.datasets.train for k in range(3): index, input, target = dataset[4 * k : 4 * (k + 1)] input, target = torch.tensor(input), torch.tensor(target) output = run.model(input) run.results.step(index, output, target) # Do something for example parameter update or early stopping. run.on_train_end() run.on_val_begin() # Can call even if there is no callback. dataset = run.datasets.val for k in range(2): index, input, target = dataset[4 * k : 4 * (k + 1)] input, target = torch.tensor(input), torch.tensor(target) output = run.model(input) run.results.step(index, output, target) run.on_val_end() run.on_epoch_end() results [16] 2020-05-30 16:20:45 ( 9.00ms ) python3 ( 6.23s ) Results(['train', 'val']) We performed a train and validation loop so that the Results instance has these data, but doesn't have test data. We can get data by nested dot-notation. results.train [17] 2020-05-30 16:20:45 ( 3.00ms ) python3 ( 6.23s ) Dict(['index', 'output', 'target']) results.train.index # The length is 4 x 3. [18] 2020-05-30 16:20:45 ( 3.00ms ) python3 ( 6.24s ) array([ 0, 2, 3, 4, 5, 6, 7, 10, 12, 13, 15, 16]) results.val.index # The length is 4 x 2. [19] 2020-05-30 16:20:45 ( 3.00ms ) python3 ( 6.24s ) array([ 1, 8, 14, 27, 30, 31, 34, 45]) results.val.output [20] 2020-05-30 16:20:45 ( 3.00ms ) python3 ( 6.24s ) array([[ 0.04275503], [ 0.102089 ], [-0.01715643], [-0.01133138], [ 0.239229 ], [ 0.13918285], [ 0.25804442], [-0.00105576]], dtype=float32) results.val.target [21] 2020-05-30 16:20:45 ( 4.00ms ) python3 ( 6.25s ) array([[ 6.287244 ], [ 7.7266474], [ 4.315375 ], [ 3.6494932], [ 7.128242 ], [ 9.64248 ], [12.528889 ], [ 4.4612327]], dtype=float32)","title":"Example Callback: Results"},{"location":"tutorial/callback/#other-callback","text":"There are several callback such as Metrics , Monitor , etc . We will learn about them in next Training a Model tutorial.","title":"Other Callback"},{"location":"tutorial/cli/","text":"Command Line Interface If you define data and model, and prepare a YAML parameter file, you don't need to write another Python script code to invoke runs. Ivory's command line interface can do it. For cross validation: $ ivory run torch fold=0-4 For grid search: $ ivory run torch dropout=0-0.5:5 hidden_sizes.0=10-20-2 For optimization using a suggest function: $ ivory optimize torch lr For parametric optimization: $ ivory optimize torch lr=1e-5_1e-3.log Right-hand side string for each parameter creates a Range instance to determine the range of parameters.","title":"<span class=\"pheasant-header\"><span class=\"header\"><span class=\"title\">Command Line Interface</span></span></span>"},{"location":"tutorial/cli/#command-line-interface","text":"If you define data and model, and prepare a YAML parameter file, you don't need to write another Python script code to invoke runs. Ivory's command line interface can do it. For cross validation: $ ivory run torch fold=0-4 For grid search: $ ivory run torch dropout=0-0.5:5 hidden_sizes.0=10-20-2 For optimization using a suggest function: $ ivory optimize torch lr For parametric optimization: $ ivory optimize torch lr=1e-5_1e-3.log Right-hand side string for each parameter creates a Range instance to determine the range of parameters.","title":"Command Line Interface"},{"location":"tutorial/core/","text":"Ivory Core Entities Client Ivory has the Client class that manages the workflow of machine learning. In this tutorial, we are working with data and model to predict rectangle area. The source module exists under the examples directory. First, create a Client instance. import ivory client = ivory.create_client(\"examples\") # Set the working directory client [3] 2020-05-30 16:20:45 ( 6.00ms ) python3 ( 6.31s ) Client(num_objects=2) list(client) [4] 2020-05-30 16:20:45 ( 3.00ms ) python3 ( 6.31s ) ['tracker', 'tuner'] The first object is a Tracker instance which connects Ivory to MLFlow Tracking . The second objects is named tuner . A Tuner instance connects Ivory to Optuna . Show files in the working directory examples . import os os.listdir('examples') [5] 2020-05-30 16:20:45 ( 5.00ms ) python3 ( 6.32s ) ['.coverage', 'client.yml', 'lgb.yml', 'mlruns', 'rectangle', 'rfr.yml', 'ridge.yml', 'study.yml', 'tf.yml', 'torch.yml'] rectangle is a Python package that contains our examples. YAML files with extension of .yml or possibly .yaml are parameter files to define a machine learning workflow. Basically, one YAML file is corresponding to one Experiment as discussed later, except the client.yml file. A YAML file name without the extension becomes an experiment name. mlruns is a directory automatically created by MLFlow Tracking in which our trained model and callbacks instances are saved. The client.yml is a configuration file for a Client instance. In our case, the file just contains the minimum settings. File 7 client.yml client: tracker: tuner: Note A YAML file for client is not required. If there is no file for client, Ivory creates a default client with a tracker and without a tuner. If you don't need a tracker, for example in debugging, use ivory.create_client(tracker=False) . Experiment The Client.create_experiment() function creates an Experiment instance. If the Client instance has a tracker , an experiment of MLFlow Tracking is also created at the same time if it hasn't existed yet. By cliking an icon ( ) in the below cell, you can see the log. experiment = client.create_experiment('torch') # Read torch.yml as params. experiment [6] 2020-05-30 16:20:45 ( 11.0ms ) python3 ( 6.33s ) [I 200530 16:20:45 tracker:48] A new experiment created with name: 'torch' Experiment(id='1', name='torch', num_objects=1) The ID for this experiment was given by MLFlow Tracking. The Client.create_experiment() function loads a corresponding YAML file to the first argument from the working directory. File 8 torch.yml library: torch datasets: data: class: rectangle.data.Data n_splits: 4 dataset: fold: 0 model: class: rectangle.torch.Model hidden_sizes: [20, 30] optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 1e-3 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: metrics: monitor: metric: val_loss early_stopping: patience: 10 trainer: loss: torch.nn.functional.mse_loss batch_size: 10 epochs: 10 verbose: 2 After loading, the Experiment instance setups the parameters for creating runs later. The parameters are stored in the params attribute. experiment.params [7] 2020-05-30 16:20:45 ( 5.00ms ) python3 ( 6.34s ) {'run': {'datasets': {'data': {'class': 'rectangle.data.Data', 'n_splits': 4}, 'dataset': {'def': 'ivory.torch.data.Dataset'}, 'fold': 0, 'class': 'ivory.core.data.Datasets'}, 'model': {'class': 'rectangle.torch.Model', 'hidden_sizes': [20, 30]}, 'optimizer': {'class': 'torch.optim.SGD', 'params': '$.model.parameters()', 'lr': 0.001}, 'scheduler': {'class': 'torch.optim.lr_scheduler.ReduceLROnPlateau', 'optimizer': '$', 'factor': 0.5, 'patience': 4}, 'results': {'class': 'ivory.torch.results.Results'}, 'metrics': {'class': 'ivory.torch.metrics.Metrics'}, 'monitor': {'metric': 'val_loss', 'class': 'ivory.callbacks.monitor.Monitor'}, 'early_stopping': {'patience': 10, 'class': 'ivory.callbacks.early_stopping.EarlyStopping'}, 'trainer': {'loss': 'torch.nn.functional.mse_loss', 'batch_size': 10, 'epochs': 10, 'verbose': 2, 'class': 'ivory.torch.trainer.Trainer'}, 'class': 'ivory.torch.run.Run'}, 'experiment': {'name': 'torch', 'class': 'ivory.core.base.Experiment', 'id': '1'}} This is similar to the YAML file, but is slightly changed by the Ivory Client. Run and experiment sections are inserted. ExperimentID and RunID are assigned by MLFlow Tracking. Default classes are specified, for example ivory.torch.trainer.Trainer for a trainer instance. Run After setting up an Experiment instance, you can create runs with various parameters. Ivory provides several way to configure them as below. Default parameters Calling without arguments creates a run with default parameters. run = experiment.create_run() run [8] 2020-05-30 16:20:45 ( 37.0ms ) python3 ( 6.37s ) Run(id='47becf3f67e4433791b46a9eea73b8e4', name='run#0', num_objects=12) Here, the ID for this run is given by MLFlow Tracking. On the other hand, the name is given by Ivory as a form of \" (run class name in lower case)#(run number) \". Simple literal (int, float, str) Passing key-value pairs, you can change the parameters. run = experiment.create_run(fold=1) run.datasets.fold [9] 2020-05-30 16:20:45 ( 36.0ms ) python3 ( 6.41s ) 1 But the type of parameter must be equal, otherwise a ValueError is raised. run = experiment.create_run(fold=0.5) run.datasets.fold [10] 2020-05-30 16:20:45 ( 141ms ) python3 ( 6.55s ) ValueError: different type: <class 'int'> != <class 'float'> ValueError Traceback (most recent call last) <ipython-input-100-db3b6dd1af57> in <module> ----> 1 run = experiment.create_run(fold=0.5) 2 run.datasets.fold ~\\Documents\\github\\ivory\\ivory\\core\\base.py in create_run(self, args, name, **kwargs) 55 56 def create_run(self, args=None, name: str = \"run\", **kwargs): ---> 57 params, args = self.create_params(args, name, **kwargs) 58 run = instance.create_base_instance(params, name, self.source_name) 59 if self.tracker: ~\\Documents\\github\\ivory\\ivory\\core\\base.py in create_params(self, args, name, **kwargs) 51 params.update(default.get(name)) 52 update, args = utils.params.create_update(params[name], args, **kwargs) ---> 53 utils.params.update_dict(params[name], update) 54 return params, args 55 ~\\Documents\\github\\ivory\\ivory\\utils\\params.py in update_dict(org, update) 28 x[k] = value 29 elif type(x[k]) is not type(value) and x[k] is not None: ---> 30 raise ValueError(f\"different type: {type(x[k])} != {type(value)}\") 31 else: 32 if isinstance(x[k], dict): List A list parameter can be overwritten by passing a new list. Off course you can change the lengh of the list. The original hidden_sizes was [10, 20] . run = experiment.create_run(hidden_sizes=[2, 3, 4]) run.model [11] 2020-05-30 16:20:45 ( 137ms ) python3 ( 6.69s ) Model( (layers): ModuleList( (0): Linear(in_features=2, out_features=2, bias=True) (1): Linear(in_features=2, out_features=3, bias=True) (2): Linear(in_features=3, out_features=4, bias=True) (3): Linear(in_features=4, out_features=1, bias=True) ) ) As an alternative way, you can use 0-indexed colon-notation like below. In this case, pass a dictionary to the first argument, because a colon ( : ) can't be in keyword arguments. params = { \"hidden_sizes:0\": 10, # Order is important. \"hidden_sizes:1\": 20, # Start from 0. \"hidden_sizes:2\": 30, # No skip. No reverse. } run = experiment.create_run(params) run.model [12] 2020-05-30 16:20:45 ( 43.0ms ) python3 ( 6.73s ) Model( (layers): ModuleList( (0): Linear(in_features=2, out_features=10, bias=True) (1): Linear(in_features=10, out_features=20, bias=True) (2): Linear(in_features=20, out_features=30, bias=True) (3): Linear(in_features=30, out_features=1, bias=True) ) ) Do you feel this method is unnecessary? This method is prepared for hyperparameter tuning . In some case, you may want to change a part of list. Use 0-indexed dot-notation . params = {\"hidden_sizes.1\": 5} run = experiment.create_run(params) run.model [13] 2020-05-30 16:20:45 ( 44.0ms ) python3 ( 6.77s ) Model( (layers): ModuleList( (0): Linear(in_features=2, out_features=20, bias=True) (1): Linear(in_features=20, out_features=5, bias=True) (2): Linear(in_features=5, out_features=1, bias=True) ) ) Duplicated parameter name Duplicated parameters with the same name are updated together. run = experiment.create_run(patience=5) run.scheduler.patience, run.early_stopping.patience [14] 2020-05-30 16:20:45 ( 44.0ms ) python3 ( 6.82s ) (5, 5) This behavior is natural to update the parameters with the same meaning. But in the above example, the patience of early stopping becomes equal to that of scheduler, so the scheduler doesn't work at all. Scoping by dots To specify an individual parameter even if there are other parameters with the same name, use scoping by dots, or parameter fullname . params = {'scheduler.patience': 8, 'early_stopping.patience': 20} run = experiment.create_run(params) run.scheduler.patience, run.early_stopping.patience [15] 2020-05-30 16:20:45 ( 48.0ms ) python3 ( 6.86s ) (8, 20) Object type Parameters are not limited to a literal such as int , float , or str . For example, run = experiment.create_run() run.optimizer [16] 2020-05-30 16:20:45 ( 50.0ms ) python3 ( 6.91s ) SGD ( Parameter Group 0 dampening: 0 lr: 0.001 momentum: 0 nesterov: False weight_decay: 0 ) run = experiment.create_run({'optimizer.class': 'torch.optim.Adam'}) run.optimizer [17] 2020-05-30 16:20:45 ( 54.0ms ) python3 ( 6.97s ) Adam ( Parameter Group 0 amsgrad: False betas: (0.9, 0.999) eps: 1e-08 lr: 0.001 weight_decay: 0 ) This means that you can compare optimizer algorithms easily through multiple runs with minimul effort. Creating a run from a client In the above examples, we created runs using the experiment.create_run() method. In addtion, you can do the same thing by client.create_run() with an experiment name as the first argument. The following code blocks are equivalent. Code 1 experiment = client.create_experiment('torch') run = experiment.create_run(fold=3) Code 2 run = client.create_run('torch', fold=3)","title":"<span class=\"pheasant-header\"><span class=\"header\"><span class=\"title\">Ivory Core Entities</span></span></span>"},{"location":"tutorial/core/#ivory-core-entities","text":"","title":"Ivory Core Entities"},{"location":"tutorial/core/#client","text":"Ivory has the Client class that manages the workflow of machine learning. In this tutorial, we are working with data and model to predict rectangle area. The source module exists under the examples directory. First, create a Client instance. import ivory client = ivory.create_client(\"examples\") # Set the working directory client [3] 2020-05-30 16:20:45 ( 6.00ms ) python3 ( 6.31s ) Client(num_objects=2) list(client) [4] 2020-05-30 16:20:45 ( 3.00ms ) python3 ( 6.31s ) ['tracker', 'tuner'] The first object is a Tracker instance which connects Ivory to MLFlow Tracking . The second objects is named tuner . A Tuner instance connects Ivory to Optuna . Show files in the working directory examples . import os os.listdir('examples') [5] 2020-05-30 16:20:45 ( 5.00ms ) python3 ( 6.32s ) ['.coverage', 'client.yml', 'lgb.yml', 'mlruns', 'rectangle', 'rfr.yml', 'ridge.yml', 'study.yml', 'tf.yml', 'torch.yml'] rectangle is a Python package that contains our examples. YAML files with extension of .yml or possibly .yaml are parameter files to define a machine learning workflow. Basically, one YAML file is corresponding to one Experiment as discussed later, except the client.yml file. A YAML file name without the extension becomes an experiment name. mlruns is a directory automatically created by MLFlow Tracking in which our trained model and callbacks instances are saved. The client.yml is a configuration file for a Client instance. In our case, the file just contains the minimum settings. File 7 client.yml client: tracker: tuner: Note A YAML file for client is not required. If there is no file for client, Ivory creates a default client with a tracker and without a tuner. If you don't need a tracker, for example in debugging, use ivory.create_client(tracker=False) .","title":"Client"},{"location":"tutorial/core/#experiment","text":"The Client.create_experiment() function creates an Experiment instance. If the Client instance has a tracker , an experiment of MLFlow Tracking is also created at the same time if it hasn't existed yet. By cliking an icon ( ) in the below cell, you can see the log. experiment = client.create_experiment('torch') # Read torch.yml as params. experiment [6] 2020-05-30 16:20:45 ( 11.0ms ) python3 ( 6.33s ) [I 200530 16:20:45 tracker:48] A new experiment created with name: 'torch' Experiment(id='1', name='torch', num_objects=1) The ID for this experiment was given by MLFlow Tracking. The Client.create_experiment() function loads a corresponding YAML file to the first argument from the working directory. File 8 torch.yml library: torch datasets: data: class: rectangle.data.Data n_splits: 4 dataset: fold: 0 model: class: rectangle.torch.Model hidden_sizes: [20, 30] optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 1e-3 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: metrics: monitor: metric: val_loss early_stopping: patience: 10 trainer: loss: torch.nn.functional.mse_loss batch_size: 10 epochs: 10 verbose: 2 After loading, the Experiment instance setups the parameters for creating runs later. The parameters are stored in the params attribute. experiment.params [7] 2020-05-30 16:20:45 ( 5.00ms ) python3 ( 6.34s ) {'run': {'datasets': {'data': {'class': 'rectangle.data.Data', 'n_splits': 4}, 'dataset': {'def': 'ivory.torch.data.Dataset'}, 'fold': 0, 'class': 'ivory.core.data.Datasets'}, 'model': {'class': 'rectangle.torch.Model', 'hidden_sizes': [20, 30]}, 'optimizer': {'class': 'torch.optim.SGD', 'params': '$.model.parameters()', 'lr': 0.001}, 'scheduler': {'class': 'torch.optim.lr_scheduler.ReduceLROnPlateau', 'optimizer': '$', 'factor': 0.5, 'patience': 4}, 'results': {'class': 'ivory.torch.results.Results'}, 'metrics': {'class': 'ivory.torch.metrics.Metrics'}, 'monitor': {'metric': 'val_loss', 'class': 'ivory.callbacks.monitor.Monitor'}, 'early_stopping': {'patience': 10, 'class': 'ivory.callbacks.early_stopping.EarlyStopping'}, 'trainer': {'loss': 'torch.nn.functional.mse_loss', 'batch_size': 10, 'epochs': 10, 'verbose': 2, 'class': 'ivory.torch.trainer.Trainer'}, 'class': 'ivory.torch.run.Run'}, 'experiment': {'name': 'torch', 'class': 'ivory.core.base.Experiment', 'id': '1'}} This is similar to the YAML file, but is slightly changed by the Ivory Client. Run and experiment sections are inserted. ExperimentID and RunID are assigned by MLFlow Tracking. Default classes are specified, for example ivory.torch.trainer.Trainer for a trainer instance.","title":"Experiment"},{"location":"tutorial/core/#run","text":"After setting up an Experiment instance, you can create runs with various parameters. Ivory provides several way to configure them as below.","title":"Run"},{"location":"tutorial/core/#default-parameters","text":"Calling without arguments creates a run with default parameters. run = experiment.create_run() run [8] 2020-05-30 16:20:45 ( 37.0ms ) python3 ( 6.37s ) Run(id='47becf3f67e4433791b46a9eea73b8e4', name='run#0', num_objects=12) Here, the ID for this run is given by MLFlow Tracking. On the other hand, the name is given by Ivory as a form of \" (run class name in lower case)#(run number) \".","title":"Default parameters"},{"location":"tutorial/core/#simple-literal-int-float-str","text":"Passing key-value pairs, you can change the parameters. run = experiment.create_run(fold=1) run.datasets.fold [9] 2020-05-30 16:20:45 ( 36.0ms ) python3 ( 6.41s ) 1 But the type of parameter must be equal, otherwise a ValueError is raised. run = experiment.create_run(fold=0.5) run.datasets.fold [10] 2020-05-30 16:20:45 ( 141ms ) python3 ( 6.55s ) ValueError: different type: <class 'int'> != <class 'float'> ValueError Traceback (most recent call last) <ipython-input-100-db3b6dd1af57> in <module> ----> 1 run = experiment.create_run(fold=0.5) 2 run.datasets.fold ~\\Documents\\github\\ivory\\ivory\\core\\base.py in create_run(self, args, name, **kwargs) 55 56 def create_run(self, args=None, name: str = \"run\", **kwargs): ---> 57 params, args = self.create_params(args, name, **kwargs) 58 run = instance.create_base_instance(params, name, self.source_name) 59 if self.tracker: ~\\Documents\\github\\ivory\\ivory\\core\\base.py in create_params(self, args, name, **kwargs) 51 params.update(default.get(name)) 52 update, args = utils.params.create_update(params[name], args, **kwargs) ---> 53 utils.params.update_dict(params[name], update) 54 return params, args 55 ~\\Documents\\github\\ivory\\ivory\\utils\\params.py in update_dict(org, update) 28 x[k] = value 29 elif type(x[k]) is not type(value) and x[k] is not None: ---> 30 raise ValueError(f\"different type: {type(x[k])} != {type(value)}\") 31 else: 32 if isinstance(x[k], dict):","title":"Simple literal (int, float, str)"},{"location":"tutorial/core/#list","text":"A list parameter can be overwritten by passing a new list. Off course you can change the lengh of the list. The original hidden_sizes was [10, 20] . run = experiment.create_run(hidden_sizes=[2, 3, 4]) run.model [11] 2020-05-30 16:20:45 ( 137ms ) python3 ( 6.69s ) Model( (layers): ModuleList( (0): Linear(in_features=2, out_features=2, bias=True) (1): Linear(in_features=2, out_features=3, bias=True) (2): Linear(in_features=3, out_features=4, bias=True) (3): Linear(in_features=4, out_features=1, bias=True) ) ) As an alternative way, you can use 0-indexed colon-notation like below. In this case, pass a dictionary to the first argument, because a colon ( : ) can't be in keyword arguments. params = { \"hidden_sizes:0\": 10, # Order is important. \"hidden_sizes:1\": 20, # Start from 0. \"hidden_sizes:2\": 30, # No skip. No reverse. } run = experiment.create_run(params) run.model [12] 2020-05-30 16:20:45 ( 43.0ms ) python3 ( 6.73s ) Model( (layers): ModuleList( (0): Linear(in_features=2, out_features=10, bias=True) (1): Linear(in_features=10, out_features=20, bias=True) (2): Linear(in_features=20, out_features=30, bias=True) (3): Linear(in_features=30, out_features=1, bias=True) ) ) Do you feel this method is unnecessary? This method is prepared for hyperparameter tuning . In some case, you may want to change a part of list. Use 0-indexed dot-notation . params = {\"hidden_sizes.1\": 5} run = experiment.create_run(params) run.model [13] 2020-05-30 16:20:45 ( 44.0ms ) python3 ( 6.77s ) Model( (layers): ModuleList( (0): Linear(in_features=2, out_features=20, bias=True) (1): Linear(in_features=20, out_features=5, bias=True) (2): Linear(in_features=5, out_features=1, bias=True) ) )","title":"List"},{"location":"tutorial/core/#duplicated-parameter-name","text":"Duplicated parameters with the same name are updated together. run = experiment.create_run(patience=5) run.scheduler.patience, run.early_stopping.patience [14] 2020-05-30 16:20:45 ( 44.0ms ) python3 ( 6.82s ) (5, 5) This behavior is natural to update the parameters with the same meaning. But in the above example, the patience of early stopping becomes equal to that of scheduler, so the scheduler doesn't work at all.","title":"Duplicated parameter name"},{"location":"tutorial/core/#scoping-by-dots","text":"To specify an individual parameter even if there are other parameters with the same name, use scoping by dots, or parameter fullname . params = {'scheduler.patience': 8, 'early_stopping.patience': 20} run = experiment.create_run(params) run.scheduler.patience, run.early_stopping.patience [15] 2020-05-30 16:20:45 ( 48.0ms ) python3 ( 6.86s ) (8, 20)","title":"Scoping by dots"},{"location":"tutorial/core/#object-type","text":"Parameters are not limited to a literal such as int , float , or str . For example, run = experiment.create_run() run.optimizer [16] 2020-05-30 16:20:45 ( 50.0ms ) python3 ( 6.91s ) SGD ( Parameter Group 0 dampening: 0 lr: 0.001 momentum: 0 nesterov: False weight_decay: 0 ) run = experiment.create_run({'optimizer.class': 'torch.optim.Adam'}) run.optimizer [17] 2020-05-30 16:20:45 ( 54.0ms ) python3 ( 6.97s ) Adam ( Parameter Group 0 amsgrad: False betas: (0.9, 0.999) eps: 1e-08 lr: 0.001 weight_decay: 0 ) This means that you can compare optimizer algorithms easily through multiple runs with minimul effort.","title":"Object type"},{"location":"tutorial/core/#creating-a-run-from-a-client","text":"In the above examples, we created runs using the experiment.create_run() method. In addtion, you can do the same thing by client.create_run() with an experiment name as the first argument. The following code blocks are equivalent. Code 1 experiment = client.create_experiment('torch') run = experiment.create_run(fold=3) Code 2 run = client.create_run('torch', fold=3)","title":"Creating a run from a client"},{"location":"tutorial/data/","text":"Set of Data classes Ivory uses three classes for data presentation: Data , Dataset , and Datasets . In this tutorial, we use the following Python module to explain them. File 5 rectangle/data.py from dataclasses import dataclass import numpy as np import ivory.core.data from ivory.utils.fold import kfold_split def create_data(num_samples=1000): xy = 4 * np.random.rand(num_samples, 2) + 1 xy = xy.astype(np.float32) dx = 0.1 * (np.random.rand(num_samples) - 0.5) dy = 0.1 * (np.random.rand(num_samples) - 0.5) z = ((xy[:, 0] + dx) * (xy[:, 1] + dy)).astype(np.float32) return xy, z @dataclass(repr=False) class Data(ivory.core.data.Data): n_splits: int = 4 DATA = create_data(1000) # Shared by each run. def init(self): # Called from self.__post_init__() self.input, self.target = self.DATA self.index = np.arange(len(self.input)) # Extra fold for test data. self.fold = kfold_split(self.input, n_splits=self.n_splits + 1) # Creating dummy test data just for demonstration. is_test = self.fold == self.n_splits # Use an extra fold. self.fold[is_test] = -1 # -1 for test data. self.target = self.target.copy() # n_splits may be different among runs. self.target[is_test] = np.nan # Delete target for test data. self.target = self.target.reshape(-1, 1) # (sample, class) def transform(mode, input, target): return input, target.reshape(-1) Data Class First import the module and check the basic behavior. import rectangle.data data = rectangle.data.Data() data [2] 2020-05-30 16:20:45 ( 5.00ms ) python3 ( 6.99s ) Data(train_size=800, test_size=200) In the Data.init() method, we need to define 4 attributes: index : Index of samples. input : Input data. target : Target data. fold : Fold number. A Data.get() method returns a tuple of ( index , input , target ). This method is called from the Dataset instance when the dataset is indexed. data.get(0) # Integer index. [3] 2020-05-30 16:20:46 ( 4.00ms ) python3 ( 6.99s ) (0, array([4.8919764, 1.1556569], dtype=float32), array([5.668457], dtype=float32)) data.get([0, 10, 20]) # Array-like index. list or np.ndarray [4] 2020-05-30 16:20:46 ( 4.00ms ) python3 ( 6.99s ) (array([ 0, 10, 20]), array([[4.8919764, 1.1556569], [3.8314247, 2.5422974], [3.243608 , 1.969316 ]], dtype=float32), array([[5.668457 ], [9.6129675], [6.432041 ]], dtype=float32)) Dataset An instance of the Dataset class holds one of train, validation, and test dataset. We use the Ivory's default Dataset class here instead of defining a subclass. The Dataset() initializer requires three arguments: A Data instance, mode , and fold . import ivory.core.data dataset = ivory.core.data.Dataset(data, 'train', 0) dataset [5] 2020-05-30 16:20:46 ( 4.00ms ) python3 ( 7.00s ) Dataset(mode='train', num_samples=600) ivory.core.data.Dataset(data, 'val', 1) # Another mode is `test`. [6] 2020-05-30 16:20:46 ( 5.00ms ) python3 ( 7.00s ) Dataset(mode='val', num_samples=200) As the Data class, the Dataset class has a init() method without any arguments and no returned value. You can define any code to modify data. To get data from an dataset. use normal indexing dataset[0] # Integer index. [7] 2020-05-30 16:20:46 ( 4.00ms ) python3 ( 7.01s ) (0, array([4.8919764, 1.1556569], dtype=float32), array([5.668457], dtype=float32)) dataset[[0, 10, 20]] # Array-like index. list or np.ndarray [8] 2020-05-30 16:20:46 ( 6.00ms ) python3 ( 7.01s ) (array([ 0, 16, 33]), array([[4.8919764, 1.1556569], [2.945102 , 2.2920632], [2.292177 , 3.0083516]], dtype=float32), array([[5.668457 ], [6.816285 ], [6.7992034]], dtype=float32)) index, *_ = dataset[:] # Get all data. print(len(index)) index[:10] [9] 2020-05-30 16:20:46 ( 6.00ms ) python3 ( 7.02s ) 600 array([ 0, 2, 3, 4, 6, 7, 10, 12, 13, 15]) These data come from a subset of the data instance according to the mode and fold. The Dataset class takes an opptional and callable argument: transform . def transform(mode: str, input, target): if mode == 'train': input = input * 2 target = target * 2 return input, target dataset_transformed = ivory.core.data.Dataset(data, 'train', 0, transform) dataset_transformed[0] [10] 2020-05-30 16:20:46 ( 5.00ms ) python3 ( 7.02s ) (0, array([9.783953 , 2.3113139], dtype=float32), array([11.336914], dtype=float32)) 2 * dataset[0][1], 2 * dataset[0][2] [11] 2020-05-30 16:20:46 ( 4.00ms ) python3 ( 7.03s ) (array([9.783953 , 2.3113139], dtype=float32), array([11.336914], dtype=float32)) Usually, we don't instantiate the Dataset class directly. Instead, the Datasets class create dataset instances. Datasets An instance of the Datasets class holds a set of train, validation, and test dataset. We use the Ivory's default Datasets class here instead of defining a subclass. The Datasets() initializer requires three arguments: A Data instance, Dataset factory, and fold . from ivory.core.data import Dataset datasets = ivory.core.data.Datasets(data, Dataset, 0) datasets [12] 2020-05-30 16:20:46 ( 4.00ms ) python3 ( 7.03s ) Datasets(data=Data(train_size=800, test_size=200), dataset=<class 'ivory.core.data.Dataset'>, fold=0) Note The second argument ( dataset ) is not a Dataset instance but its factory that returns a Dataset instance. It may be a Dataset class itself or any function that returns a Dataset instance. for mode, dataset in datasets.items(): print(mode, dataset) [13] 2020-05-30 16:20:46 ( 7.00ms ) python3 ( 7.04s ) train Dataset(mode='train', num_samples=600) val Dataset(mode='val', num_samples=200) test Dataset(mode='test', num_samples=200) Each dataset can be accessed by indexing or attributes. datasets['train'], datasets.val [14] 2020-05-30 16:20:46 ( 4.00ms ) python3 ( 7.04s ) (Dataset(mode='train', num_samples=600), Dataset(mode='val', num_samples=200)) Using the Datasets class, we can easily split a whole data stored in a Data instance into three train, validation, and test dataset.","title":"<span class=\"pheasant-header\"><span class=\"header\"><span class=\"title\">Set of Data classes</span></span></span>"},{"location":"tutorial/data/#set-of-data-classes","text":"Ivory uses three classes for data presentation: Data , Dataset , and Datasets . In this tutorial, we use the following Python module to explain them. File 5 rectangle/data.py from dataclasses import dataclass import numpy as np import ivory.core.data from ivory.utils.fold import kfold_split def create_data(num_samples=1000): xy = 4 * np.random.rand(num_samples, 2) + 1 xy = xy.astype(np.float32) dx = 0.1 * (np.random.rand(num_samples) - 0.5) dy = 0.1 * (np.random.rand(num_samples) - 0.5) z = ((xy[:, 0] + dx) * (xy[:, 1] + dy)).astype(np.float32) return xy, z @dataclass(repr=False) class Data(ivory.core.data.Data): n_splits: int = 4 DATA = create_data(1000) # Shared by each run. def init(self): # Called from self.__post_init__() self.input, self.target = self.DATA self.index = np.arange(len(self.input)) # Extra fold for test data. self.fold = kfold_split(self.input, n_splits=self.n_splits + 1) # Creating dummy test data just for demonstration. is_test = self.fold == self.n_splits # Use an extra fold. self.fold[is_test] = -1 # -1 for test data. self.target = self.target.copy() # n_splits may be different among runs. self.target[is_test] = np.nan # Delete target for test data. self.target = self.target.reshape(-1, 1) # (sample, class) def transform(mode, input, target): return input, target.reshape(-1)","title":"Set of Data classes"},{"location":"tutorial/data/#data-class","text":"First import the module and check the basic behavior. import rectangle.data data = rectangle.data.Data() data [2] 2020-05-30 16:20:45 ( 5.00ms ) python3 ( 6.99s ) Data(train_size=800, test_size=200) In the Data.init() method, we need to define 4 attributes: index : Index of samples. input : Input data. target : Target data. fold : Fold number. A Data.get() method returns a tuple of ( index , input , target ). This method is called from the Dataset instance when the dataset is indexed. data.get(0) # Integer index. [3] 2020-05-30 16:20:46 ( 4.00ms ) python3 ( 6.99s ) (0, array([4.8919764, 1.1556569], dtype=float32), array([5.668457], dtype=float32)) data.get([0, 10, 20]) # Array-like index. list or np.ndarray [4] 2020-05-30 16:20:46 ( 4.00ms ) python3 ( 6.99s ) (array([ 0, 10, 20]), array([[4.8919764, 1.1556569], [3.8314247, 2.5422974], [3.243608 , 1.969316 ]], dtype=float32), array([[5.668457 ], [9.6129675], [6.432041 ]], dtype=float32))","title":"Data Class"},{"location":"tutorial/data/#dataset","text":"An instance of the Dataset class holds one of train, validation, and test dataset. We use the Ivory's default Dataset class here instead of defining a subclass. The Dataset() initializer requires three arguments: A Data instance, mode , and fold . import ivory.core.data dataset = ivory.core.data.Dataset(data, 'train', 0) dataset [5] 2020-05-30 16:20:46 ( 4.00ms ) python3 ( 7.00s ) Dataset(mode='train', num_samples=600) ivory.core.data.Dataset(data, 'val', 1) # Another mode is `test`. [6] 2020-05-30 16:20:46 ( 5.00ms ) python3 ( 7.00s ) Dataset(mode='val', num_samples=200) As the Data class, the Dataset class has a init() method without any arguments and no returned value. You can define any code to modify data. To get data from an dataset. use normal indexing dataset[0] # Integer index. [7] 2020-05-30 16:20:46 ( 4.00ms ) python3 ( 7.01s ) (0, array([4.8919764, 1.1556569], dtype=float32), array([5.668457], dtype=float32)) dataset[[0, 10, 20]] # Array-like index. list or np.ndarray [8] 2020-05-30 16:20:46 ( 6.00ms ) python3 ( 7.01s ) (array([ 0, 16, 33]), array([[4.8919764, 1.1556569], [2.945102 , 2.2920632], [2.292177 , 3.0083516]], dtype=float32), array([[5.668457 ], [6.816285 ], [6.7992034]], dtype=float32)) index, *_ = dataset[:] # Get all data. print(len(index)) index[:10] [9] 2020-05-30 16:20:46 ( 6.00ms ) python3 ( 7.02s ) 600 array([ 0, 2, 3, 4, 6, 7, 10, 12, 13, 15]) These data come from a subset of the data instance according to the mode and fold. The Dataset class takes an opptional and callable argument: transform . def transform(mode: str, input, target): if mode == 'train': input = input * 2 target = target * 2 return input, target dataset_transformed = ivory.core.data.Dataset(data, 'train', 0, transform) dataset_transformed[0] [10] 2020-05-30 16:20:46 ( 5.00ms ) python3 ( 7.02s ) (0, array([9.783953 , 2.3113139], dtype=float32), array([11.336914], dtype=float32)) 2 * dataset[0][1], 2 * dataset[0][2] [11] 2020-05-30 16:20:46 ( 4.00ms ) python3 ( 7.03s ) (array([9.783953 , 2.3113139], dtype=float32), array([11.336914], dtype=float32)) Usually, we don't instantiate the Dataset class directly. Instead, the Datasets class create dataset instances.","title":"Dataset"},{"location":"tutorial/data/#datasets","text":"An instance of the Datasets class holds a set of train, validation, and test dataset. We use the Ivory's default Datasets class here instead of defining a subclass. The Datasets() initializer requires three arguments: A Data instance, Dataset factory, and fold . from ivory.core.data import Dataset datasets = ivory.core.data.Datasets(data, Dataset, 0) datasets [12] 2020-05-30 16:20:46 ( 4.00ms ) python3 ( 7.03s ) Datasets(data=Data(train_size=800, test_size=200), dataset=<class 'ivory.core.data.Dataset'>, fold=0) Note The second argument ( dataset ) is not a Dataset instance but its factory that returns a Dataset instance. It may be a Dataset class itself or any function that returns a Dataset instance. for mode, dataset in datasets.items(): print(mode, dataset) [13] 2020-05-30 16:20:46 ( 7.00ms ) python3 ( 7.04s ) train Dataset(mode='train', num_samples=600) val Dataset(mode='val', num_samples=200) test Dataset(mode='test', num_samples=200) Each dataset can be accessed by indexing or attributes. datasets['train'], datasets.val [14] 2020-05-30 16:20:46 ( 4.00ms ) python3 ( 7.04s ) (Dataset(mode='train', num_samples=600), Dataset(mode='val', num_samples=200)) Using the Datasets class, we can easily split a whole data stored in a Data instance into three train, validation, and test dataset.","title":"Datasets"},{"location":"tutorial/instance/","text":"Creating Instances In this tutorial, we will learn about Ivory's internal instance creation system. This is worth to understand the way of writing a YAML file for machine learning. Basic idea A syntax to create an instance is similar to a dictionary. example = ExampleCalss(arg1=123, arg2='abc') can be equivalently written as {'example': {'class': 'ExampleCalss', 'args1': 123, 'arg2': 'abc'}} Ivory excactly uses this relationship. from ivory.core.instance import create_instance params = {'data': {'class': 'rectangle.data.Data', 'n_splits': 5}} data = create_instance(params, 'data') data [2] 2020-05-30 16:20:46 ( 5.00ms ) python3 ( 7.06s ) Data(train_size=834, test_size=166) Here, the create_instance() function requires the second argument name to specify a key because the first argument params can have multiple keys. Note that we added a n_splits parameter which is different from the default value 5. Let's see unique values of fold. import numpy as np np.unique(data.fold) # 5-fold for train and 1-fold for test. [3] 2020-05-30 16:20:46 ( 5.00ms ) python3 ( 7.06s ) array([-1, 0, 1, 2, 3, 4], dtype=int8) For writing a dictionary easily, we use PyYAML library . import yaml # A helper function. def create(doc, name, **kwargs): params = yaml.safe_load(doc) return create_instance(params, name, **kwargs) doc = \"\"\" data: class: rectangle.data.Data n_splits: 5 \"\"\" create(doc, 'data') [4] 2020-05-30 16:20:46 ( 6.00ms ) python3 ( 7.07s ) Data(train_size=834, test_size=166) Hierarchal Structure Next create a Dataset instance. The Dataset class requires a Data instance as the first argument so that the corresponding dictionary have hierarchal structure. doc = \"\"\" dataset: class: ivory.core.data.Dataset data: class: rectangle.data.Data n_splits: 5 mode: train fold: 0 \"\"\" create(doc, 'dataset') [5] 2020-05-30 16:20:46 ( 5.00ms ) python3 ( 7.08s ) Dataset(mode='train', num_samples=667) As you can see, Ivory can treat this hierarchal structure correctly. Next, create a Datasets instance. doc = \"\"\" datasets: class: ivory.core.data.Datasets data: class: rectangle.data.Data n_splits: 5 dataset: def: ivory.core.data.Dataset fold: 0 \"\"\" create(doc, 'datasets') [6] 2020-05-30 16:20:46 ( 7.00ms ) python3 ( 7.08s ) Datasets(data=Data(train_size=834, test_size=166), dataset=<class 'ivory.core.data.Dataset'>, fold=0) Remember that the argument dataset for the Datasets class is not an instance but a callable that returns a Dataset instance (See the previous section ). To describe this behavior, we use a new def key instead of class to create a callable. Default Class In the above example, the two lines using an Ivory's original class seems to be verbose a little bit. Ivory adds a default class if the class or def key is missing. Here is the list of default classes prepared by Ivory: from ivory.core.default import DEFAULT_CLASS for library, values in DEFAULT_CLASS.items(): print(f'library: {library}') for name, value in values.items(): print(\" \", name, \"---\", value) [7] 2020-05-30 16:20:46 ( 69.0ms ) python3 ( 7.15s ) library: core client --- ivory.core.client.Client tracker --- ivory.core.tracker.Tracker tuner --- ivory.core.tuner.Tuner experiment --- ivory.core.base.Experiment objective --- ivory.core.objective.Objective run --- ivory.core.run.Run task --- ivory.core.run.Task study --- ivory.core.run.Study dataset --- ivory.core.data.Dataset datasets --- ivory.core.data.Datasets results --- ivory.callbacks.results.Results metrics --- ivory.callbacks.metrics.Metrics monitor --- ivory.callbacks.monitor.Monitor early_stopping --- ivory.callbacks.early_stopping.EarlyStopping library: torch run --- ivory.torch.run.Run dataset --- ivory.torch.data.Dataset results --- ivory.torch.results.Results metrics --- ivory.torch.metrics.Metrics trainer --- ivory.torch.trainer.Trainer library: tensorflow run --- ivory.tensorflow.run.Run trainer --- ivory.tensorflow.trainer.Trainer library: sklearn estimator --- ivory.sklearn.estimator.Estimator metrics --- ivory.sklearn.metrics.Metrics Therefore, we can omit the lines using default classes like below. Here, the library key is used to overload the default classes of the ivory.core package by the specific library. import torch.utils.data doc = \"\"\" library: torch # Use default class for PyTorch. datasets: data: class: rectangle.data.Data n_splits: 5 dataset: fold: 0 \"\"\" datasets = create(doc, 'datasets') isinstance(datasets.train, torch.utils.data.Dataset) [8] 2020-05-30 16:20:46 ( 7.00ms ) python3 ( 7.16s ) True Default Value If a callable has arguments with default value, you can use __default__ to get default values from the callable signature. doc = \"\"\" datasets: data: class: rectangle.data.Data n_splits: __default__ dataset: fold: 0 \"\"\" datasets = create(doc, 'datasets') datasets.data.n_splits [9] 2020-05-30 16:20:46 ( 6.00ms ) python3 ( 7.16s ) 4 Positional Arguments Do you know the name of the first argument of the numpy.array() function? import numpy as np print(np.array.__doc__[:200]) [10] 2020-05-30 16:20:46 ( 5.00ms ) python3 ( 7.17s ) array(object, dtype=None, copy=True, order='K', subok=False, ndmin=0) Create an array. Parameters ---------- object : array_like An array, any object exposing the array inter It's object . But do you want to write like this? doc = \"\"\" x: class: numpy.array # Or `call` instead of `class`. object: [1, 2, 3] \"\"\" create(doc, 'x') [11] 2020-05-30 16:20:46 ( 4.00ms ) python3 ( 7.17s ) array([1, 2, 3]) This is inconvinient and ugly. Use underscore-notation : doc = \"\"\" x: class: numpy.array _: [1, 2, 3] \"\"\" create(doc, 'x') [12] 2020-05-30 16:20:46 ( 4.00ms ) python3 ( 7.18s ) array([1, 2, 3]) The second argument of numpy.array() is dtype . You can also use double underscore , which is unpacked. doc = \"\"\" x: call: numpy.array __: [[1, 2, 3], 'float'] \"\"\" create(doc, 'x') [13] 2020-05-30 16:20:46 ( 4.00ms ) python3 ( 7.18s ) array([1., 2., 3.])","title":"<span class=\"pheasant-header\"><span class=\"header\"><span class=\"title\">Creating Instances</span></span></span>"},{"location":"tutorial/instance/#creating-instances","text":"In this tutorial, we will learn about Ivory's internal instance creation system. This is worth to understand the way of writing a YAML file for machine learning.","title":"Creating Instances"},{"location":"tutorial/instance/#basic-idea","text":"A syntax to create an instance is similar to a dictionary. example = ExampleCalss(arg1=123, arg2='abc') can be equivalently written as {'example': {'class': 'ExampleCalss', 'args1': 123, 'arg2': 'abc'}} Ivory excactly uses this relationship. from ivory.core.instance import create_instance params = {'data': {'class': 'rectangle.data.Data', 'n_splits': 5}} data = create_instance(params, 'data') data [2] 2020-05-30 16:20:46 ( 5.00ms ) python3 ( 7.06s ) Data(train_size=834, test_size=166) Here, the create_instance() function requires the second argument name to specify a key because the first argument params can have multiple keys. Note that we added a n_splits parameter which is different from the default value 5. Let's see unique values of fold. import numpy as np np.unique(data.fold) # 5-fold for train and 1-fold for test. [3] 2020-05-30 16:20:46 ( 5.00ms ) python3 ( 7.06s ) array([-1, 0, 1, 2, 3, 4], dtype=int8) For writing a dictionary easily, we use PyYAML library . import yaml # A helper function. def create(doc, name, **kwargs): params = yaml.safe_load(doc) return create_instance(params, name, **kwargs) doc = \"\"\" data: class: rectangle.data.Data n_splits: 5 \"\"\" create(doc, 'data') [4] 2020-05-30 16:20:46 ( 6.00ms ) python3 ( 7.07s ) Data(train_size=834, test_size=166)","title":"Basic idea"},{"location":"tutorial/instance/#hierarchal-structure","text":"Next create a Dataset instance. The Dataset class requires a Data instance as the first argument so that the corresponding dictionary have hierarchal structure. doc = \"\"\" dataset: class: ivory.core.data.Dataset data: class: rectangle.data.Data n_splits: 5 mode: train fold: 0 \"\"\" create(doc, 'dataset') [5] 2020-05-30 16:20:46 ( 5.00ms ) python3 ( 7.08s ) Dataset(mode='train', num_samples=667) As you can see, Ivory can treat this hierarchal structure correctly. Next, create a Datasets instance. doc = \"\"\" datasets: class: ivory.core.data.Datasets data: class: rectangle.data.Data n_splits: 5 dataset: def: ivory.core.data.Dataset fold: 0 \"\"\" create(doc, 'datasets') [6] 2020-05-30 16:20:46 ( 7.00ms ) python3 ( 7.08s ) Datasets(data=Data(train_size=834, test_size=166), dataset=<class 'ivory.core.data.Dataset'>, fold=0) Remember that the argument dataset for the Datasets class is not an instance but a callable that returns a Dataset instance (See the previous section ). To describe this behavior, we use a new def key instead of class to create a callable.","title":"Hierarchal Structure"},{"location":"tutorial/instance/#default-class","text":"In the above example, the two lines using an Ivory's original class seems to be verbose a little bit. Ivory adds a default class if the class or def key is missing. Here is the list of default classes prepared by Ivory: from ivory.core.default import DEFAULT_CLASS for library, values in DEFAULT_CLASS.items(): print(f'library: {library}') for name, value in values.items(): print(\" \", name, \"---\", value) [7] 2020-05-30 16:20:46 ( 69.0ms ) python3 ( 7.15s ) library: core client --- ivory.core.client.Client tracker --- ivory.core.tracker.Tracker tuner --- ivory.core.tuner.Tuner experiment --- ivory.core.base.Experiment objective --- ivory.core.objective.Objective run --- ivory.core.run.Run task --- ivory.core.run.Task study --- ivory.core.run.Study dataset --- ivory.core.data.Dataset datasets --- ivory.core.data.Datasets results --- ivory.callbacks.results.Results metrics --- ivory.callbacks.metrics.Metrics monitor --- ivory.callbacks.monitor.Monitor early_stopping --- ivory.callbacks.early_stopping.EarlyStopping library: torch run --- ivory.torch.run.Run dataset --- ivory.torch.data.Dataset results --- ivory.torch.results.Results metrics --- ivory.torch.metrics.Metrics trainer --- ivory.torch.trainer.Trainer library: tensorflow run --- ivory.tensorflow.run.Run trainer --- ivory.tensorflow.trainer.Trainer library: sklearn estimator --- ivory.sklearn.estimator.Estimator metrics --- ivory.sklearn.metrics.Metrics Therefore, we can omit the lines using default classes like below. Here, the library key is used to overload the default classes of the ivory.core package by the specific library. import torch.utils.data doc = \"\"\" library: torch # Use default class for PyTorch. datasets: data: class: rectangle.data.Data n_splits: 5 dataset: fold: 0 \"\"\" datasets = create(doc, 'datasets') isinstance(datasets.train, torch.utils.data.Dataset) [8] 2020-05-30 16:20:46 ( 7.00ms ) python3 ( 7.16s ) True","title":"Default Class"},{"location":"tutorial/instance/#default-value","text":"If a callable has arguments with default value, you can use __default__ to get default values from the callable signature. doc = \"\"\" datasets: data: class: rectangle.data.Data n_splits: __default__ dataset: fold: 0 \"\"\" datasets = create(doc, 'datasets') datasets.data.n_splits [9] 2020-05-30 16:20:46 ( 6.00ms ) python3 ( 7.16s ) 4","title":"Default Value"},{"location":"tutorial/instance/#positional-arguments","text":"Do you know the name of the first argument of the numpy.array() function? import numpy as np print(np.array.__doc__[:200]) [10] 2020-05-30 16:20:46 ( 5.00ms ) python3 ( 7.17s ) array(object, dtype=None, copy=True, order='K', subok=False, ndmin=0) Create an array. Parameters ---------- object : array_like An array, any object exposing the array inter It's object . But do you want to write like this? doc = \"\"\" x: class: numpy.array # Or `call` instead of `class`. object: [1, 2, 3] \"\"\" create(doc, 'x') [11] 2020-05-30 16:20:46 ( 4.00ms ) python3 ( 7.17s ) array([1, 2, 3]) This is inconvinient and ugly. Use underscore-notation : doc = \"\"\" x: class: numpy.array _: [1, 2, 3] \"\"\" create(doc, 'x') [12] 2020-05-30 16:20:46 ( 4.00ms ) python3 ( 7.18s ) array([1, 2, 3]) The second argument of numpy.array() is dtype . You can also use double underscore , which is unpacked. doc = \"\"\" x: call: numpy.array __: [[1, 2, 3], 'float'] \"\"\" create(doc, 'x') [13] 2020-05-30 16:20:46 ( 4.00ms ) python3 ( 7.18s ) array([1., 2., 3.])","title":"Positional Arguments"},{"location":"tutorial/library/","text":"Library Comparison So far, we have used PyTorch in this tutorial, but Ivory can perform machine learning with other libraries. PyTorch vs TensorFlow In this section we compare two libraries and show that using different libraries on the same problem is straightforward. First define models: File 14 A Model definition in PyTorch (rectangle/torch.py) import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self, hidden_sizes): super().__init__() layers = [] for in_features, out_features in zip([2] + hidden_sizes, hidden_sizes + [1]): layers.append(nn.Linear(in_features, out_features)) self.layers = nn.ModuleList(layers) def forward(self, x): for layer in self.layers[:-1]: x = F.relu(layer(x)) return self.layers[-1](x) File 15 A Model definition in TensorFlow (rectangle/tf.py) from tensorflow import keras from tensorflow.keras.layers import Dense def create_model(hidden_sizes): layers = [Dense(hidden_sizes[0], activation=\"relu\", input_shape=[2])] for hidden_size in hidden_sizes[1:]: layers.append(Dense(hidden_size, activation=\"relu\")) layers.append(Dense(1)) return keras.Sequential(layers) For simplicity, the TensorFlow model is defined by using the keras.Sequential() , so that we call the create_model() function to get the model. Next, write parameter YAML files: File 16 A parameter YAML for PyTorch (torch.yml) library: torch datasets: data: class: rectangle.data.Data n_splits: 4 dataset: fold: 0 model: class: rectangle.torch.Model hidden_sizes: [20, 30] optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 1e-3 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: metrics: monitor: metric: val_loss early_stopping: patience: 10 trainer: loss: torch.nn.functional.mse_loss batch_size: 10 epochs: 10 verbose: 2 File 17 A parameter YAML for TensorFlow (tf.yml) library: tensorflow datasets: data: class: rectangle.data.Data n_splits: 4 dataset: fold: 0 model: call: rectangle.tf.create_model hidden_sizes: [20, 30] optimizer: class: tensorflow.keras.optimizers.SGD lr: 1e-3 scheduler: class: tensorflow.keras.callbacks.ReduceLROnPlateau factor: 0.5 patience: 4 results: metrics: monitor: metric: val_loss early_stopping: patience: 10 trainer: loss: mse batch_size: 10 epochs: 10 verbose: 2 These YAML files have a very similar structure. The first difference comes from that, in PyTorch, an optimizer needs model parameters at the time of instantiation and a scheduler needs an optimizer too, while, in TensorFlow, an optimizer and scheduler can be instantiated without other related instances. The second difference is loss functions. The Pytorch YAML file writes the fullname, while the TensorFlow one writes an abbreviation. Note The model for TensorFlow is a function. A new call key is used. (But you can use class , too, or call for a class, vice versa, because both a class and function are callable .) Next, create two runs. import ivory client = ivory.create_client(\"examples\") run_torch = client.create_run('torch') run_tf = client.create_run('tf') [3] 2020-05-30 17:26:00 ( 97.0ms ) python3 ( 10.6s ) [I 200530 17:26:00 tracker:48] A new experiment created with name: 'torch' [I 200530 17:26:00 tracker:48] A new experiment created with name: 'tf' For comparison, equalize initial parameters. import torch for w_tf, w_torch in zip(run_tf.model.weights, run_torch.model.parameters()): w_torch.data = torch.tensor(w_tf.numpy().T) [4] 2020-05-30 17:26:01 ( 5.00ms ) python3 ( 10.6s ) Then, start the runs. run_torch.start() [5] 2020-05-30 17:26:01 ( 1.21s ) python3 ( 11.8s ) [epoch#0] loss=13.33 val_loss=7.784 lr=0.001 best [epoch#1] loss=6.305 val_loss=7.778 lr=0.001 best [epoch#2] loss=5.515 val_loss=6.369 lr=0.001 best [epoch#3] loss=4.71 val_loss=5.886 lr=0.001 best [epoch#4] loss=4.232 val_loss=4.678 lr=0.001 best [epoch#5] loss=3.506 val_loss=4.292 lr=0.001 best [epoch#6] loss=2.896 val_loss=3.123 lr=0.001 best [epoch#7] loss=2.278 val_loss=2.46 lr=0.001 best [epoch#8] loss=1.834 val_loss=2.208 lr=0.001 best [epoch#9] loss=1.429 val_loss=1.513 lr=0.001 best run_tf.start() [6] 2020-05-30 17:26:02 ( 2.23s ) python3 ( 14.0s ) [epoch#0] loss=13.49 val_loss=9.111 lr=0.001 best [epoch#1] loss=6.221 val_loss=7.118 lr=0.001 best [epoch#2] loss=5.416 val_loss=6.407 lr=0.001 best [epoch#3] loss=4.803 val_loss=5.532 lr=0.001 best [epoch#4] loss=4.218 val_loss=5.104 lr=0.001 best [epoch#5] loss=3.559 val_loss=3.797 lr=0.001 best [epoch#6] loss=2.76 val_loss=3.151 lr=0.001 best [epoch#7] loss=2.287 val_loss=2.431 lr=0.001 best [epoch#8] loss=1.771 val_loss=2.741 lr=0.001 [epoch#9] loss=1.378 val_loss=1.683 lr=0.001 best Visualize the results: import matplotlib.pyplot as plt # A helper function def plot(run): dataset = run.results.val plt.scatter(dataset.target.reshape(-1), dataset.output.reshape(-1)) plt.xlim(0, 25) plt.ylim(0, 25) plt.xlabel('Target values') plt.ylabel('Predicted values') for run in [run_tf, run_torch]: plot(run) [7] 2020-05-30 17:26:04 ( 85.0ms ) python3 ( 14.1s ) Actual outputs are like below: x = run_tf.datasets.test[:10][1] run_tf.model.predict(x) [8] 2020-05-30 17:26:04 ( 19.0ms ) python3 ( 14.1s ) array([[ 8.49312 ], [ 9.613727], [ 8.36699 ], [ 9.074398], [13.436677], [ 8.843916], [ 4.16133 ], [17.734993], [ 5.145777], [18.288681]], dtype=float32) run_torch.model(torch.tensor(x)) [9] 2020-05-30 17:26:04 ( 5.00ms ) python3 ( 14.1s ) tensor([[ 8.7655], [10.0127], [ 8.7341], [ 9.3584], [13.8856], [ 9.1302], [ 4.3797], [17.9581], [ 5.4108], [18.5158]], grad_fn=<AddmmBackward>) Scikit-learn Ivory can optimize various scikit-learn's estimators. Here are som examples. RandomForestRegressor File 18 A parameter YAML for RandomForestRegressor (rfr.yml) library: sklearn datasets: data: class: rectangle.data.Data n_splits: 4 dataset: transform: rectangle.data.transform fold: 0 estimator: model: sklearn.ensemble.RandomForestRegressor n_estimators: 5 max_depth: 3 results: metrics: The dataset has a transform argument. This function reshapes the target array to match the shape for scikit-learn estimators (1D from 2D). Code 3 rectangle.data.transform() def transform(mode, input, target): return input, target.reshape(-1) There are nothing different to start a run. run = client.create_run('rfr') run.start() [12] 2020-05-30 17:26:04 ( 81.0ms ) python3 ( 14.2s ) [I 200530 17:26:04 tracker:48] A new experiment created with name: 'rfr' [run#0] mse=1.585 Because the RandomForestRegressor estimator has a criterion attribute, the metrics are automatically calculated. Take a look at the outputs. plot(run) [13] 2020-05-30 17:26:04 ( 80.0ms ) python3 ( 14.3s ) Ridge File 19 A parameter YAML for Ridge (ridge.yml) library: sklearn datasets: data: class: rectangle.data.Data n_splits: 4 dataset: transform: rectangle.data.transform fold: 0 estimator: model: sklearn.linear_model.Ridge results: metrics: mse: mse_2: rectangle.metrics.mean_squared_error Because the Ridge estimator has no criterion attribute, you have to specify metrics if you need. A mse key has empty ( None ) value. In this case, the default function ( sklearn.metrics.mean_squared_error() ) is chosen. On the other hand, mse_2 's value is a custom funtion's name: Code 4 rectangle.metrics.mean_squared_error() def mean_squared_error(true, pred): return np.mean((true - pred) ** 2) Although the rectangle.metrics.mean_squared_error() is the same as mse , this functionality allows us to add arbitrary metrics as long as they can be calculated with true and pred values . run = client.create_run('ridge') run.start() # Both metrics would give the same values. [16] 2020-05-30 17:26:10 ( 65.0ms ) python3 ( 14.7s ) [run#1] mse=2.244 mse_2=2.244 plot(run) [17] 2020-05-30 17:26:10 ( 80.0ms ) python3 ( 14.8s ) LightGBM For LightGBM, Ivory implements two estimators: ivory.lightgbm.estimator.Regressor ivory.lightgbm.estimator.Classifier File 20 A parameter YAML for LightGBM (lgb.yml) datasets: data: class: rectangle.data.Data n_splits: 4 dataset: transform: rectangle.data.transform fold: 0 estimator: class: ivory.lightgbm.estimator.Regressor boosting_type: gbdt num_leaves: 10 learning_rate: 0.1 max_depth: 4 num_boost_round: 10 verbose_eval: 2 results: metrics: mse: run = client.create_run('lgb') run.start() [18] 2020-05-30 17:26:10 ( 84.0ms ) python3 ( 14.9s ) [2] training's l2: 15.9601 valid_1's l2: 20.3489 [4] training's l2: 11.0501 valid_1's l2: 14.2388 [6] training's l2: 7.65786 valid_1's l2: 10.0006 [8] training's l2: 5.34303 valid_1's l2: 7.07968 [10] training's l2: 3.75311 valid_1's l2: 5.02458 [run#1] mse=5.025 plot(run) [19] 2020-05-30 17:26:10 ( 90.0ms ) python3 ( 15.0s )","title":"<span class=\"pheasant-header\"><span class=\"header\"><span class=\"title\">Library Comparison</span></span></span>"},{"location":"tutorial/library/#library-comparison","text":"So far, we have used PyTorch in this tutorial, but Ivory can perform machine learning with other libraries.","title":"Library Comparison"},{"location":"tutorial/library/#pytorch-vs-tensorflow","text":"In this section we compare two libraries and show that using different libraries on the same problem is straightforward. First define models: File 14 A Model definition in PyTorch (rectangle/torch.py) import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self, hidden_sizes): super().__init__() layers = [] for in_features, out_features in zip([2] + hidden_sizes, hidden_sizes + [1]): layers.append(nn.Linear(in_features, out_features)) self.layers = nn.ModuleList(layers) def forward(self, x): for layer in self.layers[:-1]: x = F.relu(layer(x)) return self.layers[-1](x) File 15 A Model definition in TensorFlow (rectangle/tf.py) from tensorflow import keras from tensorflow.keras.layers import Dense def create_model(hidden_sizes): layers = [Dense(hidden_sizes[0], activation=\"relu\", input_shape=[2])] for hidden_size in hidden_sizes[1:]: layers.append(Dense(hidden_size, activation=\"relu\")) layers.append(Dense(1)) return keras.Sequential(layers) For simplicity, the TensorFlow model is defined by using the keras.Sequential() , so that we call the create_model() function to get the model. Next, write parameter YAML files: File 16 A parameter YAML for PyTorch (torch.yml) library: torch datasets: data: class: rectangle.data.Data n_splits: 4 dataset: fold: 0 model: class: rectangle.torch.Model hidden_sizes: [20, 30] optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 1e-3 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: metrics: monitor: metric: val_loss early_stopping: patience: 10 trainer: loss: torch.nn.functional.mse_loss batch_size: 10 epochs: 10 verbose: 2 File 17 A parameter YAML for TensorFlow (tf.yml) library: tensorflow datasets: data: class: rectangle.data.Data n_splits: 4 dataset: fold: 0 model: call: rectangle.tf.create_model hidden_sizes: [20, 30] optimizer: class: tensorflow.keras.optimizers.SGD lr: 1e-3 scheduler: class: tensorflow.keras.callbacks.ReduceLROnPlateau factor: 0.5 patience: 4 results: metrics: monitor: metric: val_loss early_stopping: patience: 10 trainer: loss: mse batch_size: 10 epochs: 10 verbose: 2 These YAML files have a very similar structure. The first difference comes from that, in PyTorch, an optimizer needs model parameters at the time of instantiation and a scheduler needs an optimizer too, while, in TensorFlow, an optimizer and scheduler can be instantiated without other related instances. The second difference is loss functions. The Pytorch YAML file writes the fullname, while the TensorFlow one writes an abbreviation. Note The model for TensorFlow is a function. A new call key is used. (But you can use class , too, or call for a class, vice versa, because both a class and function are callable .) Next, create two runs. import ivory client = ivory.create_client(\"examples\") run_torch = client.create_run('torch') run_tf = client.create_run('tf') [3] 2020-05-30 17:26:00 ( 97.0ms ) python3 ( 10.6s ) [I 200530 17:26:00 tracker:48] A new experiment created with name: 'torch' [I 200530 17:26:00 tracker:48] A new experiment created with name: 'tf' For comparison, equalize initial parameters. import torch for w_tf, w_torch in zip(run_tf.model.weights, run_torch.model.parameters()): w_torch.data = torch.tensor(w_tf.numpy().T) [4] 2020-05-30 17:26:01 ( 5.00ms ) python3 ( 10.6s ) Then, start the runs. run_torch.start() [5] 2020-05-30 17:26:01 ( 1.21s ) python3 ( 11.8s ) [epoch#0] loss=13.33 val_loss=7.784 lr=0.001 best [epoch#1] loss=6.305 val_loss=7.778 lr=0.001 best [epoch#2] loss=5.515 val_loss=6.369 lr=0.001 best [epoch#3] loss=4.71 val_loss=5.886 lr=0.001 best [epoch#4] loss=4.232 val_loss=4.678 lr=0.001 best [epoch#5] loss=3.506 val_loss=4.292 lr=0.001 best [epoch#6] loss=2.896 val_loss=3.123 lr=0.001 best [epoch#7] loss=2.278 val_loss=2.46 lr=0.001 best [epoch#8] loss=1.834 val_loss=2.208 lr=0.001 best [epoch#9] loss=1.429 val_loss=1.513 lr=0.001 best run_tf.start() [6] 2020-05-30 17:26:02 ( 2.23s ) python3 ( 14.0s ) [epoch#0] loss=13.49 val_loss=9.111 lr=0.001 best [epoch#1] loss=6.221 val_loss=7.118 lr=0.001 best [epoch#2] loss=5.416 val_loss=6.407 lr=0.001 best [epoch#3] loss=4.803 val_loss=5.532 lr=0.001 best [epoch#4] loss=4.218 val_loss=5.104 lr=0.001 best [epoch#5] loss=3.559 val_loss=3.797 lr=0.001 best [epoch#6] loss=2.76 val_loss=3.151 lr=0.001 best [epoch#7] loss=2.287 val_loss=2.431 lr=0.001 best [epoch#8] loss=1.771 val_loss=2.741 lr=0.001 [epoch#9] loss=1.378 val_loss=1.683 lr=0.001 best Visualize the results: import matplotlib.pyplot as plt # A helper function def plot(run): dataset = run.results.val plt.scatter(dataset.target.reshape(-1), dataset.output.reshape(-1)) plt.xlim(0, 25) plt.ylim(0, 25) plt.xlabel('Target values') plt.ylabel('Predicted values') for run in [run_tf, run_torch]: plot(run) [7] 2020-05-30 17:26:04 ( 85.0ms ) python3 ( 14.1s ) Actual outputs are like below: x = run_tf.datasets.test[:10][1] run_tf.model.predict(x) [8] 2020-05-30 17:26:04 ( 19.0ms ) python3 ( 14.1s ) array([[ 8.49312 ], [ 9.613727], [ 8.36699 ], [ 9.074398], [13.436677], [ 8.843916], [ 4.16133 ], [17.734993], [ 5.145777], [18.288681]], dtype=float32) run_torch.model(torch.tensor(x)) [9] 2020-05-30 17:26:04 ( 5.00ms ) python3 ( 14.1s ) tensor([[ 8.7655], [10.0127], [ 8.7341], [ 9.3584], [13.8856], [ 9.1302], [ 4.3797], [17.9581], [ 5.4108], [18.5158]], grad_fn=<AddmmBackward>)","title":"PyTorch vs TensorFlow"},{"location":"tutorial/library/#scikit-learn","text":"Ivory can optimize various scikit-learn's estimators. Here are som examples.","title":"Scikit-learn"},{"location":"tutorial/library/#randomforestregressor","text":"File 18 A parameter YAML for RandomForestRegressor (rfr.yml) library: sklearn datasets: data: class: rectangle.data.Data n_splits: 4 dataset: transform: rectangle.data.transform fold: 0 estimator: model: sklearn.ensemble.RandomForestRegressor n_estimators: 5 max_depth: 3 results: metrics: The dataset has a transform argument. This function reshapes the target array to match the shape for scikit-learn estimators (1D from 2D). Code 3 rectangle.data.transform() def transform(mode, input, target): return input, target.reshape(-1) There are nothing different to start a run. run = client.create_run('rfr') run.start() [12] 2020-05-30 17:26:04 ( 81.0ms ) python3 ( 14.2s ) [I 200530 17:26:04 tracker:48] A new experiment created with name: 'rfr' [run#0] mse=1.585 Because the RandomForestRegressor estimator has a criterion attribute, the metrics are automatically calculated. Take a look at the outputs. plot(run) [13] 2020-05-30 17:26:04 ( 80.0ms ) python3 ( 14.3s )","title":"RandomForestRegressor"},{"location":"tutorial/library/#ridge","text":"File 19 A parameter YAML for Ridge (ridge.yml) library: sklearn datasets: data: class: rectangle.data.Data n_splits: 4 dataset: transform: rectangle.data.transform fold: 0 estimator: model: sklearn.linear_model.Ridge results: metrics: mse: mse_2: rectangle.metrics.mean_squared_error Because the Ridge estimator has no criterion attribute, you have to specify metrics if you need. A mse key has empty ( None ) value. In this case, the default function ( sklearn.metrics.mean_squared_error() ) is chosen. On the other hand, mse_2 's value is a custom funtion's name: Code 4 rectangle.metrics.mean_squared_error() def mean_squared_error(true, pred): return np.mean((true - pred) ** 2) Although the rectangle.metrics.mean_squared_error() is the same as mse , this functionality allows us to add arbitrary metrics as long as they can be calculated with true and pred values . run = client.create_run('ridge') run.start() # Both metrics would give the same values. [16] 2020-05-30 17:26:10 ( 65.0ms ) python3 ( 14.7s ) [run#1] mse=2.244 mse_2=2.244 plot(run) [17] 2020-05-30 17:26:10 ( 80.0ms ) python3 ( 14.8s )","title":"Ridge"},{"location":"tutorial/library/#lightgbm","text":"For LightGBM, Ivory implements two estimators: ivory.lightgbm.estimator.Regressor ivory.lightgbm.estimator.Classifier File 20 A parameter YAML for LightGBM (lgb.yml) datasets: data: class: rectangle.data.Data n_splits: 4 dataset: transform: rectangle.data.transform fold: 0 estimator: class: ivory.lightgbm.estimator.Regressor boosting_type: gbdt num_leaves: 10 learning_rate: 0.1 max_depth: 4 num_boost_round: 10 verbose_eval: 2 results: metrics: mse: run = client.create_run('lgb') run.start() [18] 2020-05-30 17:26:10 ( 84.0ms ) python3 ( 14.9s ) [2] training's l2: 15.9601 valid_1's l2: 20.3489 [4] training's l2: 11.0501 valid_1's l2: 14.2388 [6] training's l2: 7.65786 valid_1's l2: 10.0006 [8] training's l2: 5.34303 valid_1's l2: 7.07968 [10] training's l2: 3.75311 valid_1's l2: 5.02458 [run#1] mse=5.025 plot(run) [19] 2020-05-30 17:26:10 ( 90.0ms ) python3 ( 15.0s )","title":"LightGBM"},{"location":"tutorial/model/","text":"Model Structure Model We have prepared a Datasets instance for PyTorch. Now define a MLP model that works with this Datasets . The model is defined in rectangle/torch.py File 6 rectangle/torch.py import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self, hidden_sizes): super().__init__() layers = [] for in_features, out_features in zip([2] + hidden_sizes, hidden_sizes + [1]): layers.append(nn.Linear(in_features, out_features)) self.layers = nn.ModuleList(layers) def forward(self, x): for layer in self.layers[:-1]: x = F.relu(layer(x)) return self.layers[-1](x) We again use Ivory's instance creation system . import yaml # A helper function. def create(doc, name, **kwargs): params = yaml.safe_load(doc) return create_instance(params, name, **kwargs) doc = \"\"\" library: torch datasets: data: class: rectangle.data.Data n_splits: 5 dataset: fold: 0 model: class: rectangle.torch.Model hidden_sizes: [3, 4, 5] \"\"\" datasets = create(doc, 'datasets') model = create(doc, 'model') model [2] 2020-05-30 16:20:54 ( 9.00ms ) python3 ( 15.0s ) Model( (layers): ModuleList( (0): Linear(in_features=2, out_features=3, bias=True) (1): Linear(in_features=3, out_features=4, bias=True) (2): Linear(in_features=4, out_features=5, bias=True) (3): Linear(in_features=5, out_features=1, bias=True) ) ) We can uses this model as usual. import torch index, input, target = datasets.train[:5] input [3] 2020-05-30 16:20:54 ( 4.00ms ) python3 ( 15.0s ) array([[4.8919764, 1.1556569], [3.1259346, 4.7114463], [1.65477 , 1.1083779], [1.732354 , 1.0978193], [3.0221472, 2.3750997]], dtype=float32) model(torch.tensor(input)) [4] 2020-05-30 16:20:54 ( 5.00ms ) python3 ( 15.0s ) tensor([[-0.1884], [-0.1923], [-0.1904], [-0.1904], [-0.1904]], grad_fn=<AddmmBackward>) Optimizer To train a model, we need an optimizer. For example import torch.optim optimizer = torch.optim.SGD(params=model.parameters(), lr=1e-3) optimizer [5] 2020-05-30 16:20:54 ( 4.00ms ) python3 ( 15.0s ) SGD ( Parameter Group 0 dampening: 0 lr: 0.001 momentum: 0 nesterov: False weight_decay: 0 ) Now try to describe this optimizer in a dictionary style. However, the first argument params is neigher a simple literal nor an other instance. It is an iterable of learnable parameters obtained from a model. Ivory provides \" $ -notation \" to tackle this problem. doc = \"\"\" optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 0.001 \"\"\" optimizer = create(doc, 'optimizer', globals={'model': model}) optimizer [6] 2020-05-30 16:20:54 ( 6.00ms ) python3 ( 15.0s ) SGD ( Parameter Group 0 dampening: 0 lr: 0.001 momentum: 0 nesterov: False weight_decay: 0 ) A \" $ \" is a starting point to refer other instance stored in the globals dictionary. In this case, $.model is replaced by the model instance in globals , then .parameters() invokes a call of the model.parameters() method. Scheduler A scheduler controls the learning rate of an optimizer. doc = \"\"\" scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 \"\"\" scheduler = create(doc, 'scheduler', globals={'optimizer': optimizer}) scheduler [7] 2020-05-30 16:20:54 ( 6.00ms ) python3 ( 15.0s ) <torch.optim.lr_scheduler.ReduceLROnPlateau at 0x2683ced9d88> If a $ -notation has no suffix, the value becomes its key itself. The following two examples are equivalent: optimizer: $ optimizer: $.optimizer Now we have had both data and model.","title":"<span class=\"pheasant-header\"><span class=\"header\"><span class=\"title\">Model Structure</span></span></span>"},{"location":"tutorial/model/#model-structure","text":"","title":"Model Structure"},{"location":"tutorial/model/#model","text":"We have prepared a Datasets instance for PyTorch. Now define a MLP model that works with this Datasets . The model is defined in rectangle/torch.py File 6 rectangle/torch.py import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self, hidden_sizes): super().__init__() layers = [] for in_features, out_features in zip([2] + hidden_sizes, hidden_sizes + [1]): layers.append(nn.Linear(in_features, out_features)) self.layers = nn.ModuleList(layers) def forward(self, x): for layer in self.layers[:-1]: x = F.relu(layer(x)) return self.layers[-1](x) We again use Ivory's instance creation system . import yaml # A helper function. def create(doc, name, **kwargs): params = yaml.safe_load(doc) return create_instance(params, name, **kwargs) doc = \"\"\" library: torch datasets: data: class: rectangle.data.Data n_splits: 5 dataset: fold: 0 model: class: rectangle.torch.Model hidden_sizes: [3, 4, 5] \"\"\" datasets = create(doc, 'datasets') model = create(doc, 'model') model [2] 2020-05-30 16:20:54 ( 9.00ms ) python3 ( 15.0s ) Model( (layers): ModuleList( (0): Linear(in_features=2, out_features=3, bias=True) (1): Linear(in_features=3, out_features=4, bias=True) (2): Linear(in_features=4, out_features=5, bias=True) (3): Linear(in_features=5, out_features=1, bias=True) ) ) We can uses this model as usual. import torch index, input, target = datasets.train[:5] input [3] 2020-05-30 16:20:54 ( 4.00ms ) python3 ( 15.0s ) array([[4.8919764, 1.1556569], [3.1259346, 4.7114463], [1.65477 , 1.1083779], [1.732354 , 1.0978193], [3.0221472, 2.3750997]], dtype=float32) model(torch.tensor(input)) [4] 2020-05-30 16:20:54 ( 5.00ms ) python3 ( 15.0s ) tensor([[-0.1884], [-0.1923], [-0.1904], [-0.1904], [-0.1904]], grad_fn=<AddmmBackward>)","title":"Model"},{"location":"tutorial/model/#optimizer","text":"To train a model, we need an optimizer. For example import torch.optim optimizer = torch.optim.SGD(params=model.parameters(), lr=1e-3) optimizer [5] 2020-05-30 16:20:54 ( 4.00ms ) python3 ( 15.0s ) SGD ( Parameter Group 0 dampening: 0 lr: 0.001 momentum: 0 nesterov: False weight_decay: 0 ) Now try to describe this optimizer in a dictionary style. However, the first argument params is neigher a simple literal nor an other instance. It is an iterable of learnable parameters obtained from a model. Ivory provides \" $ -notation \" to tackle this problem. doc = \"\"\" optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 0.001 \"\"\" optimizer = create(doc, 'optimizer', globals={'model': model}) optimizer [6] 2020-05-30 16:20:54 ( 6.00ms ) python3 ( 15.0s ) SGD ( Parameter Group 0 dampening: 0 lr: 0.001 momentum: 0 nesterov: False weight_decay: 0 ) A \" $ \" is a starting point to refer other instance stored in the globals dictionary. In this case, $.model is replaced by the model instance in globals , then .parameters() invokes a call of the model.parameters() method.","title":"Optimizer"},{"location":"tutorial/model/#scheduler","text":"A scheduler controls the learning rate of an optimizer. doc = \"\"\" scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 \"\"\" scheduler = create(doc, 'scheduler', globals={'optimizer': optimizer}) scheduler [7] 2020-05-30 16:20:54 ( 6.00ms ) python3 ( 15.0s ) <torch.optim.lr_scheduler.ReduceLROnPlateau at 0x2683ced9d88> If a $ -notation has no suffix, the value becomes its key itself. The following two examples are equivalent: optimizer: $ optimizer: $.optimizer Now we have had both data and model.","title":"Scheduler"},{"location":"tutorial/task/","text":"Multiple Runs Task Ivory implements a special run type called Task which controls multiple nested runs. A task is useful for parameter search or cross validation. import ivory client = ivory.create_client(\"examples\") # Set the working directory task = client.create_task('torch') # Or, experiment.create_task() task [3] 2020-05-30 16:20:54 ( 45.0ms ) python3 ( 15.1s ) [I 200530 16:20:54 tracker:48] A new experiment created with name: 'torch' Task(id='6f341f054ebb4c6ab4897caa0a2ca2dd', name='task#0', num_objects=3) The Task class has two methods to generate multiple runs: Task.prodcut() and Task.chain() . These two methods have the same functionality as itertools of Python starndard library. Product The Task.prodcut() makes an iterator that returns runs from cartesian product of input parameters. task = client.create_task('torch') # verbose=0: No progress bar. runs = task.product(fold=range(2), factor=[0.5, 0.7], verbose=0) runs [4] 2020-05-30 16:20:54 ( 36.0ms ) python3 ( 15.1s ) <generator object Task.product at 0x0000026A08E914C8> for run in runs: pass # Do somthing, for example, run.start() [5] 2020-05-30 16:20:54 ( 514ms ) python3 ( 15.6s ) [run#0] fold=0 factor=0.5 [run#1] fold=0 factor=0.7 [run#2] fold=1 factor=0.5 [run#3] fold=1 factor=0.7 You can specify other parameters which don't change during iteration. task = client.create_task('torch') runs = task.product(fold=range(2), factor=[0.5, 0.7], lr=1e-4, verbose=0) for run in runs: pass # Do somthing, for example, run.start() [6] 2020-05-30 16:20:54 ( 601ms ) python3 ( 16.2s ) [run#4] lr=0.0001 fold=0 factor=0.5 [run#5] lr=0.0001 fold=0 factor=0.7 [run#6] lr=0.0001 fold=1 factor=0.5 [run#7] lr=0.0001 fold=1 factor=0.7 Chain The Task.chain() maks an iterator that returns runs from the first input paramter until it is exhausted, then proceeds to the next parameter, until all of the parameters are exhausted. Other parameters have default values if they don't be specified by additional key-value pairs. task = client.create_task('torch') runs = task.chain( fold=range(2), factor=[0.5, 0.7], lr=[1e-4, 1e-3], batch_size=32, use_best_param=False, verbose=0) runs [7] 2020-05-30 16:20:55 ( 62.0ms ) python3 ( 16.3s ) <generator object Task.chain at 0x0000026A08E912C8> for run in runs: pass # Do somthing, for example, run.start() [8] 2020-05-30 16:20:55 ( 916ms ) python3 ( 17.2s ) [run#8] batch_size=32 fold=0 [run#9] batch_size=32 fold=1 [run#10] batch_size=32 factor=0.5 [run#11] batch_size=32 factor=0.7 [run#12] batch_size=32 lr=0.0001 [run#13] batch_size=32 lr=0.001 The use_best_param keyword argument is useful for dynamic updating of parameters. If True (default), the parameter which got the best score is used during the following iterations. task = client.create_task('torch') runs = task.chain( fold=range(2), factor=[0.5, 0.7], lr=[1e-4, 1e-3], use_best_param=True, verbose=0) for run in runs: pass # Do somthing, for example, run.start() # We do nothing, so the first values are used. [9] 2020-05-30 16:20:56 ( 1.06s ) python3 ( 18.3s ) [run#14] fold=0 [run#15] fold=1 [run#16] factor=0.5 fold=0 [run#17] factor=0.7 fold=0 [run#18] lr=0.0001 fold=0 factor=0.5 [run#19] lr=0.001 fold=0 factor=0.5 Range Ivory provides the ivory.utils.range.Range class for parameter ranging. This class can be used as the standard range , but more flexible, especially for the float type. from ivory.utils.range import Range list(Range(6)) # The stop value is included. [10] 2020-05-30 16:20:57 ( 5.00ms ) python3 ( 18.3s ) [0, 1, 2, 3, 4, 5, 6] list(Range(3, 6)) # Start and stop. [11] 2020-05-30 16:20:57 ( 4.00ms ) python3 ( 18.3s ) [3, 4, 5, 6] list(Range(3, 10, 2)) # Step size. [12] 2020-05-30 16:20:57 ( 4.00ms ) python3 ( 18.3s ) [3, 5, 7, 9] list(Range(3, 10, num=4)) # Sampling size. [13] 2020-05-30 16:20:57 ( 4.00ms ) python3 ( 18.3s ) [3, 5, 8, 10] list(Range(0.0, 1.0, 0.25)) # float type. [14] 2020-05-30 16:20:57 ( 3.00ms ) python3 ( 18.3s ) [0.0, 0.25, 0.5, 0.75, 1.0] list(Range(0.0, 1.0, num=5)) # Sampling size [15] 2020-05-30 16:20:57 ( 4.00ms ) python3 ( 18.3s ) [0.0, 0.25, 0.5, 0.75, 1.0] list(Range(1e-3, 1e2, num=6, log=True)) # Log scale [16] 2020-05-30 16:20:57 ( 3.00ms ) python3 ( 18.3s ) [0.001, 0.01, 0.1, 1.0, 10.0, 100.0] A Range instance can be created from a string. list(Range('3-7')) # <start>-<stop> [17] 2020-05-30 16:20:57 ( 3.00ms ) python3 ( 18.3s ) [3, 4, 5, 6, 7] list(Range('3-7-2')) # <start>-<stop>-<step> [18] 2020-05-30 16:20:57 ( 3.00ms ) python3 ( 18.3s ) [3, 5, 7] list(Range('0.0-1.0:5')) # <start>-<stop>:<num> [19] 2020-05-30 16:20:57 ( 3.00ms ) python3 ( 18.3s ) [0.0, 0.25, 0.5, 0.75, 1.0] list(Range('1e-3_1e2:6.log')) # '_' instead of '-', log scale [20] 2020-05-30 16:20:57 ( 4.00ms ) python3 ( 18.3s ) [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]","title":"<span class=\"pheasant-header\"><span class=\"header\"><span class=\"title\">Multiple Runs</span></span></span>"},{"location":"tutorial/task/#multiple-runs","text":"","title":"Multiple Runs"},{"location":"tutorial/task/#task","text":"Ivory implements a special run type called Task which controls multiple nested runs. A task is useful for parameter search or cross validation. import ivory client = ivory.create_client(\"examples\") # Set the working directory task = client.create_task('torch') # Or, experiment.create_task() task [3] 2020-05-30 16:20:54 ( 45.0ms ) python3 ( 15.1s ) [I 200530 16:20:54 tracker:48] A new experiment created with name: 'torch' Task(id='6f341f054ebb4c6ab4897caa0a2ca2dd', name='task#0', num_objects=3) The Task class has two methods to generate multiple runs: Task.prodcut() and Task.chain() . These two methods have the same functionality as itertools of Python starndard library.","title":"Task"},{"location":"tutorial/task/#product","text":"The Task.prodcut() makes an iterator that returns runs from cartesian product of input parameters. task = client.create_task('torch') # verbose=0: No progress bar. runs = task.product(fold=range(2), factor=[0.5, 0.7], verbose=0) runs [4] 2020-05-30 16:20:54 ( 36.0ms ) python3 ( 15.1s ) <generator object Task.product at 0x0000026A08E914C8> for run in runs: pass # Do somthing, for example, run.start() [5] 2020-05-30 16:20:54 ( 514ms ) python3 ( 15.6s ) [run#0] fold=0 factor=0.5 [run#1] fold=0 factor=0.7 [run#2] fold=1 factor=0.5 [run#3] fold=1 factor=0.7 You can specify other parameters which don't change during iteration. task = client.create_task('torch') runs = task.product(fold=range(2), factor=[0.5, 0.7], lr=1e-4, verbose=0) for run in runs: pass # Do somthing, for example, run.start() [6] 2020-05-30 16:20:54 ( 601ms ) python3 ( 16.2s ) [run#4] lr=0.0001 fold=0 factor=0.5 [run#5] lr=0.0001 fold=0 factor=0.7 [run#6] lr=0.0001 fold=1 factor=0.5 [run#7] lr=0.0001 fold=1 factor=0.7","title":"Product"},{"location":"tutorial/task/#chain","text":"The Task.chain() maks an iterator that returns runs from the first input paramter until it is exhausted, then proceeds to the next parameter, until all of the parameters are exhausted. Other parameters have default values if they don't be specified by additional key-value pairs. task = client.create_task('torch') runs = task.chain( fold=range(2), factor=[0.5, 0.7], lr=[1e-4, 1e-3], batch_size=32, use_best_param=False, verbose=0) runs [7] 2020-05-30 16:20:55 ( 62.0ms ) python3 ( 16.3s ) <generator object Task.chain at 0x0000026A08E912C8> for run in runs: pass # Do somthing, for example, run.start() [8] 2020-05-30 16:20:55 ( 916ms ) python3 ( 17.2s ) [run#8] batch_size=32 fold=0 [run#9] batch_size=32 fold=1 [run#10] batch_size=32 factor=0.5 [run#11] batch_size=32 factor=0.7 [run#12] batch_size=32 lr=0.0001 [run#13] batch_size=32 lr=0.001 The use_best_param keyword argument is useful for dynamic updating of parameters. If True (default), the parameter which got the best score is used during the following iterations. task = client.create_task('torch') runs = task.chain( fold=range(2), factor=[0.5, 0.7], lr=[1e-4, 1e-3], use_best_param=True, verbose=0) for run in runs: pass # Do somthing, for example, run.start() # We do nothing, so the first values are used. [9] 2020-05-30 16:20:56 ( 1.06s ) python3 ( 18.3s ) [run#14] fold=0 [run#15] fold=1 [run#16] factor=0.5 fold=0 [run#17] factor=0.7 fold=0 [run#18] lr=0.0001 fold=0 factor=0.5 [run#19] lr=0.001 fold=0 factor=0.5","title":"Chain"},{"location":"tutorial/task/#range","text":"Ivory provides the ivory.utils.range.Range class for parameter ranging. This class can be used as the standard range , but more flexible, especially for the float type. from ivory.utils.range import Range list(Range(6)) # The stop value is included. [10] 2020-05-30 16:20:57 ( 5.00ms ) python3 ( 18.3s ) [0, 1, 2, 3, 4, 5, 6] list(Range(3, 6)) # Start and stop. [11] 2020-05-30 16:20:57 ( 4.00ms ) python3 ( 18.3s ) [3, 4, 5, 6] list(Range(3, 10, 2)) # Step size. [12] 2020-05-30 16:20:57 ( 4.00ms ) python3 ( 18.3s ) [3, 5, 7, 9] list(Range(3, 10, num=4)) # Sampling size. [13] 2020-05-30 16:20:57 ( 4.00ms ) python3 ( 18.3s ) [3, 5, 8, 10] list(Range(0.0, 1.0, 0.25)) # float type. [14] 2020-05-30 16:20:57 ( 3.00ms ) python3 ( 18.3s ) [0.0, 0.25, 0.5, 0.75, 1.0] list(Range(0.0, 1.0, num=5)) # Sampling size [15] 2020-05-30 16:20:57 ( 4.00ms ) python3 ( 18.3s ) [0.0, 0.25, 0.5, 0.75, 1.0] list(Range(1e-3, 1e2, num=6, log=True)) # Log scale [16] 2020-05-30 16:20:57 ( 3.00ms ) python3 ( 18.3s ) [0.001, 0.01, 0.1, 1.0, 10.0, 100.0] A Range instance can be created from a string. list(Range('3-7')) # <start>-<stop> [17] 2020-05-30 16:20:57 ( 3.00ms ) python3 ( 18.3s ) [3, 4, 5, 6, 7] list(Range('3-7-2')) # <start>-<stop>-<step> [18] 2020-05-30 16:20:57 ( 3.00ms ) python3 ( 18.3s ) [3, 5, 7] list(Range('0.0-1.0:5')) # <start>-<stop>:<num> [19] 2020-05-30 16:20:57 ( 3.00ms ) python3 ( 18.3s ) [0.0, 0.25, 0.5, 0.75, 1.0] list(Range('1e-3_1e2:6.log')) # '_' instead of '-', log scale [20] 2020-05-30 16:20:57 ( 4.00ms ) python3 ( 18.3s ) [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]","title":"Range"},{"location":"tutorial/tracking/","text":"Tracking Runs with Ivory First create several runs for demonstration. import ivory client = ivory.create_client(\"examples\") run = client.create_run('torch', fold=2) run.start() [3] 2020-05-30 16:20:57 ( 1.23s ) python3 ( 19.6s ) [I 200530 16:20:57 tracker:48] A new experiment created with name: 'torch' [epoch#0] loss=25.92 val_loss=7.71 lr=0.001 best [epoch#1] loss=7.975 val_loss=6.841 lr=0.001 best [epoch#2] loss=7.107 val_loss=5.95 lr=0.001 best [epoch#3] loss=6.098 val_loss=5.075 lr=0.001 best [epoch#4] loss=5.124 val_loss=4.049 lr=0.001 best [epoch#5] loss=4.055 val_loss=3.141 lr=0.001 best [epoch#6] loss=3.075 val_loss=2.382 lr=0.001 best [epoch#7] loss=2.198 val_loss=1.692 lr=0.001 best [epoch#8] loss=1.62 val_loss=1.321 lr=0.001 best [epoch#9] loss=1.226 val_loss=1.102 lr=0.001 best run = client.create_run('torch', fold=3) run.start('both') [4] 2020-05-30 16:20:58 ( 1.27s ) python3 ( 20.9s ) [epoch#0] loss=22.48 val_loss=9.112 lr=0.001 best [epoch#1] loss=8.12 val_loss=7.637 lr=0.001 best [epoch#2] loss=7.301 val_loss=7.048 lr=0.001 best [epoch#3] loss=6.601 val_loss=6.56 lr=0.001 best [epoch#4] loss=6.084 val_loss=6.514 lr=0.001 best [epoch#5] loss=5.32 val_loss=5.228 lr=0.001 best [epoch#6] loss=4.78 val_loss=4.339 lr=0.001 best [epoch#7] loss=4.044 val_loss=3.617 lr=0.001 best [epoch#8] loss=3.415 val_loss=3.179 lr=0.001 best [epoch#9] loss=2.854 val_loss=2.558 lr=0.001 best task = client.create_task('torch') runs = task.product(fold=range(3), verbose=0) for run in runs: pass # Do something [5] 2020-05-30 16:21:00 ( 444ms ) python3 ( 21.3s ) [run#2] fold=0 [run#3] fold=1 [run#4] fold=2 task = client.create_task('torch') runs = task.product(n_splits=[3, 4], verbose=0) for run in runs: pass # Do something [6] 2020-05-30 16:21:00 ( 323ms ) python3 ( 21.6s ) [run#5] n_splits=3 [run#6] n_splits=4 task = client.create_task('torch') runs = task.chain(lr=[1e-4, 1e-3], batch_size=[16, 32], verbose=0) for run in runs: pass # Do something [7] 2020-05-30 16:21:00 ( 631ms ) python3 ( 22.3s ) [run#7] lr=0.0001 [run#8] lr=0.001 [run#9] batch_size=16 lr=0.0001 [run#10] batch_size=32 lr=0.0001 Tracking Interface Search methods The client.search_run_ids() method makes an iterator that returns RunIDs of runs. # A helper function def print_run_info(run_ids): for run_id in run_ids: print(run_id[:5], client.get_run_name(run_id)) run_ids = client.search_run_ids('torch') print_run_info(run_ids) [8] 2020-05-30 16:21:01 ( 115ms ) python3 ( 22.4s ) ac5c1 run#10 bf1b8 run#9 4993b run#8 9c72b run#7 fc4ab task#2 a413e run#6 83aa8 run#5 63ed3 task#1 b29c2 run#4 3da97 run#3 e8a93 run#2 411a1 task#0 a559f run#1 28011 run#0 You can filtering runs by passing keyword arguments. run_ids = client.search_run_ids('torch', lr=1e-4, batch_size=32) print_run_info(run_ids) [9] 2020-05-30 16:21:01 ( 195ms ) python3 ( 22.6s ) ac5c1 run#10 The client.search_nested_run_ids() method makes an iterator that returns RunIDs of runs that have a parent run. Optionally, you can filter runs. run_ids = client.search_nested_run_ids('torch') print_run_info(run_ids) [10] 2020-05-30 16:21:01 ( 78.7ms ) python3 ( 22.6s ) ac5c1 run#10 bf1b8 run#9 4993b run#8 9c72b run#7 a413e run#6 83aa8 run#5 b29c2 run#4 3da97 run#3 e8a93 run#2 Note that the run#0 isn't returned because it was created by client.create_run() directly. The client.search_parent_run_ids() method makes an iterator that returns RunIDs of runs that have nested runs. In this case, parent runs are three tasks we made above. run_ids = client.search_parent_run_ids('torch') print_run_info(run_ids) [11] 2020-05-30 16:21:01 ( 46.0ms ) python3 ( 22.7s ) fc4ab task#2 63ed3 task#1 411a1 task#0 Get methods The client.get_run_id() returns a RunID of runs you select by run name. run_id = client.get_run_id('torch', run=0) print_run_info([run_id]) [12] 2020-05-30 16:21:01 ( 39.0ms ) python3 ( 22.7s ) 28011 run#0 The client.get_run_ids() makes an iterator that returns RunIDs of runs you select by run names. run_ids = client.get_run_ids('torch', task=range(1, 3)) print_run_info(run_ids) [13] 2020-05-30 16:21:01 ( 76.7ms ) python3 ( 22.8s ) 63ed3 task#1 fc4ab task#2 The client.get_nested_run_ids() makes an iterator that returns RunIDs of runs that have a parent you select by run names. run_ids = client.get_nested_run_ids('torch', task=range(2)) print_run_info(run_ids) [14] 2020-05-30 16:21:02 ( 142ms ) python3 ( 23.0s ) b29c2 run#4 3da97 run#3 e8a93 run#2 a413e run#6 83aa8 run#5 The client.get_parent_run_id() returns a RunID of a run that is refered by a nested run. run_id = client.get_parent_run_id('torch', run=5) print_run_info([run_id]) [15] 2020-05-30 16:21:02 ( 40.0ms ) python3 ( 23.0s ) 63ed3 task#1 Set method Sometimes, you may want to change a parent for nested runs. Use the client.set_parent_run_id() method. run_ids = client.get_nested_run_ids('torch', task=2) print_run_info(run_ids) [16] 2020-05-30 16:21:02 ( 78.7ms ) python3 ( 23.1s ) ac5c1 run#10 bf1b8 run#9 4993b run#8 9c72b run#7 client.set_parent_run_id('torch', run=(0, 2, 3), task=2) run_ids = client.get_nested_run_ids('torch', task=2) print_run_info(run_ids) [17] 2020-05-30 16:21:02 ( 236ms ) python3 ( 23.3s ) ac5c1 run#10 bf1b8 run#9 4993b run#8 9c72b run#7 3da97 run#3 e8a93 run#2 28011 run#0 Next Step Once you got RunID(s), you can load a run, a member of a run, or collect results of multiple runs for an ensemble. See the quickstart .","title":"<span class=\"pheasant-header\"><span class=\"header\"><span class=\"title\">Tracking Runs with Ivory</span></span></span>"},{"location":"tutorial/tracking/#tracking-runs-with-ivory","text":"First create several runs for demonstration. import ivory client = ivory.create_client(\"examples\") run = client.create_run('torch', fold=2) run.start() [3] 2020-05-30 16:20:57 ( 1.23s ) python3 ( 19.6s ) [I 200530 16:20:57 tracker:48] A new experiment created with name: 'torch' [epoch#0] loss=25.92 val_loss=7.71 lr=0.001 best [epoch#1] loss=7.975 val_loss=6.841 lr=0.001 best [epoch#2] loss=7.107 val_loss=5.95 lr=0.001 best [epoch#3] loss=6.098 val_loss=5.075 lr=0.001 best [epoch#4] loss=5.124 val_loss=4.049 lr=0.001 best [epoch#5] loss=4.055 val_loss=3.141 lr=0.001 best [epoch#6] loss=3.075 val_loss=2.382 lr=0.001 best [epoch#7] loss=2.198 val_loss=1.692 lr=0.001 best [epoch#8] loss=1.62 val_loss=1.321 lr=0.001 best [epoch#9] loss=1.226 val_loss=1.102 lr=0.001 best run = client.create_run('torch', fold=3) run.start('both') [4] 2020-05-30 16:20:58 ( 1.27s ) python3 ( 20.9s ) [epoch#0] loss=22.48 val_loss=9.112 lr=0.001 best [epoch#1] loss=8.12 val_loss=7.637 lr=0.001 best [epoch#2] loss=7.301 val_loss=7.048 lr=0.001 best [epoch#3] loss=6.601 val_loss=6.56 lr=0.001 best [epoch#4] loss=6.084 val_loss=6.514 lr=0.001 best [epoch#5] loss=5.32 val_loss=5.228 lr=0.001 best [epoch#6] loss=4.78 val_loss=4.339 lr=0.001 best [epoch#7] loss=4.044 val_loss=3.617 lr=0.001 best [epoch#8] loss=3.415 val_loss=3.179 lr=0.001 best [epoch#9] loss=2.854 val_loss=2.558 lr=0.001 best task = client.create_task('torch') runs = task.product(fold=range(3), verbose=0) for run in runs: pass # Do something [5] 2020-05-30 16:21:00 ( 444ms ) python3 ( 21.3s ) [run#2] fold=0 [run#3] fold=1 [run#4] fold=2 task = client.create_task('torch') runs = task.product(n_splits=[3, 4], verbose=0) for run in runs: pass # Do something [6] 2020-05-30 16:21:00 ( 323ms ) python3 ( 21.6s ) [run#5] n_splits=3 [run#6] n_splits=4 task = client.create_task('torch') runs = task.chain(lr=[1e-4, 1e-3], batch_size=[16, 32], verbose=0) for run in runs: pass # Do something [7] 2020-05-30 16:21:00 ( 631ms ) python3 ( 22.3s ) [run#7] lr=0.0001 [run#8] lr=0.001 [run#9] batch_size=16 lr=0.0001 [run#10] batch_size=32 lr=0.0001","title":"Tracking Runs with Ivory"},{"location":"tutorial/tracking/#tracking-interface","text":"","title":"Tracking Interface"},{"location":"tutorial/tracking/#search-methods","text":"The client.search_run_ids() method makes an iterator that returns RunIDs of runs. # A helper function def print_run_info(run_ids): for run_id in run_ids: print(run_id[:5], client.get_run_name(run_id)) run_ids = client.search_run_ids('torch') print_run_info(run_ids) [8] 2020-05-30 16:21:01 ( 115ms ) python3 ( 22.4s ) ac5c1 run#10 bf1b8 run#9 4993b run#8 9c72b run#7 fc4ab task#2 a413e run#6 83aa8 run#5 63ed3 task#1 b29c2 run#4 3da97 run#3 e8a93 run#2 411a1 task#0 a559f run#1 28011 run#0 You can filtering runs by passing keyword arguments. run_ids = client.search_run_ids('torch', lr=1e-4, batch_size=32) print_run_info(run_ids) [9] 2020-05-30 16:21:01 ( 195ms ) python3 ( 22.6s ) ac5c1 run#10 The client.search_nested_run_ids() method makes an iterator that returns RunIDs of runs that have a parent run. Optionally, you can filter runs. run_ids = client.search_nested_run_ids('torch') print_run_info(run_ids) [10] 2020-05-30 16:21:01 ( 78.7ms ) python3 ( 22.6s ) ac5c1 run#10 bf1b8 run#9 4993b run#8 9c72b run#7 a413e run#6 83aa8 run#5 b29c2 run#4 3da97 run#3 e8a93 run#2 Note that the run#0 isn't returned because it was created by client.create_run() directly. The client.search_parent_run_ids() method makes an iterator that returns RunIDs of runs that have nested runs. In this case, parent runs are three tasks we made above. run_ids = client.search_parent_run_ids('torch') print_run_info(run_ids) [11] 2020-05-30 16:21:01 ( 46.0ms ) python3 ( 22.7s ) fc4ab task#2 63ed3 task#1 411a1 task#0","title":"Search methods"},{"location":"tutorial/tracking/#get-methods","text":"The client.get_run_id() returns a RunID of runs you select by run name. run_id = client.get_run_id('torch', run=0) print_run_info([run_id]) [12] 2020-05-30 16:21:01 ( 39.0ms ) python3 ( 22.7s ) 28011 run#0 The client.get_run_ids() makes an iterator that returns RunIDs of runs you select by run names. run_ids = client.get_run_ids('torch', task=range(1, 3)) print_run_info(run_ids) [13] 2020-05-30 16:21:01 ( 76.7ms ) python3 ( 22.8s ) 63ed3 task#1 fc4ab task#2 The client.get_nested_run_ids() makes an iterator that returns RunIDs of runs that have a parent you select by run names. run_ids = client.get_nested_run_ids('torch', task=range(2)) print_run_info(run_ids) [14] 2020-05-30 16:21:02 ( 142ms ) python3 ( 23.0s ) b29c2 run#4 3da97 run#3 e8a93 run#2 a413e run#6 83aa8 run#5 The client.get_parent_run_id() returns a RunID of a run that is refered by a nested run. run_id = client.get_parent_run_id('torch', run=5) print_run_info([run_id]) [15] 2020-05-30 16:21:02 ( 40.0ms ) python3 ( 23.0s ) 63ed3 task#1","title":"Get methods"},{"location":"tutorial/tracking/#set-method","text":"Sometimes, you may want to change a parent for nested runs. Use the client.set_parent_run_id() method. run_ids = client.get_nested_run_ids('torch', task=2) print_run_info(run_ids) [16] 2020-05-30 16:21:02 ( 78.7ms ) python3 ( 23.1s ) ac5c1 run#10 bf1b8 run#9 4993b run#8 9c72b run#7 client.set_parent_run_id('torch', run=(0, 2, 3), task=2) run_ids = client.get_nested_run_ids('torch', task=2) print_run_info(run_ids) [17] 2020-05-30 16:21:02 ( 236ms ) python3 ( 23.3s ) ac5c1 run#10 bf1b8 run#9 4993b run#8 9c72b run#7 3da97 run#3 e8a93 run#2 28011 run#0","title":"Set method"},{"location":"tutorial/tracking/#next-step","text":"Once you got RunID(s), you can load a run, a member of a run, or collect results of multiple runs for an ensemble. See the quickstart .","title":"Next Step"},{"location":"tutorial/training/","text":"Training a Model First, create data and model set. For more details about the following code, see Creating Instance section . import yaml params = yaml.safe_load(\"\"\" library: torch run: datasets: data: class: rectangle.data.Data n_splits: 4 dataset: fold: 0 model: class: rectangle.torch.Model hidden_sizes: [100, 100] optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 0.001 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: metrics: monitor: metric: val_loss early_stopping: patience: 10 trainer: loss: torch.nn.functional.mse_loss batch_size: 10 epochs: 10 verbose: 2 \"\"\") params [2] 2020-05-30 16:21:02 ( 8.00ms ) python3 ( 23.3s ) {'library': 'torch', 'run': {'datasets': {'data': {'class': 'rectangle.data.Data', 'n_splits': 4}, 'dataset': None, 'fold': 0}, 'model': {'class': 'rectangle.torch.Model', 'hidden_sizes': [100, 100]}, 'optimizer': {'class': 'torch.optim.SGD', 'params': '$.model.parameters()', 'lr': 0.001}, 'scheduler': {'class': 'torch.optim.lr_scheduler.ReduceLROnPlateau', 'optimizer': '$', 'factor': 0.5, 'patience': 4}, 'results': None, 'metrics': None, 'monitor': {'metric': 'val_loss'}, 'early_stopping': {'patience': 10}, 'trainer': {'loss': 'torch.nn.functional.mse_loss', 'batch_size': 10, 'epochs': 10, 'verbose': 2}}} Note Key-order in the params dictionary is meaningful, because the callback functions are called by this order. For example, Monitor uses the results of Metrics so that Monitor should appear later than Metrics . The ivory.core.instance.create_base_instance() function is more useful to create a run from a dictionary than the ivory.core.instance.create_instance() function because it can create multiple objects by one step processing $ -notation properly. import ivory.core.instance run = ivory.core.instance.create_base_instance(params, 'run') list(run) [3] 2020-05-30 16:21:02 ( 8.00ms ) python3 ( 23.3s ) ['datasets', 'model', 'optimizer', 'scheduler', 'results', 'metrics', 'monitor', 'early_stopping', 'trainer'] Callbacks Check callbacks of the Run instance. import ivory.core.base # A helper function def print_callbacks(obj): for func in ivory.core.base.Callback.METHODS: if hasattr(obj, func) and callable(getattr(obj, func)): print(' ', func) for name, obj in run.items(): print(f'[{name}]') print_callbacks(obj) [4] 2020-05-30 16:21:02 ( 40.0ms ) python3 ( 23.4s ) [datasets] [model] [optimizer] [scheduler] [results] on_train_begin on_train_end on_val_end on_test_begin on_test_end [metrics] on_epoch_begin on_train_begin on_train_end on_val_begin on_val_end on_epoch_end [monitor] on_epoch_end [early_stopping] on_epoch_end [trainer] on_fit_begin on_train_begin on_val_begin on_epoch_end on_test_begin Metrics The role of Metrics class is to record a set of metric for evaluation of model performance. The metirics are updated at each epoch end. run.metrics # Now, metrics are empty. [5] 2020-05-30 16:21:02 ( 3.00ms ) python3 ( 23.4s ) Metrics() Monitor The Monitor class is monitoring the most important metric to measure the model score or to determine the training logic (early stopping or pruning). run.monitor # Monitoring `val_loss`. Lower is better. [6] 2020-05-30 16:21:02 ( 3.00ms ) python3 ( 23.4s ) Monitor(metric='val_loss', mode='min') EarlyStopping The EarlyStopping class is to stop the training loop when a monitored metric has stopped improving. run.early_stopping # Early stopping occurs when `wait` > `patience`. [7] 2020-05-30 16:21:02 ( 3.00ms ) python3 ( 23.4s ) EarlyStopping(patience=10, wait=0) Trainer The Tainer class controls the model training. This is a callback, but at the same time, invokes callback functions at each step of training, validation, and test loop. run.trainer # Training hasn't started yet, so epoch = -1. [8] 2020-05-30 16:21:02 ( 3.00ms ) python3 ( 23.4s ) Trainer(epoch=-1, epochs=10, global_step=-1, verbose=2, loss=<function mse_loss at 0x000002682FBE4288>, batch_size=10, shuffle=True, gpu=False, precision=32, amp_level='O1', scheduler_step_mode='epoch') Using a Trainer A Run instance invokes its trainer by Run.start() method. run.start() # create_callbacks() is called automatically. [9] 2020-05-30 16:21:02 ( 540ms ) python3 ( 23.9s ) [epoch#0] loss=12.3 val_loss=9.073 lr=0.001 best [epoch#1] loss=6.368 val_loss=5.331 lr=0.001 best [epoch#2] loss=5.405 val_loss=3.963 lr=0.001 best [epoch#3] loss=3.881 val_loss=2.8 lr=0.001 best [epoch#4] loss=2.688 val_loss=1.784 lr=0.001 best [epoch#5] loss=1.793 val_loss=2.064 lr=0.001 [epoch#6] loss=1.134 val_loss=1.35 lr=0.001 best [epoch#7] loss=0.8556 val_loss=0.6147 lr=0.001 best [epoch#8] loss=0.635 val_loss=0.5546 lr=0.001 best [epoch#9] loss=0.6089 val_loss=0.4768 lr=0.001 best You can update attributes of run's objects at any time. run.trainer.epochs = 5 run.start() [10] 2020-05-30 16:21:03 ( 288ms ) python3 ( 24.2s ) [epoch#10] loss=0.5159 val_loss=0.6315 lr=0.001 [epoch#11] loss=0.5438 val_loss=0.5054 lr=0.001 [epoch#12] loss=0.4831 val_loss=0.3839 lr=0.001 best [epoch#13] loss=0.4455 val_loss=0.3534 lr=0.001 best [epoch#14] loss=0.4898 val_loss=0.3954 lr=0.001 Note The Run.start() method doesn't reset the trainer's epoch. Callbacks after Training After training, the callbacks changes their states. run.metrics # Show metrics at current epoch. [11] 2020-05-30 16:21:03 ( 5.00ms ) python3 ( 24.2s ) Metrics(loss=0.4898, val_loss=0.3954, lr=0.001) run.metrics.history.val_loss # Metrics history. [12] 2020-05-30 16:21:03 ( 5.00ms ) python3 ( 24.2s ) {0: 9.07283158302307, 1: 5.330642098188401, 2: 3.963082951307297, 3: 2.7999730914831162, 4: 1.7839402288198472, 5: 2.0641077041625975, 6: 1.3496331840753555, 7: 0.6146575763821602, 8: 0.5545605823397637, 9: 0.47675749361515046, 10: 0.6315262600779533, 11: 0.5053925298154354, 12: 0.3838960863649845, 13: 0.353401317819953, 14: 0.3953550048172474} run.monitor # Store the best score and its epoch. [13] 2020-05-30 16:21:03 ( 4.00ms ) python3 ( 24.2s ) Monitor(metric='val_loss', mode='min', best_score=0.353, best_epoch=13) run.early_stopping # Current `wait`. [14] 2020-05-30 16:21:03 ( 4.00ms ) python3 ( 24.2s ) EarlyStopping(patience=10, wait=1) run.trainer # Current epoch is 14 (0-indexed). [15] 2020-05-30 16:21:03 ( 4.00ms ) python3 ( 24.2s ) Trainer(epoch=14, epochs=5, global_step=899, verbose=2, loss=<function mse_loss at 0x000002682FBE4288>, batch_size=10, shuffle=True, gpu=False, precision=32, amp_level='O1', scheduler_step_mode='epoch')","title":"<span class=\"pheasant-header\"><span class=\"header\"><span class=\"title\">Training a Model</span></span></span>"},{"location":"tutorial/training/#training-a-model","text":"First, create data and model set. For more details about the following code, see Creating Instance section . import yaml params = yaml.safe_load(\"\"\" library: torch run: datasets: data: class: rectangle.data.Data n_splits: 4 dataset: fold: 0 model: class: rectangle.torch.Model hidden_sizes: [100, 100] optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 0.001 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: metrics: monitor: metric: val_loss early_stopping: patience: 10 trainer: loss: torch.nn.functional.mse_loss batch_size: 10 epochs: 10 verbose: 2 \"\"\") params [2] 2020-05-30 16:21:02 ( 8.00ms ) python3 ( 23.3s ) {'library': 'torch', 'run': {'datasets': {'data': {'class': 'rectangle.data.Data', 'n_splits': 4}, 'dataset': None, 'fold': 0}, 'model': {'class': 'rectangle.torch.Model', 'hidden_sizes': [100, 100]}, 'optimizer': {'class': 'torch.optim.SGD', 'params': '$.model.parameters()', 'lr': 0.001}, 'scheduler': {'class': 'torch.optim.lr_scheduler.ReduceLROnPlateau', 'optimizer': '$', 'factor': 0.5, 'patience': 4}, 'results': None, 'metrics': None, 'monitor': {'metric': 'val_loss'}, 'early_stopping': {'patience': 10}, 'trainer': {'loss': 'torch.nn.functional.mse_loss', 'batch_size': 10, 'epochs': 10, 'verbose': 2}}} Note Key-order in the params dictionary is meaningful, because the callback functions are called by this order. For example, Monitor uses the results of Metrics so that Monitor should appear later than Metrics . The ivory.core.instance.create_base_instance() function is more useful to create a run from a dictionary than the ivory.core.instance.create_instance() function because it can create multiple objects by one step processing $ -notation properly. import ivory.core.instance run = ivory.core.instance.create_base_instance(params, 'run') list(run) [3] 2020-05-30 16:21:02 ( 8.00ms ) python3 ( 23.3s ) ['datasets', 'model', 'optimizer', 'scheduler', 'results', 'metrics', 'monitor', 'early_stopping', 'trainer']","title":"Training a Model"},{"location":"tutorial/training/#callbacks","text":"Check callbacks of the Run instance. import ivory.core.base # A helper function def print_callbacks(obj): for func in ivory.core.base.Callback.METHODS: if hasattr(obj, func) and callable(getattr(obj, func)): print(' ', func) for name, obj in run.items(): print(f'[{name}]') print_callbacks(obj) [4] 2020-05-30 16:21:02 ( 40.0ms ) python3 ( 23.4s ) [datasets] [model] [optimizer] [scheduler] [results] on_train_begin on_train_end on_val_end on_test_begin on_test_end [metrics] on_epoch_begin on_train_begin on_train_end on_val_begin on_val_end on_epoch_end [monitor] on_epoch_end [early_stopping] on_epoch_end [trainer] on_fit_begin on_train_begin on_val_begin on_epoch_end on_test_begin","title":"Callbacks"},{"location":"tutorial/training/#metrics","text":"The role of Metrics class is to record a set of metric for evaluation of model performance. The metirics are updated at each epoch end. run.metrics # Now, metrics are empty. [5] 2020-05-30 16:21:02 ( 3.00ms ) python3 ( 23.4s ) Metrics()","title":"Metrics"},{"location":"tutorial/training/#monitor","text":"The Monitor class is monitoring the most important metric to measure the model score or to determine the training logic (early stopping or pruning). run.monitor # Monitoring `val_loss`. Lower is better. [6] 2020-05-30 16:21:02 ( 3.00ms ) python3 ( 23.4s ) Monitor(metric='val_loss', mode='min')","title":"Monitor"},{"location":"tutorial/training/#earlystopping","text":"The EarlyStopping class is to stop the training loop when a monitored metric has stopped improving. run.early_stopping # Early stopping occurs when `wait` > `patience`. [7] 2020-05-30 16:21:02 ( 3.00ms ) python3 ( 23.4s ) EarlyStopping(patience=10, wait=0)","title":"EarlyStopping"},{"location":"tutorial/training/#trainer","text":"The Tainer class controls the model training. This is a callback, but at the same time, invokes callback functions at each step of training, validation, and test loop. run.trainer # Training hasn't started yet, so epoch = -1. [8] 2020-05-30 16:21:02 ( 3.00ms ) python3 ( 23.4s ) Trainer(epoch=-1, epochs=10, global_step=-1, verbose=2, loss=<function mse_loss at 0x000002682FBE4288>, batch_size=10, shuffle=True, gpu=False, precision=32, amp_level='O1', scheduler_step_mode='epoch')","title":"Trainer"},{"location":"tutorial/training/#using-a-trainer","text":"A Run instance invokes its trainer by Run.start() method. run.start() # create_callbacks() is called automatically. [9] 2020-05-30 16:21:02 ( 540ms ) python3 ( 23.9s ) [epoch#0] loss=12.3 val_loss=9.073 lr=0.001 best [epoch#1] loss=6.368 val_loss=5.331 lr=0.001 best [epoch#2] loss=5.405 val_loss=3.963 lr=0.001 best [epoch#3] loss=3.881 val_loss=2.8 lr=0.001 best [epoch#4] loss=2.688 val_loss=1.784 lr=0.001 best [epoch#5] loss=1.793 val_loss=2.064 lr=0.001 [epoch#6] loss=1.134 val_loss=1.35 lr=0.001 best [epoch#7] loss=0.8556 val_loss=0.6147 lr=0.001 best [epoch#8] loss=0.635 val_loss=0.5546 lr=0.001 best [epoch#9] loss=0.6089 val_loss=0.4768 lr=0.001 best You can update attributes of run's objects at any time. run.trainer.epochs = 5 run.start() [10] 2020-05-30 16:21:03 ( 288ms ) python3 ( 24.2s ) [epoch#10] loss=0.5159 val_loss=0.6315 lr=0.001 [epoch#11] loss=0.5438 val_loss=0.5054 lr=0.001 [epoch#12] loss=0.4831 val_loss=0.3839 lr=0.001 best [epoch#13] loss=0.4455 val_loss=0.3534 lr=0.001 best [epoch#14] loss=0.4898 val_loss=0.3954 lr=0.001 Note The Run.start() method doesn't reset the trainer's epoch.","title":"Using a Trainer"},{"location":"tutorial/training/#callbacks-after-training","text":"After training, the callbacks changes their states. run.metrics # Show metrics at current epoch. [11] 2020-05-30 16:21:03 ( 5.00ms ) python3 ( 24.2s ) Metrics(loss=0.4898, val_loss=0.3954, lr=0.001) run.metrics.history.val_loss # Metrics history. [12] 2020-05-30 16:21:03 ( 5.00ms ) python3 ( 24.2s ) {0: 9.07283158302307, 1: 5.330642098188401, 2: 3.963082951307297, 3: 2.7999730914831162, 4: 1.7839402288198472, 5: 2.0641077041625975, 6: 1.3496331840753555, 7: 0.6146575763821602, 8: 0.5545605823397637, 9: 0.47675749361515046, 10: 0.6315262600779533, 11: 0.5053925298154354, 12: 0.3838960863649845, 13: 0.353401317819953, 14: 0.3953550048172474} run.monitor # Store the best score and its epoch. [13] 2020-05-30 16:21:03 ( 4.00ms ) python3 ( 24.2s ) Monitor(metric='val_loss', mode='min', best_score=0.353, best_epoch=13) run.early_stopping # Current `wait`. [14] 2020-05-30 16:21:03 ( 4.00ms ) python3 ( 24.2s ) EarlyStopping(patience=10, wait=1) run.trainer # Current epoch is 14 (0-indexed). [15] 2020-05-30 16:21:03 ( 4.00ms ) python3 ( 24.2s ) Trainer(epoch=14, epochs=5, global_step=899, verbose=2, loss=<function mse_loss at 0x000002682FBE4288>, batch_size=10, shuffle=True, gpu=False, precision=32, amp_level='O1', scheduler_step_mode='epoch')","title":"Callbacks after Training"},{"location":"tutorial/tuning/","text":"Hyperparameter Tuning Suggest Function To optimize a set of hyperparameters, define a suggest function . Here are example functions. File 9 rectangle/suggest.py def suggest_lr(trial, min=1e-5, max=1e-3): trial.suggest_loguniform(\"lr\", min, max) def suggest_hidden_sizes(trial, max_num_layers, min_size=10, max_size=30): num_layers = trial.suggest_int(\"num_layers\", 2, max_num_layers) for k in range(num_layers): trial.suggest_int(f\"hidden_sizes:{k}\", min_size, max_size) A suggest function must take a trial (an instance of Trial ) as the first argument but you can add arbitrary arguments if you need. For more details about what the Trial can do, see the offical Optuna documentation . Note In the suggest_hidden_sizes() function, we use 0-indexed colon-notation , because Optuna doesn't suggest a list itself but its element. These suggest functions don't return any parameters. The only work of suggest functions is to make the Trial instance suggest parameters. Suggested parameters are stored in the Trial instance, so that nothing is needed from suggest functions. Note that an objective function in Optuna has only one trial argument, so that we have to use the functools.partial() function to make a pure suggest function. from functools import partial from rectangle.suggest import suggest_lr, suggest_hidden_sizes lr = partial(suggest_lr, min=1e-5, max=1e-2) hidden_sizes = partial(suggest_hidden_sizes, max_num_layers=3) [3] 2020-05-30 16:21:03 ( 5.00ms ) python3 ( 24.3s ) Study Ivory implements a special run type called Study which controls hyperparameter tuning using Optuna. import ivory client = ivory.create_client(\"examples\") # Set the working directory study_lr = client.create_study('torch', lr=lr) study_hs = client.create_study('torch', hidden_sizes=hidden_sizes) study_lr [4] 2020-05-30 16:21:03 ( 106ms ) python3 ( 24.4s ) [I 200530 16:21:03 tracker:48] A new experiment created with name: 'torch' Study(id='46256053f0764453894a2ea29eff0f8c', name='study#0', num_objects=5) In the client.create_study() function, you can pass a keyword argument in which the key is a suggest name and the value is a pure suggest function. Objective The ivory.core.objective.Objective class provides objective functions that return a score to minimize or maximize. But you don't need to know about the Objective class in details. Ivory builds an objective function from a suggest function and sends it to Optuna so that Optuna can optimize the parameters. A Study instance has an Objective instance. study_lr.objective [5] 2020-05-30 16:21:03 ( 5.00ms ) python3 ( 24.4s ) Objective(['lr']) study_hs.objective [6] 2020-05-30 16:21:03 ( 3.00ms ) python3 ( 24.4s ) Objective(['hidden_sizes']) Optimization Then \"optimize\" the learning rate and hidden sizes just for fun. optuna_study_lr = study_lr.optimize(n_trials=3, fold=3, epochs=3) [7] 2020-05-30 16:21:03 ( 1.94s ) python3 ( 26.4s ) [I 2020-05-30 16:21:03,734] A new study created with name: torch.lr.study#0 [run#0] lr=0.001162 fold=3 epochs=3 [epoch#0] loss=21.33 val_loss=8.713 lr=0.001162 best [epoch#1] loss=7.378 val_loss=7.16 lr=0.001162 best [epoch#2] loss=6.126 val_loss=5.946 lr=0.001162 best [I 2020-05-30 16:21:04,385] Finished trial#0 with value: 5.946157741546631 with parameters: {'lr': 0.0011615489105682442}. Best is trial#0 with value: 5.946157741546631. [run#1] lr=1.731e-05 fold=3 epochs=3 [epoch#0] loss=108.1 val_loss=110.8 lr=1.731e-05 best [epoch#1] loss=103 val_loss=105.4 lr=1.731e-05 best [epoch#2] loss=97.65 val_loss=99.69 lr=1.731e-05 best [I 2020-05-30 16:21:05,004] Finished trial#1 with value: 99.6929874420166 with parameters: {'lr': 1.7308156422436674e-05}. Best is trial#0 with value: 5.946157741546631. [run#2] lr=5.87e-05 fold=3 epochs=3 [epoch#0] loss=98.14 val_loss=93.91 lr=5.87e-05 best [epoch#1] loss=78.3 val_loss=69.29 lr=5.87e-05 best [epoch#2] loss=51.4 val_loss=38.99 lr=5.87e-05 best [I 2020-05-30 16:21:05,629] Finished trial#2 with value: 38.985439682006835 with parameters: {'lr': 5.869870250578206e-05}. Best is trial#0 with value: 5.946157741546631. optuna_study_hs = study_hs.optimize(n_trials=3, epochs=3) [8] 2020-05-30 16:21:05 ( 2.06s ) python3 ( 28.4s ) [I 2020-05-30 16:21:05,659] A new study created with name: torch.hidden_sizes.study#1 [run#3] hidden_sizes:0=10 hidden_sizes:1=18 hidden_sizes:2=14 num_layers=3 epochs=3 [epoch#0] loss=35.99 val_loss=10.58 lr=0.001 best [epoch#1] loss=9.618 val_loss=8.644 lr=0.001 best [epoch#2] loss=8.924 val_loss=7.854 lr=0.001 best [I 2020-05-30 16:21:06,360] Finished trial#0 with value: 7.854496133327484 with parameters: {'hidden_sizes:0': 10, 'hidden_sizes:1': 18, 'hidden_sizes:2': 14, 'num_layers': 3}. Best is trial#0 with value: 7.854496133327484. [run#4] hidden_sizes:0=27 hidden_sizes:1=28 num_layers=2 epochs=3 [epoch#0] loss=22.5 val_loss=7.242 lr=0.001 best [epoch#1] loss=7.146 val_loss=6.653 lr=0.001 best [epoch#2] loss=6.394 val_loss=5.772 lr=0.001 best [I 2020-05-30 16:21:07,025] Finished trial#1 with value: 5.772146391868591 with parameters: {'hidden_sizes:0': 27, 'hidden_sizes:1': 28, 'num_layers': 2}. Best is trial#1 with value: 5.772146391868591. [run#5] hidden_sizes:0=14 hidden_sizes:1=20 hidden_sizes:2=13 num_layers=3 epochs=3 [epoch#0] loss=35.51 val_loss=8.824 lr=0.001 best [epoch#1] loss=9.398 val_loss=7.871 lr=0.001 best [epoch#2] loss=8.045 val_loss=7.054 lr=0.001 best [I 2020-05-30 16:21:07,691] Finished trial#2 with value: 7.0543858170509335 with parameters: {'hidden_sizes:0': 14, 'hidden_sizes:1': 20, 'hidden_sizes:2': 13, 'num_layers': 3}. Best is trial#1 with value: 5.772146391868591. Note By cliking an icon ( ) in the above cells, you can see the Optuna's log. The returned value of the study.optimize() is an Optuna's Study instance (not Ivory's one). optuna_study_lr [9] 2020-05-30 16:21:07 ( 3.00ms ) python3 ( 28.4s ) <optuna.study.Study at 0x26a141a0cc8> The Study instance is named after the experiment name, suggest name, and run name. optuna_study_lr.study_name [10] 2020-05-30 16:21:07 ( 4.00ms ) python3 ( 28.4s ) 'torch.lr.study#0' In user attributes that Optuna's Study and Trial instances provide, RunID is saved. optuna_study_lr.user_attrs [11] 2020-05-30 16:21:07 ( 4.00ms ) python3 ( 28.4s ) {'run_id': '46256053f0764453894a2ea29eff0f8c'} optuna_study_lr.trials[0].user_attrs [12] 2020-05-30 16:21:07 ( 6.00ms ) python3 ( 28.4s ) {'run_id': '32392acb5fc544e48774b637becb0afc'} On the other hand, MLFlow Tracking's run (not Ivory's one) has a tag to refer Optuna's study and trial. mlflow_client = client.tracker.client mlflow_client [13] 2020-05-30 16:21:07 ( 3.00ms ) python3 ( 28.4s ) <mlflow.tracking.client.MlflowClient at 0x26a08e81fc8> run_id = optuna_study_lr.user_attrs['run_id'] run = mlflow_client.get_run(run_id) run.data.tags['study_name'] [14] 2020-05-30 16:21:07 ( 7.00ms ) python3 ( 28.4s ) 'torch.lr.study#0' run_id = optuna_study_lr.trials[0].user_attrs['run_id'] run = mlflow_client.get_run(run_id) run.data.tags['trial_number'] [15] 2020-05-30 16:21:07 ( 11.0ms ) python3 ( 28.5s ) '0' You may have a question. How does Optuna optimize the parameters without any score? The answer is the Monitor instance. An Objective instance gets the monitoring score from run.monitor and sends it to Optuna so that Optuna can determine the next suggestion. All you need is to make your Run instance have a Monitor instance. Check the YAML parameter file: File 10 torch.yml library: torch datasets: data: class: rectangle.data.Data n_splits: 4 dataset: fold: 0 model: class: rectangle.torch.Model hidden_sizes: [20, 30] optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 1e-3 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: metrics: monitor: metric: val_loss early_stopping: patience: 10 trainer: loss: torch.nn.functional.mse_loss batch_size: 10 epochs: 10 verbose: 2 The Monitor instance monitors val_loss (actually this is the default value, so that you can delete this line) and the default mode is min (smaller is better). If your monitor is accuracy, for example, set the monitor like this: monitor: metric: accuracy mode: max Parametric Optimization Again read the suggest functions. File 11 rectangle/suggest.py def suggest_lr(trial, min=1e-5, max=1e-3): trial.suggest_loguniform(\"lr\", min, max) def suggest_hidden_sizes(trial, max_num_layers, min_size=10, max_size=30): num_layers = trial.suggest_int(\"num_layers\", 2, max_num_layers) for k in range(num_layers): trial.suggest_int(f\"hidden_sizes:{k}\", min_size, max_size) The suggest_hidden_sizes() function has some logic but the code of the suggest_lr() function is too simple to define a function. You may not want to write such a function. Ivory can do that for you. You can pass key-iterable pairs to the client.create_study() function instead of key-callable pairs. tuple, range, Range A tuple, range, or Range instance represents parameter range. study = client.create_study('torch', lr=(1e-3, 1e-2)) _ = study.optimize(n_trials=5, epochs=1, verbose=0) [16] 2020-05-30 16:21:07 ( 2.15s ) python3 ( 30.6s ) [I 2020-05-30 16:21:07,826] A new study created with name: torch.lr.study#2 [run#6] lr=0.006373 epochs=1 [I 2020-05-30 16:21:08,251] Finished trial#0 with value: 13.06497323513031 with parameters: {'lr': 0.0063730206002892325}. Best is trial#0 with value: 13.06497323513031. [run#7] lr=0.005542 epochs=1 [I 2020-05-30 16:21:08,648] Finished trial#1 with value: 23.722581911087037 with parameters: {'lr': 0.0055420033453726794}. Best is trial#0 with value: 13.06497323513031. [run#8] lr=0.001796 epochs=1 [I 2020-05-30 16:21:09,059] Finished trial#2 with value: 6.396551394462586 with parameters: {'lr': 0.0017962443005900336}. Best is trial#2 with value: 6.396551394462586. [run#9] lr=0.00828 epochs=1 [I 2020-05-30 16:21:09,464] Finished trial#3 with value: 44.09297480583191 with parameters: {'lr': 0.008280008845782515}. Best is trial#2 with value: 6.396551394462586. [run#10] lr=0.006705 epochs=1 [I 2020-05-30 16:21:09,894] Finished trial#4 with value: 22.682585144042967 with parameters: {'lr': 0.006705493906174322}. Best is trial#2 with value: 6.396551394462586. In the above cell, lr=Range(1e-3, 1e-2) also works. For integer parameters, you can use normal range as well as tuple or Range . params = {'hidden_sizes.0': range(10, 20)} study = client.create_study('torch', params) _ = study.optimize(n_trials=5, epochs=1, verbose=0) [17] 2020-05-30 16:21:09 ( 2.22s ) python3 ( 32.8s ) [I 2020-05-30 16:21:09,992] A new study created with name: torch.hidden_sizes.0.study#3 [run#11] hidden_sizes.0=10 epochs=1 [I 2020-05-30 16:21:10,407] Finished trial#0 with value: 8.225177800655365 with parameters: {'hidden_sizes.0': 10}. Best is trial#0 with value: 8.225177800655365. [run#12] hidden_sizes.0=15 epochs=1 [I 2020-05-30 16:21:10,845] Finished trial#1 with value: 8.317616879940033 with parameters: {'hidden_sizes.0': 15}. Best is trial#0 with value: 8.225177800655365. [run#13] hidden_sizes.0=10 epochs=1 [I 2020-05-30 16:21:11,267] Finished trial#2 with value: 7.582435202598572 with parameters: {'hidden_sizes.0': 10}. Best is trial#2 with value: 7.582435202598572. [run#14] hidden_sizes.0=16 epochs=1 [I 2020-05-30 16:21:11,688] Finished trial#3 with value: 7.729201233386993 with parameters: {'hidden_sizes.0': 16}. Best is trial#2 with value: 7.582435202598572. [run#15] hidden_sizes.0=15 epochs=1 [I 2020-05-30 16:21:12,115] Finished trial#4 with value: 8.239565718173981 with parameters: {'hidden_sizes.0': 15}. Best is trial#2 with value: 7.582435202598572. You can specify a step params = {'hidden_sizes.0': range(10, 20, 3)} study = client.create_study('torch', params) _ = study.optimize(n_trials=5, epochs=1, verbose=0) [18] 2020-05-30 16:21:12 ( 2.34s ) python3 ( 35.2s ) [I 2020-05-30 16:21:12,225] A new study created with name: torch.hidden_sizes.0.study#4 [run#16] hidden_sizes.0=19 epochs=1 [I 2020-05-30 16:21:12,693] Finished trial#0 with value: 8.773016667366027 with parameters: {'hidden_sizes.0': 19}. Best is trial#0 with value: 8.773016667366027. [run#17] hidden_sizes.0=10 epochs=1 [I 2020-05-30 16:21:13,126] Finished trial#1 with value: 7.978509604930878 with parameters: {'hidden_sizes.0': 10}. Best is trial#1 with value: 7.978509604930878. [run#18] hidden_sizes.0=16 epochs=1 [I 2020-05-30 16:21:13,575] Finished trial#2 with value: 6.835799562931061 with parameters: {'hidden_sizes.0': 16}. Best is trial#2 with value: 6.835799562931061. [run#19] hidden_sizes.0=10 epochs=1 [I 2020-05-30 16:21:14,017] Finished trial#3 with value: 6.8263637065887455 with parameters: {'hidden_sizes.0': 10}. Best is trial#3 with value: 6.8263637065887455. [run#20] hidden_sizes.0=10 epochs=1 [I 2020-05-30 16:21:14,461] Finished trial#4 with value: 9.080605137348176 with parameters: {'hidden_sizes.0': 10}. Best is trial#3 with value: 6.8263637065887455. If you need sampling in log scale, use Range with log=True . from ivory.utils.range import Range study = client.create_study('torch', lr=Range(1e-3, 1e-2, log=True)) _ = study.optimize(n_trials=5, epochs=1, verbose=0) [19] 2020-05-30 16:21:14 ( 2.44s ) python3 ( 37.6s ) [I 2020-05-30 16:21:14,586] A new study created with name: torch.lr.study#5 [run#21] lr=0.001268 epochs=1 [I 2020-05-30 16:21:15,059] Finished trial#0 with value: 6.160090672969818 with parameters: {'lr': 0.0012681705164193893}. Best is trial#0 with value: 6.160090672969818. [run#22] lr=0.001002 epochs=1 [I 2020-05-30 16:21:15,525] Finished trial#1 with value: 7.261878383159638 with parameters: {'lr': 0.001001630390167924}. Best is trial#0 with value: 6.160090672969818. [run#23] lr=0.001532 epochs=1 [I 2020-05-30 16:21:15,983] Finished trial#2 with value: 8.25329647064209 with parameters: {'lr': 0.0015317522840502373}. Best is trial#0 with value: 6.160090672969818. [run#24] lr=0.004811 epochs=1 [I 2020-05-30 16:21:16,441] Finished trial#3 with value: 9.890727862715721 with parameters: {'lr': 0.004810586455660262}. Best is trial#0 with value: 6.160090672969818. [run#25] lr=0.001871 epochs=1 [I 2020-05-30 16:21:16,903] Finished trial#4 with value: 7.948227286338806 with parameters: {'lr': 0.0018709114198870204}. Best is trial#0 with value: 6.160090672969818. list A list represents parameter choice. params = {'hidden_sizes.0': [10, 20, 30]} study = client.create_study('torch', params) _ = study.optimize(n_trials=5, epochs=1, verbose=0) [20] 2020-05-30 16:21:16 ( 2.51s ) python3 ( 40.1s ) [I 2020-05-30 16:21:17,058] A new study created with name: torch.hidden_sizes.0.study#6 [run#26] hidden_sizes.0=30 epochs=1 [I 2020-05-30 16:21:17,529] Finished trial#0 with value: 8.483554589748383 with parameters: {'hidden_sizes.0': 30}. Best is trial#0 with value: 8.483554589748383. [run#27] hidden_sizes.0=30 epochs=1 [I 2020-05-30 16:21:18,005] Finished trial#1 with value: 7.632884705066681 with parameters: {'hidden_sizes.0': 30}. Best is trial#1 with value: 7.632884705066681. [run#28] hidden_sizes.0=30 epochs=1 [I 2020-05-30 16:21:18,473] Finished trial#2 with value: 6.967569494247437 with parameters: {'hidden_sizes.0': 30}. Best is trial#2 with value: 6.967569494247437. [run#29] hidden_sizes.0=10 epochs=1 [I 2020-05-30 16:21:18,940] Finished trial#3 with value: 7.66311936378479 with parameters: {'hidden_sizes.0': 10}. Best is trial#2 with value: 6.967569494247437. [run#30] hidden_sizes.0=20 epochs=1 [I 2020-05-30 16:21:19,412] Finished trial#4 with value: 9.244291877746582 with parameters: {'hidden_sizes.0': 20}. Best is trial#2 with value: 6.967569494247437. Product If a key and value are tuples, the entry means cartesian product of suggest functions like Task.product() . params = {('hidden_sizes', 'lr'): (hidden_sizes, Range(1e-4, 1e-3))} study = client.create_study('torch', params) optuna_study = study.optimize(n_trials=10, epochs=1, verbose=0) [21] 2020-05-30 16:21:19 ( 5.61s ) python3 ( 45.7s ) [I 2020-05-30 16:21:19,572] A new study created with name: torch.hidden_sizes.lr.study#7 [run#31] hidden_sizes:0=12 hidden_sizes:1=20 hidden_sizes:2=22 lr=0.0004221 num_layers=3 epochs=1 [I 2020-05-30 16:21:20,129] Finished trial#0 with value: 74.10611133575439 with parameters: {'hidden_sizes:0': 12, 'hidden_sizes:1': 20, 'hidden_sizes:2': 22, 'lr': 0.00042207389833183977, 'num_layers': 3}. Best is trial#0 with value: 74.10611133575439. [run#32] hidden_sizes:0=20 hidden_sizes:1=24 lr=0.0008275 num_layers=2 epochs=1 [I 2020-05-30 16:21:20,651] Finished trial#1 with value: 8.098038172721862 with parameters: {'hidden_sizes:0': 20, 'hidden_sizes:1': 24, 'lr': 0.000827520795979748, 'num_layers': 2}. Best is trial#1 with value: 8.098038172721862. [run#33] hidden_sizes:0=30 hidden_sizes:1=12 hidden_sizes:2=25 lr=0.000294 num_layers=3 epochs=1 [I 2020-05-30 16:21:21,195] Finished trial#2 with value: 78.10075788497925 with parameters: {'hidden_sizes:0': 30, 'hidden_sizes:1': 12, 'hidden_sizes:2': 25, 'lr': 0.0002939938053063356, 'num_layers': 3}. Best is trial#1 with value: 8.098038172721862. [run#34] hidden_sizes:0=16 hidden_sizes:1=29 hidden_sizes:2=11 lr=0.0006987 num_layers=3 epochs=1 [I 2020-05-30 16:21:21,740] Finished trial#3 with value: 9.046184372901916 with parameters: {'hidden_sizes:0': 16, 'hidden_sizes:1': 29, 'hidden_sizes:2': 11, 'lr': 0.0006987258870869795, 'num_layers': 3}. Best is trial#1 with value: 8.098038172721862. [run#35] hidden_sizes:0=11 hidden_sizes:1=20 lr=0.0005005 num_layers=2 epochs=1 [I 2020-05-30 16:21:22,282] Finished trial#4 with value: 7.213297444581985 with parameters: {'hidden_sizes:0': 11, 'hidden_sizes:1': 20, 'lr': 0.0005004910155482576, 'num_layers': 2}. Best is trial#4 with value: 7.213297444581985. [run#36] hidden_sizes:0=24 hidden_sizes:1=12 hidden_sizes:2=15 lr=0.0007677 num_layers=3 epochs=1 [I 2020-05-30 16:21:22,831] Finished trial#5 with value: 8.231700348854066 with parameters: {'hidden_sizes:0': 24, 'hidden_sizes:1': 12, 'hidden_sizes:2': 15, 'lr': 0.0007677205561129921, 'num_layers': 3}. Best is trial#4 with value: 7.213297444581985. [run#37] hidden_sizes:0=16 hidden_sizes:1=29 lr=0.0003588 num_layers=2 epochs=1 [I 2020-05-30 16:21:23,363] Finished trial#6 with value: 8.06752678155899 with parameters: {'hidden_sizes:0': 16, 'hidden_sizes:1': 29, 'lr': 0.0003588099853395727, 'num_layers': 2}. Best is trial#4 with value: 7.213297444581985. [run#38] hidden_sizes:0=27 hidden_sizes:1=12 hidden_sizes:2=25 lr=0.0003427 num_layers=3 epochs=1 [I 2020-05-30 16:21:23,933] Finished trial#7 with value: 10.450584828853607 with parameters: {'hidden_sizes:0': 27, 'hidden_sizes:1': 12, 'hidden_sizes:2': 25, 'lr': 0.00034273119167598203, 'num_layers': 3}. Best is trial#4 with value: 7.213297444581985. [run#39] hidden_sizes:0=30 hidden_sizes:1=20 lr=0.0008172 num_layers=2 epochs=1 [I 2020-05-30 16:21:24,470] Finished trial#8 with value: 5.795502430200576 with parameters: {'hidden_sizes:0': 30, 'hidden_sizes:1': 20, 'lr': 0.0008171889599402527, 'num_layers': 2}. Best is trial#8 with value: 5.795502430200576. [run#40] hidden_sizes:0=26 hidden_sizes:1=30 lr=0.0009875 num_layers=2 epochs=1 [I 2020-05-30 16:21:25,023] Finished trial#9 with value: 7.292723047733307 with parameters: {'hidden_sizes:0': 26, 'hidden_sizes:1': 30, 'lr': 0.000987491471845785, 'num_layers': 2}. Best is trial#8 with value: 5.795502430200576. Note You can mix suggest funtions and parametric optimization. Note You may feel that \" params = {'hidden_sizes.1': hidden_sizes, 'lr': Range(1e-4, 1e-3)} \" is better, but the above style is intentional. In parametric optimization, the name of Optuna's Study instance is dot-joint style : optuna_study.study_name [22] 2020-05-30 16:21:25 ( 5.00ms ) python3 ( 45.7s ) 'torch.hidden_sizes.lr.study#7' Study from YAML file As a normal Run , a Study instance also can be created from a YAML file. Pass an extra keyword argument to the client.create_experiment() function. The key is the instance name (in this case study ) and value is a YAML file name without its extension. experiment = client.create_experiment('torch', study='study') experiment [23] 2020-05-30 16:21:25 ( 10.0ms ) python3 ( 45.7s ) Experiment(id='1', name='torch', num_objects=1) Here is the contents of study.yml file. File 12 study.yml objective: lr: rectangle.suggest.suggest_lr hidden_sizes: def: rectangle.suggest.suggest_hidden_sizes max_num_layers: 3 min_size: __default__ max_size: __default__ Suggest functions should be callable, hidden_sizes uses def keyword to create a callable. On the other hand, lr is just one line. If a suggest funtion can be called without additional arguments, you can omit the def keyword. Using this experiment, we can create Study instances with a suggest function. study_lr = client.create_study('torch', 'lr') study_lr.objective [24] 2020-05-30 16:21:25 ( 174ms ) python3 ( 45.9s ) Objective(['lr']) study_hs = client.create_study('torch', 'hidden_sizes') study_hs.objective [25] 2020-05-30 16:21:25 ( 186ms ) python3 ( 46.1s ) Objective(['hidden_sizes']) study_hs.objective.hidden_sizes [26] 2020-05-30 16:21:25 ( 3.00ms ) python3 ( 46.1s ) functools.partial(<function suggest_hidden_sizes at 0x00000269FD08C798>, max_num_layers=3, min_size=10, max_size=30) For min_size and max_size , default values are inspected from the signature. study_lr.optimize(n_trials=3, epochs=3, verbose=0) [27] 2020-05-30 16:21:25 ( 2.33s ) python3 ( 48.4s ) [I 2020-05-30 16:21:25,441] A new study created with name: torch.lr.study#8 [run#41] lr=1.4e-05 epochs=3 [I 2020-05-30 16:21:26,201] Finished trial#0 with value: 83.7037977218628 with parameters: {'lr': 1.4003049046885165e-05}. Best is trial#0 with value: 83.7037977218628. [run#42] lr=0.0008086 epochs=3 [I 2020-05-30 16:21:26,969] Finished trial#1 with value: 7.2571200132369995 with parameters: {'lr': 0.0008085538449343595}. Best is trial#1 with value: 7.2571200132369995. [run#43] lr=0.0001357 epochs=3 [I 2020-05-30 16:21:27,739] Finished trial#2 with value: 7.968274736404419 with parameters: {'lr': 0.0001356837134362589}. Best is trial#1 with value: 7.2571200132369995. <optuna.study.Study at 0x26a142bbe48> Pruning Optuna provides the pruning functionality . Ivory can uses this feature seamlessly. Here is the updated contents of study.yml file. File 13 study.yml tuner: pruner: class: optuna.pruners.MedianPruner objective: lr: rectangle.suggest.suggest_lr hidden_sizes: def: rectangle.suggest.suggest_hidden_sizes max_num_layers: 3 min_size: __default__ max_size: __default__ The Tuner instance has Optuna's MedianPruner . (Off course, you can use other pruners .) A Study instance give an ivory.callbacks.Pruning instance to a run when the run is created, then with Ivory's callback system , the Pruning instance communicates with Optuna in order to determine the step of pruning. Note Pruning is supported for PyTorch and TensorFlow now.","title":"<span class=\"pheasant-header\"><span class=\"header\"><span class=\"title\">Hyperparameter Tuning</span></span></span>"},{"location":"tutorial/tuning/#hyperparameter-tuning","text":"","title":"Hyperparameter Tuning"},{"location":"tutorial/tuning/#suggest-function","text":"To optimize a set of hyperparameters, define a suggest function . Here are example functions. File 9 rectangle/suggest.py def suggest_lr(trial, min=1e-5, max=1e-3): trial.suggest_loguniform(\"lr\", min, max) def suggest_hidden_sizes(trial, max_num_layers, min_size=10, max_size=30): num_layers = trial.suggest_int(\"num_layers\", 2, max_num_layers) for k in range(num_layers): trial.suggest_int(f\"hidden_sizes:{k}\", min_size, max_size) A suggest function must take a trial (an instance of Trial ) as the first argument but you can add arbitrary arguments if you need. For more details about what the Trial can do, see the offical Optuna documentation . Note In the suggest_hidden_sizes() function, we use 0-indexed colon-notation , because Optuna doesn't suggest a list itself but its element. These suggest functions don't return any parameters. The only work of suggest functions is to make the Trial instance suggest parameters. Suggested parameters are stored in the Trial instance, so that nothing is needed from suggest functions. Note that an objective function in Optuna has only one trial argument, so that we have to use the functools.partial() function to make a pure suggest function. from functools import partial from rectangle.suggest import suggest_lr, suggest_hidden_sizes lr = partial(suggest_lr, min=1e-5, max=1e-2) hidden_sizes = partial(suggest_hidden_sizes, max_num_layers=3) [3] 2020-05-30 16:21:03 ( 5.00ms ) python3 ( 24.3s )","title":"Suggest Function"},{"location":"tutorial/tuning/#study","text":"Ivory implements a special run type called Study which controls hyperparameter tuning using Optuna. import ivory client = ivory.create_client(\"examples\") # Set the working directory study_lr = client.create_study('torch', lr=lr) study_hs = client.create_study('torch', hidden_sizes=hidden_sizes) study_lr [4] 2020-05-30 16:21:03 ( 106ms ) python3 ( 24.4s ) [I 200530 16:21:03 tracker:48] A new experiment created with name: 'torch' Study(id='46256053f0764453894a2ea29eff0f8c', name='study#0', num_objects=5) In the client.create_study() function, you can pass a keyword argument in which the key is a suggest name and the value is a pure suggest function.","title":"Study"},{"location":"tutorial/tuning/#objective","text":"The ivory.core.objective.Objective class provides objective functions that return a score to minimize or maximize. But you don't need to know about the Objective class in details. Ivory builds an objective function from a suggest function and sends it to Optuna so that Optuna can optimize the parameters. A Study instance has an Objective instance. study_lr.objective [5] 2020-05-30 16:21:03 ( 5.00ms ) python3 ( 24.4s ) Objective(['lr']) study_hs.objective [6] 2020-05-30 16:21:03 ( 3.00ms ) python3 ( 24.4s ) Objective(['hidden_sizes'])","title":"Objective"},{"location":"tutorial/tuning/#optimization","text":"Then \"optimize\" the learning rate and hidden sizes just for fun. optuna_study_lr = study_lr.optimize(n_trials=3, fold=3, epochs=3) [7] 2020-05-30 16:21:03 ( 1.94s ) python3 ( 26.4s ) [I 2020-05-30 16:21:03,734] A new study created with name: torch.lr.study#0 [run#0] lr=0.001162 fold=3 epochs=3 [epoch#0] loss=21.33 val_loss=8.713 lr=0.001162 best [epoch#1] loss=7.378 val_loss=7.16 lr=0.001162 best [epoch#2] loss=6.126 val_loss=5.946 lr=0.001162 best [I 2020-05-30 16:21:04,385] Finished trial#0 with value: 5.946157741546631 with parameters: {'lr': 0.0011615489105682442}. Best is trial#0 with value: 5.946157741546631. [run#1] lr=1.731e-05 fold=3 epochs=3 [epoch#0] loss=108.1 val_loss=110.8 lr=1.731e-05 best [epoch#1] loss=103 val_loss=105.4 lr=1.731e-05 best [epoch#2] loss=97.65 val_loss=99.69 lr=1.731e-05 best [I 2020-05-30 16:21:05,004] Finished trial#1 with value: 99.6929874420166 with parameters: {'lr': 1.7308156422436674e-05}. Best is trial#0 with value: 5.946157741546631. [run#2] lr=5.87e-05 fold=3 epochs=3 [epoch#0] loss=98.14 val_loss=93.91 lr=5.87e-05 best [epoch#1] loss=78.3 val_loss=69.29 lr=5.87e-05 best [epoch#2] loss=51.4 val_loss=38.99 lr=5.87e-05 best [I 2020-05-30 16:21:05,629] Finished trial#2 with value: 38.985439682006835 with parameters: {'lr': 5.869870250578206e-05}. Best is trial#0 with value: 5.946157741546631. optuna_study_hs = study_hs.optimize(n_trials=3, epochs=3) [8] 2020-05-30 16:21:05 ( 2.06s ) python3 ( 28.4s ) [I 2020-05-30 16:21:05,659] A new study created with name: torch.hidden_sizes.study#1 [run#3] hidden_sizes:0=10 hidden_sizes:1=18 hidden_sizes:2=14 num_layers=3 epochs=3 [epoch#0] loss=35.99 val_loss=10.58 lr=0.001 best [epoch#1] loss=9.618 val_loss=8.644 lr=0.001 best [epoch#2] loss=8.924 val_loss=7.854 lr=0.001 best [I 2020-05-30 16:21:06,360] Finished trial#0 with value: 7.854496133327484 with parameters: {'hidden_sizes:0': 10, 'hidden_sizes:1': 18, 'hidden_sizes:2': 14, 'num_layers': 3}. Best is trial#0 with value: 7.854496133327484. [run#4] hidden_sizes:0=27 hidden_sizes:1=28 num_layers=2 epochs=3 [epoch#0] loss=22.5 val_loss=7.242 lr=0.001 best [epoch#1] loss=7.146 val_loss=6.653 lr=0.001 best [epoch#2] loss=6.394 val_loss=5.772 lr=0.001 best [I 2020-05-30 16:21:07,025] Finished trial#1 with value: 5.772146391868591 with parameters: {'hidden_sizes:0': 27, 'hidden_sizes:1': 28, 'num_layers': 2}. Best is trial#1 with value: 5.772146391868591. [run#5] hidden_sizes:0=14 hidden_sizes:1=20 hidden_sizes:2=13 num_layers=3 epochs=3 [epoch#0] loss=35.51 val_loss=8.824 lr=0.001 best [epoch#1] loss=9.398 val_loss=7.871 lr=0.001 best [epoch#2] loss=8.045 val_loss=7.054 lr=0.001 best [I 2020-05-30 16:21:07,691] Finished trial#2 with value: 7.0543858170509335 with parameters: {'hidden_sizes:0': 14, 'hidden_sizes:1': 20, 'hidden_sizes:2': 13, 'num_layers': 3}. Best is trial#1 with value: 5.772146391868591. Note By cliking an icon ( ) in the above cells, you can see the Optuna's log. The returned value of the study.optimize() is an Optuna's Study instance (not Ivory's one). optuna_study_lr [9] 2020-05-30 16:21:07 ( 3.00ms ) python3 ( 28.4s ) <optuna.study.Study at 0x26a141a0cc8> The Study instance is named after the experiment name, suggest name, and run name. optuna_study_lr.study_name [10] 2020-05-30 16:21:07 ( 4.00ms ) python3 ( 28.4s ) 'torch.lr.study#0' In user attributes that Optuna's Study and Trial instances provide, RunID is saved. optuna_study_lr.user_attrs [11] 2020-05-30 16:21:07 ( 4.00ms ) python3 ( 28.4s ) {'run_id': '46256053f0764453894a2ea29eff0f8c'} optuna_study_lr.trials[0].user_attrs [12] 2020-05-30 16:21:07 ( 6.00ms ) python3 ( 28.4s ) {'run_id': '32392acb5fc544e48774b637becb0afc'} On the other hand, MLFlow Tracking's run (not Ivory's one) has a tag to refer Optuna's study and trial. mlflow_client = client.tracker.client mlflow_client [13] 2020-05-30 16:21:07 ( 3.00ms ) python3 ( 28.4s ) <mlflow.tracking.client.MlflowClient at 0x26a08e81fc8> run_id = optuna_study_lr.user_attrs['run_id'] run = mlflow_client.get_run(run_id) run.data.tags['study_name'] [14] 2020-05-30 16:21:07 ( 7.00ms ) python3 ( 28.4s ) 'torch.lr.study#0' run_id = optuna_study_lr.trials[0].user_attrs['run_id'] run = mlflow_client.get_run(run_id) run.data.tags['trial_number'] [15] 2020-05-30 16:21:07 ( 11.0ms ) python3 ( 28.5s ) '0' You may have a question. How does Optuna optimize the parameters without any score? The answer is the Monitor instance. An Objective instance gets the monitoring score from run.monitor and sends it to Optuna so that Optuna can determine the next suggestion. All you need is to make your Run instance have a Monitor instance. Check the YAML parameter file: File 10 torch.yml library: torch datasets: data: class: rectangle.data.Data n_splits: 4 dataset: fold: 0 model: class: rectangle.torch.Model hidden_sizes: [20, 30] optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 1e-3 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: metrics: monitor: metric: val_loss early_stopping: patience: 10 trainer: loss: torch.nn.functional.mse_loss batch_size: 10 epochs: 10 verbose: 2 The Monitor instance monitors val_loss (actually this is the default value, so that you can delete this line) and the default mode is min (smaller is better). If your monitor is accuracy, for example, set the monitor like this: monitor: metric: accuracy mode: max","title":"Optimization"},{"location":"tutorial/tuning/#parametric-optimization","text":"Again read the suggest functions. File 11 rectangle/suggest.py def suggest_lr(trial, min=1e-5, max=1e-3): trial.suggest_loguniform(\"lr\", min, max) def suggest_hidden_sizes(trial, max_num_layers, min_size=10, max_size=30): num_layers = trial.suggest_int(\"num_layers\", 2, max_num_layers) for k in range(num_layers): trial.suggest_int(f\"hidden_sizes:{k}\", min_size, max_size) The suggest_hidden_sizes() function has some logic but the code of the suggest_lr() function is too simple to define a function. You may not want to write such a function. Ivory can do that for you. You can pass key-iterable pairs to the client.create_study() function instead of key-callable pairs.","title":"Parametric Optimization"},{"location":"tutorial/tuning/#tuple-range-range","text":"A tuple, range, or Range instance represents parameter range. study = client.create_study('torch', lr=(1e-3, 1e-2)) _ = study.optimize(n_trials=5, epochs=1, verbose=0) [16] 2020-05-30 16:21:07 ( 2.15s ) python3 ( 30.6s ) [I 2020-05-30 16:21:07,826] A new study created with name: torch.lr.study#2 [run#6] lr=0.006373 epochs=1 [I 2020-05-30 16:21:08,251] Finished trial#0 with value: 13.06497323513031 with parameters: {'lr': 0.0063730206002892325}. Best is trial#0 with value: 13.06497323513031. [run#7] lr=0.005542 epochs=1 [I 2020-05-30 16:21:08,648] Finished trial#1 with value: 23.722581911087037 with parameters: {'lr': 0.0055420033453726794}. Best is trial#0 with value: 13.06497323513031. [run#8] lr=0.001796 epochs=1 [I 2020-05-30 16:21:09,059] Finished trial#2 with value: 6.396551394462586 with parameters: {'lr': 0.0017962443005900336}. Best is trial#2 with value: 6.396551394462586. [run#9] lr=0.00828 epochs=1 [I 2020-05-30 16:21:09,464] Finished trial#3 with value: 44.09297480583191 with parameters: {'lr': 0.008280008845782515}. Best is trial#2 with value: 6.396551394462586. [run#10] lr=0.006705 epochs=1 [I 2020-05-30 16:21:09,894] Finished trial#4 with value: 22.682585144042967 with parameters: {'lr': 0.006705493906174322}. Best is trial#2 with value: 6.396551394462586. In the above cell, lr=Range(1e-3, 1e-2) also works. For integer parameters, you can use normal range as well as tuple or Range . params = {'hidden_sizes.0': range(10, 20)} study = client.create_study('torch', params) _ = study.optimize(n_trials=5, epochs=1, verbose=0) [17] 2020-05-30 16:21:09 ( 2.22s ) python3 ( 32.8s ) [I 2020-05-30 16:21:09,992] A new study created with name: torch.hidden_sizes.0.study#3 [run#11] hidden_sizes.0=10 epochs=1 [I 2020-05-30 16:21:10,407] Finished trial#0 with value: 8.225177800655365 with parameters: {'hidden_sizes.0': 10}. Best is trial#0 with value: 8.225177800655365. [run#12] hidden_sizes.0=15 epochs=1 [I 2020-05-30 16:21:10,845] Finished trial#1 with value: 8.317616879940033 with parameters: {'hidden_sizes.0': 15}. Best is trial#0 with value: 8.225177800655365. [run#13] hidden_sizes.0=10 epochs=1 [I 2020-05-30 16:21:11,267] Finished trial#2 with value: 7.582435202598572 with parameters: {'hidden_sizes.0': 10}. Best is trial#2 with value: 7.582435202598572. [run#14] hidden_sizes.0=16 epochs=1 [I 2020-05-30 16:21:11,688] Finished trial#3 with value: 7.729201233386993 with parameters: {'hidden_sizes.0': 16}. Best is trial#2 with value: 7.582435202598572. [run#15] hidden_sizes.0=15 epochs=1 [I 2020-05-30 16:21:12,115] Finished trial#4 with value: 8.239565718173981 with parameters: {'hidden_sizes.0': 15}. Best is trial#2 with value: 7.582435202598572. You can specify a step params = {'hidden_sizes.0': range(10, 20, 3)} study = client.create_study('torch', params) _ = study.optimize(n_trials=5, epochs=1, verbose=0) [18] 2020-05-30 16:21:12 ( 2.34s ) python3 ( 35.2s ) [I 2020-05-30 16:21:12,225] A new study created with name: torch.hidden_sizes.0.study#4 [run#16] hidden_sizes.0=19 epochs=1 [I 2020-05-30 16:21:12,693] Finished trial#0 with value: 8.773016667366027 with parameters: {'hidden_sizes.0': 19}. Best is trial#0 with value: 8.773016667366027. [run#17] hidden_sizes.0=10 epochs=1 [I 2020-05-30 16:21:13,126] Finished trial#1 with value: 7.978509604930878 with parameters: {'hidden_sizes.0': 10}. Best is trial#1 with value: 7.978509604930878. [run#18] hidden_sizes.0=16 epochs=1 [I 2020-05-30 16:21:13,575] Finished trial#2 with value: 6.835799562931061 with parameters: {'hidden_sizes.0': 16}. Best is trial#2 with value: 6.835799562931061. [run#19] hidden_sizes.0=10 epochs=1 [I 2020-05-30 16:21:14,017] Finished trial#3 with value: 6.8263637065887455 with parameters: {'hidden_sizes.0': 10}. Best is trial#3 with value: 6.8263637065887455. [run#20] hidden_sizes.0=10 epochs=1 [I 2020-05-30 16:21:14,461] Finished trial#4 with value: 9.080605137348176 with parameters: {'hidden_sizes.0': 10}. Best is trial#3 with value: 6.8263637065887455. If you need sampling in log scale, use Range with log=True . from ivory.utils.range import Range study = client.create_study('torch', lr=Range(1e-3, 1e-2, log=True)) _ = study.optimize(n_trials=5, epochs=1, verbose=0) [19] 2020-05-30 16:21:14 ( 2.44s ) python3 ( 37.6s ) [I 2020-05-30 16:21:14,586] A new study created with name: torch.lr.study#5 [run#21] lr=0.001268 epochs=1 [I 2020-05-30 16:21:15,059] Finished trial#0 with value: 6.160090672969818 with parameters: {'lr': 0.0012681705164193893}. Best is trial#0 with value: 6.160090672969818. [run#22] lr=0.001002 epochs=1 [I 2020-05-30 16:21:15,525] Finished trial#1 with value: 7.261878383159638 with parameters: {'lr': 0.001001630390167924}. Best is trial#0 with value: 6.160090672969818. [run#23] lr=0.001532 epochs=1 [I 2020-05-30 16:21:15,983] Finished trial#2 with value: 8.25329647064209 with parameters: {'lr': 0.0015317522840502373}. Best is trial#0 with value: 6.160090672969818. [run#24] lr=0.004811 epochs=1 [I 2020-05-30 16:21:16,441] Finished trial#3 with value: 9.890727862715721 with parameters: {'lr': 0.004810586455660262}. Best is trial#0 with value: 6.160090672969818. [run#25] lr=0.001871 epochs=1 [I 2020-05-30 16:21:16,903] Finished trial#4 with value: 7.948227286338806 with parameters: {'lr': 0.0018709114198870204}. Best is trial#0 with value: 6.160090672969818.","title":"tuple, range, Range"},{"location":"tutorial/tuning/#list","text":"A list represents parameter choice. params = {'hidden_sizes.0': [10, 20, 30]} study = client.create_study('torch', params) _ = study.optimize(n_trials=5, epochs=1, verbose=0) [20] 2020-05-30 16:21:16 ( 2.51s ) python3 ( 40.1s ) [I 2020-05-30 16:21:17,058] A new study created with name: torch.hidden_sizes.0.study#6 [run#26] hidden_sizes.0=30 epochs=1 [I 2020-05-30 16:21:17,529] Finished trial#0 with value: 8.483554589748383 with parameters: {'hidden_sizes.0': 30}. Best is trial#0 with value: 8.483554589748383. [run#27] hidden_sizes.0=30 epochs=1 [I 2020-05-30 16:21:18,005] Finished trial#1 with value: 7.632884705066681 with parameters: {'hidden_sizes.0': 30}. Best is trial#1 with value: 7.632884705066681. [run#28] hidden_sizes.0=30 epochs=1 [I 2020-05-30 16:21:18,473] Finished trial#2 with value: 6.967569494247437 with parameters: {'hidden_sizes.0': 30}. Best is trial#2 with value: 6.967569494247437. [run#29] hidden_sizes.0=10 epochs=1 [I 2020-05-30 16:21:18,940] Finished trial#3 with value: 7.66311936378479 with parameters: {'hidden_sizes.0': 10}. Best is trial#2 with value: 6.967569494247437. [run#30] hidden_sizes.0=20 epochs=1 [I 2020-05-30 16:21:19,412] Finished trial#4 with value: 9.244291877746582 with parameters: {'hidden_sizes.0': 20}. Best is trial#2 with value: 6.967569494247437.","title":"list"},{"location":"tutorial/tuning/#product","text":"If a key and value are tuples, the entry means cartesian product of suggest functions like Task.product() . params = {('hidden_sizes', 'lr'): (hidden_sizes, Range(1e-4, 1e-3))} study = client.create_study('torch', params) optuna_study = study.optimize(n_trials=10, epochs=1, verbose=0) [21] 2020-05-30 16:21:19 ( 5.61s ) python3 ( 45.7s ) [I 2020-05-30 16:21:19,572] A new study created with name: torch.hidden_sizes.lr.study#7 [run#31] hidden_sizes:0=12 hidden_sizes:1=20 hidden_sizes:2=22 lr=0.0004221 num_layers=3 epochs=1 [I 2020-05-30 16:21:20,129] Finished trial#0 with value: 74.10611133575439 with parameters: {'hidden_sizes:0': 12, 'hidden_sizes:1': 20, 'hidden_sizes:2': 22, 'lr': 0.00042207389833183977, 'num_layers': 3}. Best is trial#0 with value: 74.10611133575439. [run#32] hidden_sizes:0=20 hidden_sizes:1=24 lr=0.0008275 num_layers=2 epochs=1 [I 2020-05-30 16:21:20,651] Finished trial#1 with value: 8.098038172721862 with parameters: {'hidden_sizes:0': 20, 'hidden_sizes:1': 24, 'lr': 0.000827520795979748, 'num_layers': 2}. Best is trial#1 with value: 8.098038172721862. [run#33] hidden_sizes:0=30 hidden_sizes:1=12 hidden_sizes:2=25 lr=0.000294 num_layers=3 epochs=1 [I 2020-05-30 16:21:21,195] Finished trial#2 with value: 78.10075788497925 with parameters: {'hidden_sizes:0': 30, 'hidden_sizes:1': 12, 'hidden_sizes:2': 25, 'lr': 0.0002939938053063356, 'num_layers': 3}. Best is trial#1 with value: 8.098038172721862. [run#34] hidden_sizes:0=16 hidden_sizes:1=29 hidden_sizes:2=11 lr=0.0006987 num_layers=3 epochs=1 [I 2020-05-30 16:21:21,740] Finished trial#3 with value: 9.046184372901916 with parameters: {'hidden_sizes:0': 16, 'hidden_sizes:1': 29, 'hidden_sizes:2': 11, 'lr': 0.0006987258870869795, 'num_layers': 3}. Best is trial#1 with value: 8.098038172721862. [run#35] hidden_sizes:0=11 hidden_sizes:1=20 lr=0.0005005 num_layers=2 epochs=1 [I 2020-05-30 16:21:22,282] Finished trial#4 with value: 7.213297444581985 with parameters: {'hidden_sizes:0': 11, 'hidden_sizes:1': 20, 'lr': 0.0005004910155482576, 'num_layers': 2}. Best is trial#4 with value: 7.213297444581985. [run#36] hidden_sizes:0=24 hidden_sizes:1=12 hidden_sizes:2=15 lr=0.0007677 num_layers=3 epochs=1 [I 2020-05-30 16:21:22,831] Finished trial#5 with value: 8.231700348854066 with parameters: {'hidden_sizes:0': 24, 'hidden_sizes:1': 12, 'hidden_sizes:2': 15, 'lr': 0.0007677205561129921, 'num_layers': 3}. Best is trial#4 with value: 7.213297444581985. [run#37] hidden_sizes:0=16 hidden_sizes:1=29 lr=0.0003588 num_layers=2 epochs=1 [I 2020-05-30 16:21:23,363] Finished trial#6 with value: 8.06752678155899 with parameters: {'hidden_sizes:0': 16, 'hidden_sizes:1': 29, 'lr': 0.0003588099853395727, 'num_layers': 2}. Best is trial#4 with value: 7.213297444581985. [run#38] hidden_sizes:0=27 hidden_sizes:1=12 hidden_sizes:2=25 lr=0.0003427 num_layers=3 epochs=1 [I 2020-05-30 16:21:23,933] Finished trial#7 with value: 10.450584828853607 with parameters: {'hidden_sizes:0': 27, 'hidden_sizes:1': 12, 'hidden_sizes:2': 25, 'lr': 0.00034273119167598203, 'num_layers': 3}. Best is trial#4 with value: 7.213297444581985. [run#39] hidden_sizes:0=30 hidden_sizes:1=20 lr=0.0008172 num_layers=2 epochs=1 [I 2020-05-30 16:21:24,470] Finished trial#8 with value: 5.795502430200576 with parameters: {'hidden_sizes:0': 30, 'hidden_sizes:1': 20, 'lr': 0.0008171889599402527, 'num_layers': 2}. Best is trial#8 with value: 5.795502430200576. [run#40] hidden_sizes:0=26 hidden_sizes:1=30 lr=0.0009875 num_layers=2 epochs=1 [I 2020-05-30 16:21:25,023] Finished trial#9 with value: 7.292723047733307 with parameters: {'hidden_sizes:0': 26, 'hidden_sizes:1': 30, 'lr': 0.000987491471845785, 'num_layers': 2}. Best is trial#8 with value: 5.795502430200576. Note You can mix suggest funtions and parametric optimization. Note You may feel that \" params = {'hidden_sizes.1': hidden_sizes, 'lr': Range(1e-4, 1e-3)} \" is better, but the above style is intentional. In parametric optimization, the name of Optuna's Study instance is dot-joint style : optuna_study.study_name [22] 2020-05-30 16:21:25 ( 5.00ms ) python3 ( 45.7s ) 'torch.hidden_sizes.lr.study#7'","title":"Product"},{"location":"tutorial/tuning/#study-from-yaml-file","text":"As a normal Run , a Study instance also can be created from a YAML file. Pass an extra keyword argument to the client.create_experiment() function. The key is the instance name (in this case study ) and value is a YAML file name without its extension. experiment = client.create_experiment('torch', study='study') experiment [23] 2020-05-30 16:21:25 ( 10.0ms ) python3 ( 45.7s ) Experiment(id='1', name='torch', num_objects=1) Here is the contents of study.yml file. File 12 study.yml objective: lr: rectangle.suggest.suggest_lr hidden_sizes: def: rectangle.suggest.suggest_hidden_sizes max_num_layers: 3 min_size: __default__ max_size: __default__ Suggest functions should be callable, hidden_sizes uses def keyword to create a callable. On the other hand, lr is just one line. If a suggest funtion can be called without additional arguments, you can omit the def keyword. Using this experiment, we can create Study instances with a suggest function. study_lr = client.create_study('torch', 'lr') study_lr.objective [24] 2020-05-30 16:21:25 ( 174ms ) python3 ( 45.9s ) Objective(['lr']) study_hs = client.create_study('torch', 'hidden_sizes') study_hs.objective [25] 2020-05-30 16:21:25 ( 186ms ) python3 ( 46.1s ) Objective(['hidden_sizes']) study_hs.objective.hidden_sizes [26] 2020-05-30 16:21:25 ( 3.00ms ) python3 ( 46.1s ) functools.partial(<function suggest_hidden_sizes at 0x00000269FD08C798>, max_num_layers=3, min_size=10, max_size=30) For min_size and max_size , default values are inspected from the signature. study_lr.optimize(n_trials=3, epochs=3, verbose=0) [27] 2020-05-30 16:21:25 ( 2.33s ) python3 ( 48.4s ) [I 2020-05-30 16:21:25,441] A new study created with name: torch.lr.study#8 [run#41] lr=1.4e-05 epochs=3 [I 2020-05-30 16:21:26,201] Finished trial#0 with value: 83.7037977218628 with parameters: {'lr': 1.4003049046885165e-05}. Best is trial#0 with value: 83.7037977218628. [run#42] lr=0.0008086 epochs=3 [I 2020-05-30 16:21:26,969] Finished trial#1 with value: 7.2571200132369995 with parameters: {'lr': 0.0008085538449343595}. Best is trial#1 with value: 7.2571200132369995. [run#43] lr=0.0001357 epochs=3 [I 2020-05-30 16:21:27,739] Finished trial#2 with value: 7.968274736404419 with parameters: {'lr': 0.0001356837134362589}. Best is trial#1 with value: 7.2571200132369995. <optuna.study.Study at 0x26a142bbe48>","title":"Study from YAML file"},{"location":"tutorial/tuning/#pruning","text":"Optuna provides the pruning functionality . Ivory can uses this feature seamlessly. Here is the updated contents of study.yml file. File 13 study.yml tuner: pruner: class: optuna.pruners.MedianPruner objective: lr: rectangle.suggest.suggest_lr hidden_sizes: def: rectangle.suggest.suggest_hidden_sizes max_num_layers: 3 min_size: __default__ max_size: __default__ The Tuner instance has Optuna's MedianPruner . (Off course, you can use other pruners .) A Study instance give an ivory.callbacks.Pruning instance to a run when the run is created, then with Ivory's callback system , the Pruning instance communicates with Optuna in order to determine the step of pruning. Note Pruning is supported for PyTorch and TensorFlow now.","title":"Pruning"},{"location":"tutorial/ui/","text":"Tracking UI Ivory uses MLFlow Tracking for the workflow tracking and model saving. For this feature, the Client instace has to have a Tracker instance. First create several runs for demonstration. import ivory client = ivory.create_client(\"examples\") run = client.create_run('torch') run.start('both') [3] 2020-05-30 16:21:28 ( 1.31s ) python3 ( 50.0s ) [I 200530 16:21:28 tracker:48] A new experiment created with name: 'torch' [epoch#0] loss=20.97 val_loss=7.083 lr=0.001 best [epoch#1] loss=7.361 val_loss=6.422 lr=0.001 best [epoch#2] loss=6.72 val_loss=6.383 lr=0.001 best [epoch#3] loss=5.779 val_loss=4.946 lr=0.001 best [epoch#4] loss=4.918 val_loss=4.104 lr=0.001 best [epoch#5] loss=4.103 val_loss=3.951 lr=0.001 best [epoch#6] loss=3.405 val_loss=3.131 lr=0.001 best [epoch#7] loss=2.541 val_loss=1.988 lr=0.001 best [epoch#8] loss=1.988 val_loss=1.553 lr=0.001 best [epoch#9] loss=1.606 val_loss=1.453 lr=0.001 best task = client.create_task('torch') runs = task.product(fold=range(3), verbose=0) for run in runs: run.start('both') [4] 2020-05-30 16:21:29 ( 4.22s ) python3 ( 54.2s ) [run#1] fold=0 [run#2] fold=1 [run#3] fold=2 task = client.create_task('torch') runs = task.chain(lr=[1e-4, 1e-3], batch_size=[16, 32], verbose=0) for run in runs: run.start('both') [5] 2020-05-30 16:21:33 ( 5.24s ) python3 ( 59.5s ) [run#4] lr=0.0001 [run#5] lr=0.001 [run#6] batch_size=16 lr=0.001 [run#7] batch_size=32 lr=0.001 from ivory.utils.range import Range study = client.create_study('torch', lr=Range(1e-5, 1e-3, log=True)) study.optimize(n_trials=5, verbose=0) [6] 2020-05-30 16:21:38 ( 7.44s ) python3 ( 1min7s ) [I 2020-05-30 16:21:38,869] A new study created with name: torch.lr.study#0 [run#8] lr=0.0003525 [I 2020-05-30 16:21:40,348] Finished trial#0 with value: 5.444503486156464 with parameters: {'lr': 0.00035245015545868805}. Best is trial#0 with value: 5.444503486156464. [run#9] lr=1.512e-05 [I 2020-05-30 16:21:41,796] Finished trial#1 with value: 46.889670753479 with parameters: {'lr': 1.511972584755075e-05}. Best is trial#0 with value: 5.444503486156464. [run#10] lr=2.699e-05 [I 2020-05-30 16:21:43,244] Finished trial#2 with value: 7.843799555301667 with parameters: {'lr': 2.6985302099561763e-05}. Best is trial#0 with value: 5.444503486156464. [run#11] lr=1.573e-05 [I 2020-05-30 16:21:44,741] Finished trial#3 with value: 50.56015796661377 with parameters: {'lr': 1.5732324426281996e-05}. Best is trial#0 with value: 5.444503486156464. [run#12] lr=0.0007275 [I 2020-05-30 16:21:46,225] Finished trial#4 with value: 1.652654379606247 with parameters: {'lr': 0.0007275201467120322}. Best is trial#4 with value: 1.652654379606247. <optuna.study.Study at 0x2683735f688> Tracking UI Optionally, you can update missing parameters: client.update_params('torch') [7] 2020-05-30 16:21:46 ( 356ms ) python3 ( 1min7s ) In a terminal, move to the working directory ( examples ), then run $ ivory ui [8] ( ) ( ) You can view the UI using URL http://localhost:5000 in your browser. Table 1 A collection of runs. Parameters, metrics, tags are logged. You can compare the training results among runs. Figure 1 Comparison of training curves See also the official MLFlow documentation .","title":"<span class=\"pheasant-header\"><span class=\"header\"><span class=\"title\">Tracking UI</span></span></span>"},{"location":"tutorial/ui/#tracking-ui","text":"Ivory uses MLFlow Tracking for the workflow tracking and model saving. For this feature, the Client instace has to have a Tracker instance. First create several runs for demonstration. import ivory client = ivory.create_client(\"examples\") run = client.create_run('torch') run.start('both') [3] 2020-05-30 16:21:28 ( 1.31s ) python3 ( 50.0s ) [I 200530 16:21:28 tracker:48] A new experiment created with name: 'torch' [epoch#0] loss=20.97 val_loss=7.083 lr=0.001 best [epoch#1] loss=7.361 val_loss=6.422 lr=0.001 best [epoch#2] loss=6.72 val_loss=6.383 lr=0.001 best [epoch#3] loss=5.779 val_loss=4.946 lr=0.001 best [epoch#4] loss=4.918 val_loss=4.104 lr=0.001 best [epoch#5] loss=4.103 val_loss=3.951 lr=0.001 best [epoch#6] loss=3.405 val_loss=3.131 lr=0.001 best [epoch#7] loss=2.541 val_loss=1.988 lr=0.001 best [epoch#8] loss=1.988 val_loss=1.553 lr=0.001 best [epoch#9] loss=1.606 val_loss=1.453 lr=0.001 best task = client.create_task('torch') runs = task.product(fold=range(3), verbose=0) for run in runs: run.start('both') [4] 2020-05-30 16:21:29 ( 4.22s ) python3 ( 54.2s ) [run#1] fold=0 [run#2] fold=1 [run#3] fold=2 task = client.create_task('torch') runs = task.chain(lr=[1e-4, 1e-3], batch_size=[16, 32], verbose=0) for run in runs: run.start('both') [5] 2020-05-30 16:21:33 ( 5.24s ) python3 ( 59.5s ) [run#4] lr=0.0001 [run#5] lr=0.001 [run#6] batch_size=16 lr=0.001 [run#7] batch_size=32 lr=0.001 from ivory.utils.range import Range study = client.create_study('torch', lr=Range(1e-5, 1e-3, log=True)) study.optimize(n_trials=5, verbose=0) [6] 2020-05-30 16:21:38 ( 7.44s ) python3 ( 1min7s ) [I 2020-05-30 16:21:38,869] A new study created with name: torch.lr.study#0 [run#8] lr=0.0003525 [I 2020-05-30 16:21:40,348] Finished trial#0 with value: 5.444503486156464 with parameters: {'lr': 0.00035245015545868805}. Best is trial#0 with value: 5.444503486156464. [run#9] lr=1.512e-05 [I 2020-05-30 16:21:41,796] Finished trial#1 with value: 46.889670753479 with parameters: {'lr': 1.511972584755075e-05}. Best is trial#0 with value: 5.444503486156464. [run#10] lr=2.699e-05 [I 2020-05-30 16:21:43,244] Finished trial#2 with value: 7.843799555301667 with parameters: {'lr': 2.6985302099561763e-05}. Best is trial#0 with value: 5.444503486156464. [run#11] lr=1.573e-05 [I 2020-05-30 16:21:44,741] Finished trial#3 with value: 50.56015796661377 with parameters: {'lr': 1.5732324426281996e-05}. Best is trial#0 with value: 5.444503486156464. [run#12] lr=0.0007275 [I 2020-05-30 16:21:46,225] Finished trial#4 with value: 1.652654379606247 with parameters: {'lr': 0.0007275201467120322}. Best is trial#4 with value: 1.652654379606247. <optuna.study.Study at 0x2683735f688>","title":"Tracking UI"},{"location":"tutorial/ui/#tracking-ui_1","text":"Optionally, you can update missing parameters: client.update_params('torch') [7] 2020-05-30 16:21:46 ( 356ms ) python3 ( 1min7s ) In a terminal, move to the working directory ( examples ), then run $ ivory ui [8] ( ) ( ) You can view the UI using URL http://localhost:5000 in your browser. Table 1 A collection of runs. Parameters, metrics, tags are logged. You can compare the training results among runs. Figure 1 Comparison of training curves See also the official MLFlow documentation .","title":"Tracking UI"}]}