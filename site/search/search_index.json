{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Quickstart Ivory is a lightweight framework for machine learning. It integrates model design, tracking, and hyperparmeter tuning. Ivory uses MLflow Tracking for tracking and Optuna for hyperparmeter tuning. The relationship of these libraries is shown in Table 1 . Table 1 Ivory MLFlow Optuna Experiment Experiment Study Run Run Trial Using Ivory, you can tackle both tracking and tuning workflow at one place. Another key feature of Ivory is its model design. You can write down all of your model structure and tracking/tuning process in one YAML file. It allows us to understand the whole process at a glance. Installation You can install Ivory by a pip command. $ pip install ivory Using a Ivory Client Ivory has the Client class that manages the workflow of any machine learning. Let's create your first Client instance. In this quickstart, we are working with examples under the examples directory. import ivory client = ivory.create_client(\"examples\") client [2] 2020-05-24 22:25:44 ( 1.05s ) python3 ( 1.09s ) Client(num_objects=2) The representation of the client shows that it has two objects. Objects that a client has can be accessed by index notation or dot notation . client[0] # or client['tracker'], or client.tracker [3] 2020-05-24 22:25:45 ( 4.00ms ) python3 ( 1.10s ) Tracker(tracking_uri='file:///C:/Users/daizu/Documents/github/ivory/docs/examples/mlruns', artifact_location=None) The first object is a Tracker instance which connects Ivory to MLFlow Tracking . Because a Client insctance is an iterable, you can get all of the objects by applying list to it. list(client) [4] 2020-05-24 22:25:45 ( 6.00ms ) python3 ( 1.10s ) ['tracker', 'tuner'] The second objects is named tuner . client.tuner [5] 2020-05-24 22:25:45 ( 4.00ms ) python3 ( 1.11s ) Tuner(storage='sqlite://', sampler=None, pruner=None, load_if_exists=True) A Tuner instance connects Ivory to Optuna: A hyperparameter optimization framework . We can customize these objects with a YAML file named client.yml under the woking directory. In our case, the file just contains the minimum settings. File 1 client.yml client: tracker: tuner: Note A YAML file for client is not required. If there is no file for client, Ivory creates a default client with a tracker and without a tuner. If you don't need a tracker, use ivory.create_client(tracker=False) . Create NumPy data In this quickstart, we try to predict rectangles area from thier width and height using PyTorch . First, prepare the data as NumPy arrays. In example.py under the working directory, a create_data() function is defined. The ivory.create_client() function automatically inserts the working directory, so that we can import the module. import example [6] 2020-05-24 22:25:45 ( 280ms ) python3 ( 1.39s ) Let's check the create_data() function definition and an example output: Code 1 example.create_data def create_data(num_samples=1000): xy = 4 * np.random.rand(num_samples, 2) + 1 xy = xy.astype(np.float32) dx = 0.1 * (np.random.rand(num_samples) - 0.5) dy = 0.1 * (np.random.rand(num_samples) - 0.5) z = ((xy[:, 0] + dx) * (xy[:, 1] + dy)).astype(np.float32) return xy, z xy, z = example.create_data(4) xy [8] 2020-05-24 22:25:45 ( 5.00ms ) python3 ( 1.41s ) array([[3.1809084, 4.6395426], [1.5099585, 4.5993605], [3.1226885, 1.4896991], [2.6278324, 3.1246 ]], dtype=float32) z [9] 2020-05-24 22:25:45 ( 4.00ms ) python3 ( 1.41s ) array([15.0283785, 6.802533 , 4.7126684, 8.047901 ], dtype=float32) Set of Data classes Ivory defines a set of Data classes ( Data , Dataset , Datasets , DataLoaders ). But now, we use the Data class only. Code 2 example.Data @dataclass class Data(ivory.core.data.Data): n_splits: int = 5 DATA = create_data(1000) def init(self): self.input, self.target = self.DATA self.index = np.arange(len(self.input)) self.fold = kfold_split(self.input, n_splits=self.n_splits) # Creating test set just for demonstration. is_test = self.fold == self.n_splits - 1 self.fold = np.where(is_test, -1, self.fold) self.target = np.where(is_test, np.nan, self.target) self.target = self.target.reshape(-1, 1) # (sample, channel) Here, kfold_split function creates a fold-array. In Ivory, fold number = -1 means their samples are test data. import numpy as np from ivory.utils.fold import kfold_split kfold_split(np.arange(10), n_splits=3) [11] 2020-05-24 22:25:45 ( 5.00ms ) python3 ( 1.44s ) array([2, 1, 0, 2, 0, 2, 1, 1, 0, 0], dtype=int8) Now, we can get a Data instance. data = example.Data() data [12] 2020-05-24 22:25:45 ( 4.00ms ) python3 ( 1.44s ) Data(n_splits=5) data.get(0) # get data of index = 0. [13] 2020-05-24 22:25:45 ( 4.00ms ) python3 ( 1.44s ) [0, array([1.5857297, 2.593705 ], dtype=float32), array([4.1839447], dtype=float32)] This returned values are (index, input, target). Ivory always keeps data index so that Ivory can detect where a sample comes from. Define a model We use a simple MLP model here. Code 3 example.Model class Model(nn.Module): def __init__(self, hidden_sizes): super().__init__() layers = [] for in_features, out_features in zip([2] + hidden_sizes, hidden_sizes + [1]): layers.append(nn.Linear(in_features, out_features)) self.layers = nn.ModuleList(layers) def forward(self, x): for layer in self.layers[:-1]: x = F.relu(layer(x)) return self.layers[-1](x) Parameter file for Run Ivory defines a run by a YAML file. Here is a full example. File 2 torch.yaml library: torch dataloaders: data: class: example.Data n_splits: 5 dataset: batch_size: 10 fold: 0 model: class: example.Model hidden_sizes: [100, 100] optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 1e-3 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: metrics: criterion: def: torch.nn.functional.mse_loss monitor: metric: val_loss early_stopping: patience: 10 trainer: epochs: 10 verbose: 2 Let's create a run by client.create_run() run = client.create_run('torch') run [15] 2020-05-24 22:25:45 ( 292ms ) python3 ( 1.75s ) [I 200524 22:25:45 tracker:48] A new experiment created with name: torch Run(id='4b6f610d1b2041e98cd43c98795f8f79', name='run#0', num_objects=12) Note client.create_run(<name>) creates an experiment named <name> if it hasn't exist yet. By cliking an icon ( ) in the above cell, you can know that. Or you can directly create an experiment then make the experiment create a run: experiment = client . create_experiment ( 'torch' ) run = experiment . create_run () A Run instance have a params attribute that holds the parameters for the run. import yaml print(yaml.dump(run.params, sort_keys=False)) [16] 2020-05-24 22:25:46 ( 7.00ms ) python3 ( 1.76s ) run: dataloaders: data: class: example.Data n_splits: 5 dataset: def: ivory.torch.data.Dataset batch_size: 10 fold: 0 class: ivory.torch.data.DataLoaders model: class: example.Model hidden_sizes: - 100 - 100 optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 0.001 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: class: ivory.torch.results.Results metrics: criterion: def: torch.nn.functional.mse_loss class: ivory.torch.metrics.Metrics monitor: metric: val_loss class: ivory.callbacks.monitor.Monitor early_stopping: patience: 10 class: ivory.callbacks.early_stopping.EarlyStopping trainer: epochs: 10 verbose: 2 class: ivory.torch.trainer.Trainer class: ivory.torch.run.Run name: run#0 id: 4b6f610d1b2041e98cd43c98795f8f79 experiment: name: torch class: ivory.core.base.Experiment id: '1' This is similar to the YAML file we read before, but slightly changed by the Ivory Client. Run and experiment sections are inserted. ExperimentID and RunID are assigned by the MLFlow Tracking. Default classes are specified, for example ivory.torch.trainer.Trainer for a trainer instance. The create_run() method takes keyword arguments to modify these parameters: run = client.create_run( 'torch', batch_size=20, hidden_sizes=[40, 50, 60], ) print('[dataloaders]') print(yaml.dump(run.params['run']['dataloaders'], sort_keys=False)) print('[model]') print(yaml.dump(run.params['run']['model'], sort_keys=False)) [17] 2020-05-24 22:25:46 ( 48.0ms ) python3 ( 1.81s ) [dataloaders] data: class: example.Data n_splits: 5 dataset: def: ivory.torch.data.Dataset batch_size: 20 fold: 0 class: ivory.torch.data.DataLoaders [model] class: example.Model hidden_sizes: - 40 - 50 - 60 Train a model Once you got a run instance, then all you need is to start it. run = client.create_run('torch') # Back to the default settings. run.start() [18] 2020-05-24 22:25:46 ( 1.41s ) python3 ( 3.21s ) [epoch#0] loss=13.29 val_loss=7.564 lr=0.001 best [epoch#1] loss=6.895 val_loss=5.619 lr=0.001 best [epoch#2] loss=5.403 val_loss=3.895 lr=0.001 best [epoch#3] loss=3.845 val_loss=3.002 lr=0.001 best [epoch#4] loss=2.547 val_loss=1.734 lr=0.001 best [epoch#5] loss=2.053 val_loss=1.208 lr=0.001 best [epoch#6] loss=1.436 val_loss=0.9552 lr=0.001 best [epoch#7] loss=1.287 val_loss=1.398 lr=0.001 [epoch#8] loss=0.9768 val_loss=0.928 lr=0.001 best [epoch#9] loss=0.9438 val_loss=0.8438 lr=0.001 best The history of metrics is saved as the history attribute of run.metrics . run.metrics.history [19] 2020-05-24 22:25:47 ( 5.00ms ) python3 ( 3.22s ) {'loss': {0: 13.2915274143219, 1: 6.895381383101145, 2: 5.402782511711121, 3: 3.8453857560952502, 4: 2.5471531798442206, 5: 2.0533000896374385, 6: 1.4360316440463066, 7: 1.287196725110213, 8: 0.9768397375941277, 9: 0.9437889402111371}, 'val_loss': {0: 7.564033889770508, 1: 5.619347631931305, 2: 3.8952303409576414, 3: 3.001619479060173, 4: 1.734294581413269, 5: 1.2084212899208069, 6: 0.9551760077476501, 7: 1.3979959055781364, 8: 0.9280101835727692, 9: 0.8437783315777778}, 'lr': {0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001}} Also the model output and target are automatically collected. run.results [20] 2020-05-24 22:25:47 ( 5.00ms ) python3 ( 3.22s ) Results('train', 'val') run.results.val.output[:5] [21] 2020-05-24 22:25:47 ( 5.00ms ) python3 ( 3.23s ) array([[-0.0041028], [ 2.880908 ], [ 4.020448 ], [ 1.9799994], [ 4.043664 ]], dtype=float32) run.results.val.target[:5] [22] 2020-05-24 22:25:47 ( 4.00ms ) python3 ( 3.23s ) array([[1.1692593], [2.9674063], [4.305286 ], [2.3574038], [4.2668324]], dtype=float32) Test a model Testing a model is as simple as training. Just call run.start() with a test argument in stead of (default) train . run.start('test') run.results [23] 2020-05-24 22:25:47 ( 43.0ms ) python3 ( 3.27s ) Results('train', 'val', 'test') You can see, test results were added. run.results.test.output[:5] [24] 2020-05-24 22:25:47 ( 4.00ms ) python3 ( 3.28s ) array([[ 7.9116325], [ 2.829218 ], [10.7172365], [ 6.1285763], [ 6.4077835]], dtype=float32) Off course the target values are np.nan . run.results.test.target[:5] [25] 2020-05-24 22:25:47 ( 4.00ms ) python3 ( 3.28s ) array([[nan], [nan], [nan], [nan], [nan]], dtype=float32) Task for multiple runs Ivory implements special run type called Task which controls multiple nested runs. A task is useful for parameter search or cross validation. task = client.create_task('torch') task [26] 2020-05-24 22:25:47 ( 49.0ms ) python3 ( 3.33s ) Task(id='0ad6d11465f14bb9a2f1e59fbdb894a3', name='task#0', num_objects=3) The Task class has two methods to generate multiple runs: prodcut() and chain() . These two methods have the same functionality as itertools of Python starndard library. Let's try cross validation. runs = task.product(fold=range(4), verbose=0, epochs=3) runs [27] 2020-05-24 22:25:47 ( 5.00ms ) python3 ( 3.34s ) <generator object Task.product at 0x00000242167F7448> Like itertools 's functions, Task.prodcut() and Task.chain() return a generator, which yields runs that are configured by different parameters you specified. In this case, this generator will yield 4 runs with a fold number ranging from 0 to 4 for each. A task instance doesn't start any training by itself. Note You can pass fixed parameters to update the original parameters in the YAML file. Then start 4 runs by a for loop including run.train() . Here a both argument means execution of test after training. for run in runs: run.start('both') [28] 2020-05-24 22:25:47 ( 2.33s ) python3 ( 5.67s ) [run#3] epochs=3 fold=0 [epoch#0] loss=13.17 val_loss=7.041 lr=0.001 best [epoch#1] loss=6.723 val_loss=5.485 lr=0.001 best [epoch#2] loss=5.116 val_loss=4.732 lr=0.001 best [run#4] epochs=3 fold=1 [epoch#0] loss=14.23 val_loss=6.067 lr=0.001 best [epoch#1] loss=6.059 val_loss=4.517 lr=0.001 best [epoch#2] loss=4.519 val_loss=3.021 lr=0.001 best [run#5] epochs=3 fold=2 [epoch#0] loss=14.92 val_loss=8.153 lr=0.001 best [epoch#1] loss=6.1 val_loss=5.811 lr=0.001 best [epoch#2] loss=4.239 val_loss=4.076 lr=0.001 best [run#6] epochs=3 fold=3 [epoch#0] loss=16.37 val_loss=7.484 lr=0.001 best [epoch#1] loss=7.299 val_loss=5.93 lr=0.001 best [epoch#2] loss=5.53 val_loss=4.115 lr=0.001 best Collect runs Our client has a Tracker instance. It stores the state of runs in background using the powerful MLFlow Tracking . The Client class provides several methods to access the stored runs. For example, search_run_ids() returns a generator which yields RunID created by the MLFlow Tracking. def print_run_info(run_ids): for run_id in run_ids: print(run_id[:5], client.get_run_name(run_id)) [29] 2020-05-24 22:25:49 ( 4.00ms ) python3 ( 5.67s ) run_ids = client.search_run_ids('torch') print_run_info(run_ids) [30] 2020-05-24 22:25:49 ( 81.8ms ) python3 ( 5.76s ) 94d47 run#6 3432c run#5 c3d3a run#4 ef2fd run#3 0ad6d task#0 fcca9 run#2 682c6 run#1 4b6f6 run#0 For filtering, add key-value pairs. run_ids = client.search_run_ids('torch', fold=0, exclude_parent=True) print_run_info(run_ids) [31] 2020-05-24 22:25:50 ( 160ms ) python3 ( 5.92s ) ef2fd run#3 fcca9 run#2 682c6 run#1 4b6f6 run#0 run_ids = client.search_run_ids('torch', parent_run_id=task.id) print_run_info(run_ids) [32] 2020-05-24 22:25:50 ( 47.0ms ) python3 ( 5.96s ) 94d47 run#6 3432c run#5 c3d3a run#4 ef2fd run#3 Note exclude_parent : If True, parent runs are excluded. parent_run_id : If specified, nested runs are returned only if it has the parent. client.get_run_id() and client.get_run_ids() fetch RunID from run name, more strictly, (run class name in lowercase) plus (run number). run_ids = [client.get_run_id('torch', run=0), client.get_run_id('torch', task=0)] print_run_info(run_ids) [33] 2020-05-24 22:25:50 ( 54.0ms ) python3 ( 6.02s ) 4b6f6 run#0 0ad6d task#0 run_ids = client.get_run_ids('torch', run=range(2, 4)) print_run_info(run_ids) [34] 2020-05-24 22:25:50 ( 80.7ms ) python3 ( 6.10s ) fcca9 run#2 ef2fd run#3 Load runs and results The Ivory Client class can load runs. First select RunID(s) to load. We want to perform cross validation here, so that we need a run collection created by a task. In this case, we can use client.get_nested_run_ids() . Why don't use client.search_run_ids as we did above? Because generally we can't write down a very long RunID. On the ohter hand, a run name is easy to manege and write. run_ids = list(client.get_nested_run_ids('torch', task=0)) print_run_info(run_ids) [35] 2020-05-24 22:25:50 ( 80.8ms ) python3 ( 6.18s ) 94d47 run#6 3432c run#5 c3d3a run#4 ef2fd run#3 Let's load the latest run. run = client.load_run(run_ids[0]) run [36] 2020-05-24 22:25:50 ( 55.0ms ) python3 ( 6.23s ) Run(id='94d477f2ca6d403dac3146c440b7a098', name='run#6', num_objects=11) Note client.load_run() doesn't require an experiment name, because RunID is unique among MLFlow Tracking. As you expected, the fold number is 3. run.dataloaders.fold [37] 2020-05-24 22:25:50 ( 3.00ms ) python3 ( 6.24s ) 3 We obtained the trained model. run.model.eval() [38] 2020-05-24 22:25:50 ( 4.00ms ) python3 ( 6.24s ) Model( (layers): ModuleList( (0): Linear(in_features=2, out_features=100, bias=True) (1): Linear(in_features=100, out_features=100, bias=True) (2): Linear(in_features=100, out_features=1, bias=True) ) ) import torch index, input, target = next(iter(run.dataloaders.val)) with torch.no_grad(): output = run.model(input) print('[output]') print(output) print('[target]') print(target) [39] 2020-05-24 22:25:50 ( 12.0ms ) python3 ( 6.25s ) [output] tensor([[ 8.9875], [ 8.8513], [ 7.5677], [ 6.8679], [ 3.4749], [15.7395], [10.1597], [14.5195], [ 8.8349], [ 4.5969]]) [target] tensor([[ 7.6544], [ 8.2451], [ 5.9819], [ 4.8056], [ 1.7836], [21.4229], [ 9.9691], [18.8468], [ 7.9122], [ 2.8403]]) If you don't need a whole run instance, client.load_instance() is better choice to save time and memory. results = client.load_instance(run_ids[0], 'results') results [40] 2020-05-24 22:25:50 ( 29.0ms ) python3 ( 6.28s ) Results('train', 'val', 'test') for mode in ['train', 'val', 'test']: print(mode, results[mode].output.shape) [41] 2020-05-24 22:25:50 ( 11.0ms ) python3 ( 6.29s ) train (600, 1) val (200, 1) test (200, 1) For cross validation, we need 4 runs. ( n_splits is 5 but we used the last fold for dummy test data.) To load multiple run's results. Ivory Client provides a convenient method. results = client.load_results(run_ids, verbose=False) results [42] 2020-05-24 22:25:50 ( 103ms ) python3 ( 6.40s ) Results('val', 'test') for mode in ['val', 'test']: print(mode, results[mode].output.shape) [43] 2020-05-24 22:25:50 ( 8.00ms ) python3 ( 6.40s ) val (800, 1) test (800, 1) Note client.load_results drops train data for saving memory. The lengths of validation data and test data are both 800 (200 times 4). But be careful about the test data. The length of unique samples is 200 (one fold size). import numpy as np len(np.unique(results.val.index)), len(np.unique(results.test.index)) [44] 2020-05-24 22:25:50 ( 5.00ms ) python3 ( 6.41s ) (800, 200) Usually, duplicated samples are averaged. Results.mean() method performs this mean reduction and returns a newly created Rusults instance. reduced_results = results.mean() for mode in ['val', 'test']: print(mode, reduced_results[mode].output.shape) [45] 2020-05-24 22:25:50 ( 15.0ms ) python3 ( 6.42s ) val (800, 1) test (200, 1) Compare the results. index = results.test.index index_0 = index[0] x = results.test.output[index == index_0] print('[results]') print(x) print(np.mean(x)) index = reduced_results.test.index x = reduced_results.test.output[index == index_0] print('[reduced_results]') print(x) [46] 2020-05-24 22:25:50 ( 10.0ms ) python3 ( 6.43s ) [results] [[9.345718] [8.816608] [9.444256] [8.720442]] 9.081757 [reduced_results] [[9.081757]] For convenience, client.load_results() has reduction keyword argument. results = client.load_results(run_ids, reduction='mean', verbose=False) results [47] 2020-05-24 22:25:50 ( 103ms ) python3 ( 6.54s ) Results('val', 'test') for mode in ['val', 'test']: print(mode, results[mode].output.shape) [48] 2020-05-24 22:25:50 ( 6.00ms ) python3 ( 6.54s ) val (800, 1) test (200, 1)","title":"Quickstart"},{"location":"#quickstart","text":"Ivory is a lightweight framework for machine learning. It integrates model design, tracking, and hyperparmeter tuning. Ivory uses MLflow Tracking for tracking and Optuna for hyperparmeter tuning. The relationship of these libraries is shown in Table 1 . Table 1 Ivory MLFlow Optuna Experiment Experiment Study Run Run Trial Using Ivory, you can tackle both tracking and tuning workflow at one place. Another key feature of Ivory is its model design. You can write down all of your model structure and tracking/tuning process in one YAML file. It allows us to understand the whole process at a glance.","title":"Quickstart"},{"location":"#installation","text":"You can install Ivory by a pip command. $ pip install ivory","title":"Installation"},{"location":"#using-a-ivory-client","text":"Ivory has the Client class that manages the workflow of any machine learning. Let's create your first Client instance. In this quickstart, we are working with examples under the examples directory. import ivory client = ivory.create_client(\"examples\") client [2] 2020-05-24 22:25:44 ( 1.05s ) python3 ( 1.09s ) Client(num_objects=2) The representation of the client shows that it has two objects. Objects that a client has can be accessed by index notation or dot notation . client[0] # or client['tracker'], or client.tracker [3] 2020-05-24 22:25:45 ( 4.00ms ) python3 ( 1.10s ) Tracker(tracking_uri='file:///C:/Users/daizu/Documents/github/ivory/docs/examples/mlruns', artifact_location=None) The first object is a Tracker instance which connects Ivory to MLFlow Tracking . Because a Client insctance is an iterable, you can get all of the objects by applying list to it. list(client) [4] 2020-05-24 22:25:45 ( 6.00ms ) python3 ( 1.10s ) ['tracker', 'tuner'] The second objects is named tuner . client.tuner [5] 2020-05-24 22:25:45 ( 4.00ms ) python3 ( 1.11s ) Tuner(storage='sqlite://', sampler=None, pruner=None, load_if_exists=True) A Tuner instance connects Ivory to Optuna: A hyperparameter optimization framework . We can customize these objects with a YAML file named client.yml under the woking directory. In our case, the file just contains the minimum settings. File 1 client.yml client: tracker: tuner: Note A YAML file for client is not required. If there is no file for client, Ivory creates a default client with a tracker and without a tuner. If you don't need a tracker, use ivory.create_client(tracker=False) .","title":"Using a Ivory Client"},{"location":"#create-numpy-data","text":"In this quickstart, we try to predict rectangles area from thier width and height using PyTorch . First, prepare the data as NumPy arrays. In example.py under the working directory, a create_data() function is defined. The ivory.create_client() function automatically inserts the working directory, so that we can import the module. import example [6] 2020-05-24 22:25:45 ( 280ms ) python3 ( 1.39s ) Let's check the create_data() function definition and an example output: Code 1 example.create_data def create_data(num_samples=1000): xy = 4 * np.random.rand(num_samples, 2) + 1 xy = xy.astype(np.float32) dx = 0.1 * (np.random.rand(num_samples) - 0.5) dy = 0.1 * (np.random.rand(num_samples) - 0.5) z = ((xy[:, 0] + dx) * (xy[:, 1] + dy)).astype(np.float32) return xy, z xy, z = example.create_data(4) xy [8] 2020-05-24 22:25:45 ( 5.00ms ) python3 ( 1.41s ) array([[3.1809084, 4.6395426], [1.5099585, 4.5993605], [3.1226885, 1.4896991], [2.6278324, 3.1246 ]], dtype=float32) z [9] 2020-05-24 22:25:45 ( 4.00ms ) python3 ( 1.41s ) array([15.0283785, 6.802533 , 4.7126684, 8.047901 ], dtype=float32)","title":"Create NumPy data"},{"location":"#set-of-data-classes","text":"Ivory defines a set of Data classes ( Data , Dataset , Datasets , DataLoaders ). But now, we use the Data class only. Code 2 example.Data @dataclass class Data(ivory.core.data.Data): n_splits: int = 5 DATA = create_data(1000) def init(self): self.input, self.target = self.DATA self.index = np.arange(len(self.input)) self.fold = kfold_split(self.input, n_splits=self.n_splits) # Creating test set just for demonstration. is_test = self.fold == self.n_splits - 1 self.fold = np.where(is_test, -1, self.fold) self.target = np.where(is_test, np.nan, self.target) self.target = self.target.reshape(-1, 1) # (sample, channel) Here, kfold_split function creates a fold-array. In Ivory, fold number = -1 means their samples are test data. import numpy as np from ivory.utils.fold import kfold_split kfold_split(np.arange(10), n_splits=3) [11] 2020-05-24 22:25:45 ( 5.00ms ) python3 ( 1.44s ) array([2, 1, 0, 2, 0, 2, 1, 1, 0, 0], dtype=int8) Now, we can get a Data instance. data = example.Data() data [12] 2020-05-24 22:25:45 ( 4.00ms ) python3 ( 1.44s ) Data(n_splits=5) data.get(0) # get data of index = 0. [13] 2020-05-24 22:25:45 ( 4.00ms ) python3 ( 1.44s ) [0, array([1.5857297, 2.593705 ], dtype=float32), array([4.1839447], dtype=float32)] This returned values are (index, input, target). Ivory always keeps data index so that Ivory can detect where a sample comes from.","title":"Set of Data classes"},{"location":"#define-a-model","text":"We use a simple MLP model here. Code 3 example.Model class Model(nn.Module): def __init__(self, hidden_sizes): super().__init__() layers = [] for in_features, out_features in zip([2] + hidden_sizes, hidden_sizes + [1]): layers.append(nn.Linear(in_features, out_features)) self.layers = nn.ModuleList(layers) def forward(self, x): for layer in self.layers[:-1]: x = F.relu(layer(x)) return self.layers[-1](x)","title":"Define a model"},{"location":"#parameter-file-for-run","text":"Ivory defines a run by a YAML file. Here is a full example. File 2 torch.yaml library: torch dataloaders: data: class: example.Data n_splits: 5 dataset: batch_size: 10 fold: 0 model: class: example.Model hidden_sizes: [100, 100] optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 1e-3 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: metrics: criterion: def: torch.nn.functional.mse_loss monitor: metric: val_loss early_stopping: patience: 10 trainer: epochs: 10 verbose: 2 Let's create a run by client.create_run() run = client.create_run('torch') run [15] 2020-05-24 22:25:45 ( 292ms ) python3 ( 1.75s ) [I 200524 22:25:45 tracker:48] A new experiment created with name: torch Run(id='4b6f610d1b2041e98cd43c98795f8f79', name='run#0', num_objects=12) Note client.create_run(<name>) creates an experiment named <name> if it hasn't exist yet. By cliking an icon ( ) in the above cell, you can know that. Or you can directly create an experiment then make the experiment create a run: experiment = client . create_experiment ( 'torch' ) run = experiment . create_run () A Run instance have a params attribute that holds the parameters for the run. import yaml print(yaml.dump(run.params, sort_keys=False)) [16] 2020-05-24 22:25:46 ( 7.00ms ) python3 ( 1.76s ) run: dataloaders: data: class: example.Data n_splits: 5 dataset: def: ivory.torch.data.Dataset batch_size: 10 fold: 0 class: ivory.torch.data.DataLoaders model: class: example.Model hidden_sizes: - 100 - 100 optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 0.001 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: class: ivory.torch.results.Results metrics: criterion: def: torch.nn.functional.mse_loss class: ivory.torch.metrics.Metrics monitor: metric: val_loss class: ivory.callbacks.monitor.Monitor early_stopping: patience: 10 class: ivory.callbacks.early_stopping.EarlyStopping trainer: epochs: 10 verbose: 2 class: ivory.torch.trainer.Trainer class: ivory.torch.run.Run name: run#0 id: 4b6f610d1b2041e98cd43c98795f8f79 experiment: name: torch class: ivory.core.base.Experiment id: '1' This is similar to the YAML file we read before, but slightly changed by the Ivory Client. Run and experiment sections are inserted. ExperimentID and RunID are assigned by the MLFlow Tracking. Default classes are specified, for example ivory.torch.trainer.Trainer for a trainer instance. The create_run() method takes keyword arguments to modify these parameters: run = client.create_run( 'torch', batch_size=20, hidden_sizes=[40, 50, 60], ) print('[dataloaders]') print(yaml.dump(run.params['run']['dataloaders'], sort_keys=False)) print('[model]') print(yaml.dump(run.params['run']['model'], sort_keys=False)) [17] 2020-05-24 22:25:46 ( 48.0ms ) python3 ( 1.81s ) [dataloaders] data: class: example.Data n_splits: 5 dataset: def: ivory.torch.data.Dataset batch_size: 20 fold: 0 class: ivory.torch.data.DataLoaders [model] class: example.Model hidden_sizes: - 40 - 50 - 60","title":"Parameter file for Run"},{"location":"#train-a-model","text":"Once you got a run instance, then all you need is to start it. run = client.create_run('torch') # Back to the default settings. run.start() [18] 2020-05-24 22:25:46 ( 1.41s ) python3 ( 3.21s ) [epoch#0] loss=13.29 val_loss=7.564 lr=0.001 best [epoch#1] loss=6.895 val_loss=5.619 lr=0.001 best [epoch#2] loss=5.403 val_loss=3.895 lr=0.001 best [epoch#3] loss=3.845 val_loss=3.002 lr=0.001 best [epoch#4] loss=2.547 val_loss=1.734 lr=0.001 best [epoch#5] loss=2.053 val_loss=1.208 lr=0.001 best [epoch#6] loss=1.436 val_loss=0.9552 lr=0.001 best [epoch#7] loss=1.287 val_loss=1.398 lr=0.001 [epoch#8] loss=0.9768 val_loss=0.928 lr=0.001 best [epoch#9] loss=0.9438 val_loss=0.8438 lr=0.001 best The history of metrics is saved as the history attribute of run.metrics . run.metrics.history [19] 2020-05-24 22:25:47 ( 5.00ms ) python3 ( 3.22s ) {'loss': {0: 13.2915274143219, 1: 6.895381383101145, 2: 5.402782511711121, 3: 3.8453857560952502, 4: 2.5471531798442206, 5: 2.0533000896374385, 6: 1.4360316440463066, 7: 1.287196725110213, 8: 0.9768397375941277, 9: 0.9437889402111371}, 'val_loss': {0: 7.564033889770508, 1: 5.619347631931305, 2: 3.8952303409576414, 3: 3.001619479060173, 4: 1.734294581413269, 5: 1.2084212899208069, 6: 0.9551760077476501, 7: 1.3979959055781364, 8: 0.9280101835727692, 9: 0.8437783315777778}, 'lr': {0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001}} Also the model output and target are automatically collected. run.results [20] 2020-05-24 22:25:47 ( 5.00ms ) python3 ( 3.22s ) Results('train', 'val') run.results.val.output[:5] [21] 2020-05-24 22:25:47 ( 5.00ms ) python3 ( 3.23s ) array([[-0.0041028], [ 2.880908 ], [ 4.020448 ], [ 1.9799994], [ 4.043664 ]], dtype=float32) run.results.val.target[:5] [22] 2020-05-24 22:25:47 ( 4.00ms ) python3 ( 3.23s ) array([[1.1692593], [2.9674063], [4.305286 ], [2.3574038], [4.2668324]], dtype=float32)","title":"Train a model"},{"location":"#test-a-model","text":"Testing a model is as simple as training. Just call run.start() with a test argument in stead of (default) train . run.start('test') run.results [23] 2020-05-24 22:25:47 ( 43.0ms ) python3 ( 3.27s ) Results('train', 'val', 'test') You can see, test results were added. run.results.test.output[:5] [24] 2020-05-24 22:25:47 ( 4.00ms ) python3 ( 3.28s ) array([[ 7.9116325], [ 2.829218 ], [10.7172365], [ 6.1285763], [ 6.4077835]], dtype=float32) Off course the target values are np.nan . run.results.test.target[:5] [25] 2020-05-24 22:25:47 ( 4.00ms ) python3 ( 3.28s ) array([[nan], [nan], [nan], [nan], [nan]], dtype=float32)","title":"Test a model"},{"location":"#task-for-multiple-runs","text":"Ivory implements special run type called Task which controls multiple nested runs. A task is useful for parameter search or cross validation. task = client.create_task('torch') task [26] 2020-05-24 22:25:47 ( 49.0ms ) python3 ( 3.33s ) Task(id='0ad6d11465f14bb9a2f1e59fbdb894a3', name='task#0', num_objects=3) The Task class has two methods to generate multiple runs: prodcut() and chain() . These two methods have the same functionality as itertools of Python starndard library. Let's try cross validation. runs = task.product(fold=range(4), verbose=0, epochs=3) runs [27] 2020-05-24 22:25:47 ( 5.00ms ) python3 ( 3.34s ) <generator object Task.product at 0x00000242167F7448> Like itertools 's functions, Task.prodcut() and Task.chain() return a generator, which yields runs that are configured by different parameters you specified. In this case, this generator will yield 4 runs with a fold number ranging from 0 to 4 for each. A task instance doesn't start any training by itself. Note You can pass fixed parameters to update the original parameters in the YAML file. Then start 4 runs by a for loop including run.train() . Here a both argument means execution of test after training. for run in runs: run.start('both') [28] 2020-05-24 22:25:47 ( 2.33s ) python3 ( 5.67s ) [run#3] epochs=3 fold=0 [epoch#0] loss=13.17 val_loss=7.041 lr=0.001 best [epoch#1] loss=6.723 val_loss=5.485 lr=0.001 best [epoch#2] loss=5.116 val_loss=4.732 lr=0.001 best [run#4] epochs=3 fold=1 [epoch#0] loss=14.23 val_loss=6.067 lr=0.001 best [epoch#1] loss=6.059 val_loss=4.517 lr=0.001 best [epoch#2] loss=4.519 val_loss=3.021 lr=0.001 best [run#5] epochs=3 fold=2 [epoch#0] loss=14.92 val_loss=8.153 lr=0.001 best [epoch#1] loss=6.1 val_loss=5.811 lr=0.001 best [epoch#2] loss=4.239 val_loss=4.076 lr=0.001 best [run#6] epochs=3 fold=3 [epoch#0] loss=16.37 val_loss=7.484 lr=0.001 best [epoch#1] loss=7.299 val_loss=5.93 lr=0.001 best [epoch#2] loss=5.53 val_loss=4.115 lr=0.001 best","title":"Task for multiple runs"},{"location":"#collect-runs","text":"Our client has a Tracker instance. It stores the state of runs in background using the powerful MLFlow Tracking . The Client class provides several methods to access the stored runs. For example, search_run_ids() returns a generator which yields RunID created by the MLFlow Tracking. def print_run_info(run_ids): for run_id in run_ids: print(run_id[:5], client.get_run_name(run_id)) [29] 2020-05-24 22:25:49 ( 4.00ms ) python3 ( 5.67s ) run_ids = client.search_run_ids('torch') print_run_info(run_ids) [30] 2020-05-24 22:25:49 ( 81.8ms ) python3 ( 5.76s ) 94d47 run#6 3432c run#5 c3d3a run#4 ef2fd run#3 0ad6d task#0 fcca9 run#2 682c6 run#1 4b6f6 run#0 For filtering, add key-value pairs. run_ids = client.search_run_ids('torch', fold=0, exclude_parent=True) print_run_info(run_ids) [31] 2020-05-24 22:25:50 ( 160ms ) python3 ( 5.92s ) ef2fd run#3 fcca9 run#2 682c6 run#1 4b6f6 run#0 run_ids = client.search_run_ids('torch', parent_run_id=task.id) print_run_info(run_ids) [32] 2020-05-24 22:25:50 ( 47.0ms ) python3 ( 5.96s ) 94d47 run#6 3432c run#5 c3d3a run#4 ef2fd run#3 Note exclude_parent : If True, parent runs are excluded. parent_run_id : If specified, nested runs are returned only if it has the parent. client.get_run_id() and client.get_run_ids() fetch RunID from run name, more strictly, (run class name in lowercase) plus (run number). run_ids = [client.get_run_id('torch', run=0), client.get_run_id('torch', task=0)] print_run_info(run_ids) [33] 2020-05-24 22:25:50 ( 54.0ms ) python3 ( 6.02s ) 4b6f6 run#0 0ad6d task#0 run_ids = client.get_run_ids('torch', run=range(2, 4)) print_run_info(run_ids) [34] 2020-05-24 22:25:50 ( 80.7ms ) python3 ( 6.10s ) fcca9 run#2 ef2fd run#3","title":"Collect runs"},{"location":"#load-runs-and-results","text":"The Ivory Client class can load runs. First select RunID(s) to load. We want to perform cross validation here, so that we need a run collection created by a task. In this case, we can use client.get_nested_run_ids() . Why don't use client.search_run_ids as we did above? Because generally we can't write down a very long RunID. On the ohter hand, a run name is easy to manege and write. run_ids = list(client.get_nested_run_ids('torch', task=0)) print_run_info(run_ids) [35] 2020-05-24 22:25:50 ( 80.8ms ) python3 ( 6.18s ) 94d47 run#6 3432c run#5 c3d3a run#4 ef2fd run#3 Let's load the latest run. run = client.load_run(run_ids[0]) run [36] 2020-05-24 22:25:50 ( 55.0ms ) python3 ( 6.23s ) Run(id='94d477f2ca6d403dac3146c440b7a098', name='run#6', num_objects=11) Note client.load_run() doesn't require an experiment name, because RunID is unique among MLFlow Tracking. As you expected, the fold number is 3. run.dataloaders.fold [37] 2020-05-24 22:25:50 ( 3.00ms ) python3 ( 6.24s ) 3 We obtained the trained model. run.model.eval() [38] 2020-05-24 22:25:50 ( 4.00ms ) python3 ( 6.24s ) Model( (layers): ModuleList( (0): Linear(in_features=2, out_features=100, bias=True) (1): Linear(in_features=100, out_features=100, bias=True) (2): Linear(in_features=100, out_features=1, bias=True) ) ) import torch index, input, target = next(iter(run.dataloaders.val)) with torch.no_grad(): output = run.model(input) print('[output]') print(output) print('[target]') print(target) [39] 2020-05-24 22:25:50 ( 12.0ms ) python3 ( 6.25s ) [output] tensor([[ 8.9875], [ 8.8513], [ 7.5677], [ 6.8679], [ 3.4749], [15.7395], [10.1597], [14.5195], [ 8.8349], [ 4.5969]]) [target] tensor([[ 7.6544], [ 8.2451], [ 5.9819], [ 4.8056], [ 1.7836], [21.4229], [ 9.9691], [18.8468], [ 7.9122], [ 2.8403]]) If you don't need a whole run instance, client.load_instance() is better choice to save time and memory. results = client.load_instance(run_ids[0], 'results') results [40] 2020-05-24 22:25:50 ( 29.0ms ) python3 ( 6.28s ) Results('train', 'val', 'test') for mode in ['train', 'val', 'test']: print(mode, results[mode].output.shape) [41] 2020-05-24 22:25:50 ( 11.0ms ) python3 ( 6.29s ) train (600, 1) val (200, 1) test (200, 1) For cross validation, we need 4 runs. ( n_splits is 5 but we used the last fold for dummy test data.) To load multiple run's results. Ivory Client provides a convenient method. results = client.load_results(run_ids, verbose=False) results [42] 2020-05-24 22:25:50 ( 103ms ) python3 ( 6.40s ) Results('val', 'test') for mode in ['val', 'test']: print(mode, results[mode].output.shape) [43] 2020-05-24 22:25:50 ( 8.00ms ) python3 ( 6.40s ) val (800, 1) test (800, 1) Note client.load_results drops train data for saving memory. The lengths of validation data and test data are both 800 (200 times 4). But be careful about the test data. The length of unique samples is 200 (one fold size). import numpy as np len(np.unique(results.val.index)), len(np.unique(results.test.index)) [44] 2020-05-24 22:25:50 ( 5.00ms ) python3 ( 6.41s ) (800, 200) Usually, duplicated samples are averaged. Results.mean() method performs this mean reduction and returns a newly created Rusults instance. reduced_results = results.mean() for mode in ['val', 'test']: print(mode, reduced_results[mode].output.shape) [45] 2020-05-24 22:25:50 ( 15.0ms ) python3 ( 6.42s ) val (800, 1) test (200, 1) Compare the results. index = results.test.index index_0 = index[0] x = results.test.output[index == index_0] print('[results]') print(x) print(np.mean(x)) index = reduced_results.test.index x = reduced_results.test.output[index == index_0] print('[reduced_results]') print(x) [46] 2020-05-24 22:25:50 ( 10.0ms ) python3 ( 6.43s ) [results] [[9.345718] [8.816608] [9.444256] [8.720442]] 9.081757 [reduced_results] [[9.081757]] For convenience, client.load_results() has reduction keyword argument. results = client.load_results(run_ids, reduction='mean', verbose=False) results [47] 2020-05-24 22:25:50 ( 103ms ) python3 ( 6.54s ) Results('val', 'test') for mode in ['val', 'test']: print(mode, results[mode].output.shape) [48] 2020-05-24 22:25:50 ( 6.00ms ) python3 ( 6.54s ) val (800, 1) test (200, 1)","title":"Load runs and results"},{"location":"quickstart/","text":"Skipped.","title":"Quickstart"},{"location":"api/data/","text":"Data","title":"Data"},{"location":"api/data/#data","text":"","title":"Data"},{"location":"examples/example/","text":"Skipped.","title":"Example"},{"location":"tutorial/client_experiment_run/","text":"Skipped.","title":"Client experiment run"},{"location":"tutorial/overview/","text":"Skipped.","title":"Overview"},{"location":"tutorial_old/data/","text":"Skipped.","title":"Data"},{"location":"tutorial_old/metrics/","text":"Skipped.","title":"Metrics"},{"location":"tutorial_old/model/","text":"Skipped.","title":"Model"}]}