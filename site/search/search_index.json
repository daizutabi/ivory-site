{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Ivory Documentation Ivory is a lightweight framework for machine learning. It integrates model design, tracking, and hyperparmeter tuning. Ivory uses MLflow Tracking for tracking and Optuna for hyperparmeter tuning. Using Ivory, you can tackle both tracking and tuning workflow at one place. Another key feature of Ivory is its workflow design. You can write down all of your workflow such as model structure or tracking/tuning process in one YAML file. It allows us to understand the whole process at a glance. Ivory is library-agnostic. You can use it with any machine learning library. Get started using the Quickstart. Quickstart","title":"<span class=\"pheasant-header\"><span class=\"header\"><span class=\"title\">Ivory Documentation</span></span></span>"},{"location":"#ivory-documentation","text":"Ivory is a lightweight framework for machine learning. It integrates model design, tracking, and hyperparmeter tuning. Ivory uses MLflow Tracking for tracking and Optuna for hyperparmeter tuning. Using Ivory, you can tackle both tracking and tuning workflow at one place. Another key feature of Ivory is its workflow design. You can write down all of your workflow such as model structure or tracking/tuning process in one YAML file. It allows us to understand the whole process at a glance. Ivory is library-agnostic. You can use it with any machine learning library. Get started using the Quickstart. Quickstart","title":"Ivory Documentation"},{"location":"quickstart/","text":"Quickstart Installation Install Ivory using pip . $ pip install ivory Using an Ivory Client Ivory has the Client class that manages the workflow of machine learning. Let's create your first Client instance. In this quickstart, we are working with examples under the examples directory. import ivory client = ivory.create_client(\"examples\") client [3] 2020-05-27 23:18:19 ( 1.01s ) python3 ( 1.23s ) Client(num_objects=2) The representation of the client shows that it has two objects. These objects can be accessed by index notation or dot notation . client[0] # or client['tracker'], or client.tracker [4] 2020-05-27 23:18:20 ( 3.00ms ) python3 ( 1.23s ) Tracker(tracking_uri='file:///C:/Users/daizu/Documents/github/ivory/examples/mlruns', artifact_location=None) The first object is a Tracker instance which connects Ivory to MLFlow Tracking . Because a Client instance is an iterable, you can get all of the objects by applying list() to it. list(client) [5] 2020-05-27 23:18:20 ( 3.00ms ) python3 ( 1.24s ) ['tracker', 'tuner'] The second objects is named tuner . client.tuner [6] 2020-05-27 23:18:20 ( 3.00ms ) python3 ( 1.24s ) Tuner(storage='sqlite://', sampler=None, pruner=None, load_if_exists=True) A Tuner instance connects Ivory to Optuna: A hyperparameter optimization framework . We can customize these objects with a YAML file named client.yml under the woking directory. In our case, the file just contains the minimum settings. File 1 client.yml client: tracker: tuner: Note A YAML file for client is not required. If there is no file for client, Ivory creates a default client with a tracker and without a tuner. If you don't need a tracker, for example in debugging, use ivory.create_client(tracker=False) . Create NumPy data In this quickstart, we try to predict rectangles area from thier width and height using PyTorch . First, prepare the data as NumPy arrays. In rectangle/data.py under the working directory, a create_data() function is defined. The ivory.create_client() function automatically inserts the working directory to sys.path , so that we can import the module regardless of the current directory. Let's check the create_data() function definition and an example output: Code 1 rectangle.data.create_data def create_data(num_samples=1000): xy = 4 * np.random.rand(num_samples, 2) + 1 xy = xy.astype(np.float32) dx = 0.1 * (np.random.rand(num_samples) - 0.5) dy = 0.1 * (np.random.rand(num_samples) - 0.5) z = ((xy[:, 0] + dx) * (xy[:, 1] + dy)).astype(np.float32) return xy, z import rectangle.data xy, z = rectangle.data.create_data(4) xy [9] 2020-05-27 23:18:20 ( 5.00ms ) python3 ( 1.26s ) array([[4.3368535, 4.1240745], [3.9042778, 3.103979 ], [2.0759816, 2.1330137], [1.4477707, 3.7044263]], dtype=float32) z [10] 2020-05-27 23:18:20 ( 4.00ms ) python3 ( 1.27s ) array([17.516344 , 12.129661 , 4.4025064, 5.3668284], dtype=float32) Set of Data classes Ivory defines a set of Data classes ( Data , Dataset , Datasets , DataLoaders ). But now, we use the Data class only. Code 2 rectangle.data.Data @dataclass(repr=False) class Data(ivory.core.data.Data): n_splits: int = 4 DATA = create_data(1000) # Shared by each run. def init(self): # Called from self.__post_init__() self.input, self.target = self.DATA self.index = np.arange(len(self.input)) # Extra fold for test data. self.fold = kfold_split(self.input, n_splits=self.n_splits + 1) # Creating dummy test data just for demonstration. is_test = self.fold == self.n_splits # Use an extra fold. self.fold[is_test] = -1 # -1 for test data. self.target = self.target.copy() # n_splits may be different among runs. self.target[is_test] = np.nan # Delete target for test data. self.target = self.target.reshape(-1, 1) # (sample, class) Here, kfold_split function creates a fold-array. import numpy as np from ivory.utils.fold import kfold_split kfold_split(np.arange(10), n_splits=3) [12] 2020-05-27 23:18:20 ( 4.00ms ) python3 ( 1.29s ) array([2, 1, 0, 2, 0, 2, 1, 1, 0, 0], dtype=int8) In Ivory, fold number = -1 means their samples are test data. Now, we can get a Data instance. data = rectangle.data.Data() data [13] 2020-05-27 23:18:20 ( 5.00ms ) python3 ( 1.29s ) Data(train_size=800, test_size=200) data.get(0) # get data of index = 0. [14] 2020-05-27 23:18:20 ( 3.00ms ) python3 ( 1.29s ) [0, array([2.5822766, 1.8416597], dtype=float32), array([4.844128], dtype=float32)] This returned value is a list of [index, input, target]. Ivory always keeps data index so that we can know where a sample comes from. Define a model We use a simple MLP model here. Code 3 rectangle.torch.Model class Model(nn.Module): def __init__(self, hidden_sizes): super().__init__() layers = [] for in_features, out_features in zip([2] + hidden_sizes, hidden_sizes + [1]): layers.append(nn.Linear(in_features, out_features)) self.layers = nn.ModuleList(layers) def forward(self, x): for layer in self.layers[:-1]: x = F.relu(layer(x)) return self.layers[-1](x) Parameter file for Run Ivory configures a run using a YAML file. Here is a full example. File 2 torch.yaml library: torch dataloaders: data: class: rectangle.data.Data n_splits: 4 dataset: batch_size: 10 fold: 0 model: class: rectangle.torch.Model hidden_sizes: [100, 100] optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 1e-3 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: metrics: criterion: def: torch.nn.functional.mse_loss monitor: metric: val_loss early_stopping: patience: 10 trainer: epochs: 10 verbose: 2 Let's create a run by Client.create_run() run = client.create_run('torch') run [17] 2020-05-27 23:18:20 ( 286ms ) python3 ( 1.87s ) [I 200527 23:18:20 tracker:48] A new experiment created with name: 'torch' Run(id='8ec2d61a8fec4bbb829bcda2cbe04406', name='run#0', num_objects=12) Note Client.create_run(<name>) creates an experiment named <name> if it hasn't existed yet. By cliking an icon ( ) in the above cell, you can see the log. Or you can directly create an experiment then make the experiment create a run: experiment = client . create_experiment ( 'torch' ) run = experiment . create_run () A Run instance have a params attribute that holds the parameters for the run. import yaml print(yaml.dump(run.params, sort_keys=False)) [18] 2020-05-27 23:18:21 ( 6.00ms ) python3 ( 1.87s ) run: dataloaders: data: class: rectangle.data.Data n_splits: 4 dataset: def: ivory.torch.data.Dataset batch_size: 10 fold: 0 class: ivory.torch.data.DataLoaders model: class: rectangle.torch.Model hidden_sizes: - 100 - 100 optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 0.001 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: class: ivory.torch.results.Results metrics: criterion: def: torch.nn.functional.mse_loss class: ivory.torch.metrics.Metrics monitor: metric: val_loss class: ivory.callbacks.monitor.Monitor early_stopping: patience: 10 class: ivory.callbacks.early_stopping.EarlyStopping trainer: epochs: 10 verbose: 2 class: ivory.torch.trainer.Trainer class: ivory.torch.run.Run name: run#0 id: 8ec2d61a8fec4bbb829bcda2cbe04406 experiment: name: torch class: ivory.core.base.Experiment id: '1' This is similar to the YAML file we read before, but is slightly changed by the Ivory Client. Run and experiment sections are inserted. ExperimentID and RunID are assigned by the MLFlow Tracking. Default classes are specified, for example ivory.torch.trainer.Trainer for a trainer instance. The Client.create_run() method takes keyword arguments to modify these parameters: run = client.create_run( 'torch', batch_size=20, hidden_sizes=[40, 50, 60], ) print('[dataloaders]') print(yaml.dump(run.params['run']['dataloaders'], sort_keys=False)) print('[model]') print(yaml.dump(run.params['run']['model'], sort_keys=False)) [19] 2020-05-27 23:18:21 ( 48.0ms ) python3 ( 1.92s ) [dataloaders] data: class: rectangle.data.Data n_splits: 4 dataset: def: ivory.torch.data.Dataset batch_size: 20 fold: 0 class: ivory.torch.data.DataLoaders [model] class: rectangle.torch.Model hidden_sizes: - 40 - 50 - 60 Train a model Once you got a run instance, then all you need is to start it. run = client.create_run('torch') # Back to the default settings. run.start() [20] 2020-05-27 23:18:21 ( 1.41s ) python3 ( 3.33s ) [epoch#0] loss=15.64 val_loss=6.735 lr=0.001 best [epoch#1] loss=6.861 val_loss=4.826 lr=0.001 best [epoch#2] loss=5.091 val_loss=3.203 lr=0.001 best [epoch#3] loss=3.27 val_loss=1.885 lr=0.001 best [epoch#4] loss=1.876 val_loss=0.9849 lr=0.001 best [epoch#5] loss=1.024 val_loss=0.8851 lr=0.001 best [epoch#6] loss=0.7397 val_loss=0.8339 lr=0.001 best [epoch#7] loss=0.7215 val_loss=0.5174 lr=0.001 best [epoch#8] loss=0.6436 val_loss=0.4298 lr=0.001 best [epoch#9] loss=0.6339 val_loss=0.562 lr=0.001 The history of metrics is saved as the history attribute of a run.metrics instance. run.metrics.history [21] 2020-05-27 23:18:22 ( 4.00ms ) python3 ( 3.34s ) Dict('loss', 'val_loss', 'lr') Also the model output and target are automatically collected in a run.results instance. run.results [22] 2020-05-27 23:18:22 ( 4.00ms ) python3 ( 3.34s ) Results('train', 'val') run.results.val.output[:5] [23] 2020-05-27 23:18:22 ( 4.00ms ) python3 ( 3.34s ) array([[14.95174 ], [ 6.051064 ], [17.12607 ], [ 7.2004786], [13.265303 ]], dtype=float32) run.results.val.target[:5] [24] 2020-05-27 23:18:22 ( 4.00ms ) python3 ( 3.35s ) array([[14.530574 ], [ 5.1734476], [16.429028 ], [ 7.05365 ], [12.901388 ]], dtype=float32) Test a model Testing a model is as simple as training. Just call run.start('test') instead of (default) 'train' . run.start('test') run.results [25] 2020-05-27 23:18:22 ( 43.0ms ) python3 ( 3.39s ) Results('train', 'val', 'test') As you can see, test results were added. run.results.test.output[:5] [26] 2020-05-27 23:18:22 ( 4.00ms ) python3 ( 3.39s ) array([[15.120237 ], [ 7.131886 ], [ 3.9118407], [ 8.292936 ], [ 5.343852 ]], dtype=float32) Off course the target values for the test data are np.nan . run.results.test.target[:5] [27] 2020-05-27 23:18:22 ( 4.00ms ) python3 ( 3.40s ) array([[nan], [nan], [nan], [nan], [nan]], dtype=float32) Task for multiple runs Ivory implements a special run type called Task which controls multiple nested runs. A task is useful for parameter search or cross validation. task = client.create_task('torch') task [28] 2020-05-27 23:18:22 ( 57.0ms ) python3 ( 3.46s ) Task(id='bd4766908c184d14b30d5f601e235069', name='task#0', num_objects=3) The Task class has two methods to generate multiple runs: prodcut() and chain() . These two methods have the same functionality as itertools of Python starndard library. Let's try to perform cross validation. runs = task.product(fold=range(4), verbose=0, epochs=3) runs [29] 2020-05-27 23:18:22 ( 4.00ms ) python3 ( 3.46s ) <generator object Task.product at 0x000001FA1A694D48> Like itertools 's functions, Task.prodcut() and Task.chain() return a generator, which yields runs that are configured by different parameters you specified. In this case, this generator will yield 4 runs with a fold number ranging from 0 to 4 for each. A task instance doesn't start any training by itself. In addtion, you can pass fixed parameters to update the original parameters in the YAML file. Then start 4 runs by a for loop including run.start('both') . Here 'both' means execution of test after training. for run in runs: run.start('both') [30] 2020-05-27 23:18:22 ( 2.38s ) python3 ( 5.83s ) [run#3] epochs=3 fold=0 [run#4] epochs=3 fold=1 [run#5] epochs=3 fold=2 [run#6] epochs=3 fold=3 Collect runs Our client has a Tracker instance. It stores the state of runs in background using the MLFlow Tracking. The Client class provides several methods to access the stored runs. For example, Client.search_run_ids() returns a generator which yields RunID created by the MLFlow Tracking. # A helper function def print_run_info(run_ids): for run_id in run_ids: print(run_id[:5], client.get_run_name(run_id)) [31] 2020-05-27 23:18:25 ( 4.00ms ) python3 ( 5.84s ) run_ids = client.search_run_ids('torch') # Yields all runs of `torch`. print_run_info(run_ids) [32] 2020-05-27 23:18:25 ( 73.5ms ) python3 ( 5.91s ) 79ae8 run#6 a6e05 run#5 7b35e run#4 c8254 run#3 bd476 task#0 2ea29 run#2 3f798 run#1 8ec2d run#0 For filtering, add key-value pairs. # If `exclude_parent` is True, parent runs are excluded. run_ids = client.search_run_ids('torch', fold=0, exclude_parent=True) print_run_info(run_ids) [33] 2020-05-27 23:18:25 ( 161ms ) python3 ( 6.07s ) c8254 run#3 2ea29 run#2 3f798 run#1 8ec2d run#0 # If `parent_run_id` is specified, nested runs having the parent are returned. run_ids = client.search_run_ids('torch', parent_run_id=task.id) print_run_info(run_ids) [34] 2020-05-27 23:18:25 ( 47.0ms ) python3 ( 6.12s ) 79ae8 run#6 a6e05 run#5 7b35e run#4 c8254 run#3 Client.get_run_id() and Client.get_run_ids() fetch RunID from run name, more strictly, (run class name in lower case) plus (run number). run_ids = [client.get_run_id('torch', run=0), client.get_run_id('torch', task=0)] print_run_info(run_ids) [35] 2020-05-27 23:18:25 ( 54.0ms ) python3 ( 6.17s ) 8ec2d run#0 bd476 task#0 run_ids = client.get_run_ids('torch', run=range(2, 4)) print_run_info(run_ids) [36] 2020-05-27 23:18:25 ( 57.0ms ) python3 ( 6.23s ) 2ea29 run#2 c8254 run#3 Load runs and results The Ivory Client class can load runs. First select RunID(s) to load. We want to perform cross validation here, so that we need a run collection created by the task#0 . In this case, we can use Client.get_nested_run_ids() . Why don't we use Client.search_run_ids() as we did above? Because we don't have an easy way to get a very long RunID after we restart a Python session and lose the Task instance. On the ohter hand, a run name is easy to manage and write. # Assume that we restart a session so we have no run instances. run_ids = list(client.get_nested_run_ids('torch', task=0)) print_run_info(run_ids) [37] 2020-05-27 23:18:25 ( 66.0ms ) python3 ( 6.30s ) 79ae8 run#6 a6e05 run#5 7b35e run#4 c8254 run#3 Let's load the latest run. run = client.load_run(run_ids[0]) run [38] 2020-05-27 23:18:25 ( 50.0ms ) python3 ( 6.35s ) Run(id='79ae8979b27b4398ba0c6460059c51d3', name='run#6', num_objects=11) Note that the Client.load_run() function doesn't require an experiment name because RunID is UUID . As you expected, the fold number is 3. run.dataloaders.fold [39] 2020-05-27 23:18:25 ( 4.00ms ) python3 ( 6.35s ) 3 By loading a run, we obtained the trained model. run.model.eval() [40] 2020-05-27 23:18:25 ( 5.00ms ) python3 ( 6.36s ) Model( (layers): ModuleList( (0): Linear(in_features=2, out_features=100, bias=True) (1): Linear(in_features=100, out_features=100, bias=True) (2): Linear(in_features=100, out_features=1, bias=True) ) ) import torch index, input, target = next(iter(run.dataloaders.val)) with torch.no_grad(): output = run.model(input) print('[output]') print(output[:5]) print('[target]') print(target[:5]) [41] 2020-05-27 23:18:25 ( 11.0ms ) python3 ( 6.37s ) [output] tensor([[ 9.2734], [ 9.5633], [11.0113], [14.3928], [ 4.0253]]) [target] tensor([[ 9.1201], [ 9.5565], [12.3574], [18.1897], [ 2.1280]]) If you don't need a whole run instance, Client.load_instance() is a better choice to save time and memory. results = client.load_instance(run_ids[0], 'results') results [42] 2020-05-27 23:18:25 ( 25.0ms ) python3 ( 6.39s ) Results('train', 'val', 'test') for mode in ['train', 'val', 'test']: print(mode, results[mode].output.shape) [43] 2020-05-27 23:18:25 ( 7.00ms ) python3 ( 6.40s ) train (600, 1) val (200, 1) test (200, 1) For cross validation, we need 4 runs. To load multiple run's results, the Ivory Client provides a convenient method. results = client.load_results(run_ids, verbose=False) # No progress bar. results [44] 2020-05-27 23:18:25 ( 90.0ms ) python3 ( 6.49s ) Results('val', 'test') for mode in ['val', 'test']: print(mode, results[mode].output.shape) [45] 2020-05-27 23:18:25 ( 6.00ms ) python3 ( 6.50s ) val (800, 1) test (800, 1) Note Client.load_results() drops train data for saving memory. The lengths of validation data and test data are both 800 (200 times 4). But be careful about the test data. The length of unique samples is 200 (one fold size). import numpy as np len(np.unique(results.val.index)), len(np.unique(results.test.index)) [46] 2020-05-27 23:18:25 ( 4.00ms ) python3 ( 6.50s ) (800, 200) Usually, duplicated samples are averaged for ensembling. Results.mean() method performs this mean reduction and returns a newly created Rusults instance. reduced_results = results.mean() for mode in ['val', 'test']: print(mode, reduced_results[mode].output.shape) [47] 2020-05-27 23:18:25 ( 14.0ms ) python3 ( 6.51s ) val (800, 1) test (200, 1) Compare the results. index = results.test.index index_0 = index[0] x = results.test.output[index == index_0] print('[results]') print(x) print(\"-> mean:\", np.mean(x)) index = reduced_results.test.index x = reduced_results.test.output[index == index_0] print('[reduced_results]') print(x) [48] 2020-05-27 23:18:25 ( 9.00ms ) python3 ( 6.52s ) [results] [[12.487465] [13.379925] [13.132174] [12.502523]] -> mean: 12.875523 [reduced_results] [[12.875522]] For convenience, Client.load_results() has a reduction keyword argument. results = client.load_results(run_ids, reduction='mean', verbose=False) results [49] 2020-05-27 23:18:25 ( 86.0ms ) python3 ( 6.61s ) Results('val', 'test') for mode in ['val', 'test']: print(mode, results[mode].output.shape) [50] 2020-05-27 23:18:26 ( 6.00ms ) python3 ( 6.61s ) val (800, 1) test (200, 1) A cross validation (CV) score can be calculated as follows: pred = results.val.output true = results.val.target np.mean(np.sqrt((pred - true) ** 2)) # Use any function for your metric. [51] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.62s ) 1.687068 And we got a prediction for the test data using 4 MLP models. results.test.output[:5] [52] 2020-05-27 23:18:26 ( 5.00ms ) python3 ( 6.62s ) array([[12.875522 ], [ 7.7887363], [ 5.632531 ], [ 8.772461 ], [ 7.1976414]], dtype=float32) Summary In this quickstart, we learned how to use the Ivory library to perform machine learning workflow. For more details see the tutorial section.","title":"<span class=\"pheasant-header\"><span class=\"header\"><span class=\"title\">Quickstart</span></span></span>"},{"location":"quickstart/#quickstart","text":"","title":"Quickstart"},{"location":"quickstart/#installation","text":"Install Ivory using pip . $ pip install ivory","title":"Installation"},{"location":"quickstart/#using-an-ivory-client","text":"Ivory has the Client class that manages the workflow of machine learning. Let's create your first Client instance. In this quickstart, we are working with examples under the examples directory. import ivory client = ivory.create_client(\"examples\") client [3] 2020-05-27 23:18:19 ( 1.01s ) python3 ( 1.23s ) Client(num_objects=2) The representation of the client shows that it has two objects. These objects can be accessed by index notation or dot notation . client[0] # or client['tracker'], or client.tracker [4] 2020-05-27 23:18:20 ( 3.00ms ) python3 ( 1.23s ) Tracker(tracking_uri='file:///C:/Users/daizu/Documents/github/ivory/examples/mlruns', artifact_location=None) The first object is a Tracker instance which connects Ivory to MLFlow Tracking . Because a Client instance is an iterable, you can get all of the objects by applying list() to it. list(client) [5] 2020-05-27 23:18:20 ( 3.00ms ) python3 ( 1.24s ) ['tracker', 'tuner'] The second objects is named tuner . client.tuner [6] 2020-05-27 23:18:20 ( 3.00ms ) python3 ( 1.24s ) Tuner(storage='sqlite://', sampler=None, pruner=None, load_if_exists=True) A Tuner instance connects Ivory to Optuna: A hyperparameter optimization framework . We can customize these objects with a YAML file named client.yml under the woking directory. In our case, the file just contains the minimum settings. File 1 client.yml client: tracker: tuner: Note A YAML file for client is not required. If there is no file for client, Ivory creates a default client with a tracker and without a tuner. If you don't need a tracker, for example in debugging, use ivory.create_client(tracker=False) .","title":"Using an Ivory Client"},{"location":"quickstart/#create-numpy-data","text":"In this quickstart, we try to predict rectangles area from thier width and height using PyTorch . First, prepare the data as NumPy arrays. In rectangle/data.py under the working directory, a create_data() function is defined. The ivory.create_client() function automatically inserts the working directory to sys.path , so that we can import the module regardless of the current directory. Let's check the create_data() function definition and an example output: Code 1 rectangle.data.create_data def create_data(num_samples=1000): xy = 4 * np.random.rand(num_samples, 2) + 1 xy = xy.astype(np.float32) dx = 0.1 * (np.random.rand(num_samples) - 0.5) dy = 0.1 * (np.random.rand(num_samples) - 0.5) z = ((xy[:, 0] + dx) * (xy[:, 1] + dy)).astype(np.float32) return xy, z import rectangle.data xy, z = rectangle.data.create_data(4) xy [9] 2020-05-27 23:18:20 ( 5.00ms ) python3 ( 1.26s ) array([[4.3368535, 4.1240745], [3.9042778, 3.103979 ], [2.0759816, 2.1330137], [1.4477707, 3.7044263]], dtype=float32) z [10] 2020-05-27 23:18:20 ( 4.00ms ) python3 ( 1.27s ) array([17.516344 , 12.129661 , 4.4025064, 5.3668284], dtype=float32)","title":"Create NumPy data"},{"location":"quickstart/#set-of-data-classes","text":"Ivory defines a set of Data classes ( Data , Dataset , Datasets , DataLoaders ). But now, we use the Data class only. Code 2 rectangle.data.Data @dataclass(repr=False) class Data(ivory.core.data.Data): n_splits: int = 4 DATA = create_data(1000) # Shared by each run. def init(self): # Called from self.__post_init__() self.input, self.target = self.DATA self.index = np.arange(len(self.input)) # Extra fold for test data. self.fold = kfold_split(self.input, n_splits=self.n_splits + 1) # Creating dummy test data just for demonstration. is_test = self.fold == self.n_splits # Use an extra fold. self.fold[is_test] = -1 # -1 for test data. self.target = self.target.copy() # n_splits may be different among runs. self.target[is_test] = np.nan # Delete target for test data. self.target = self.target.reshape(-1, 1) # (sample, class) Here, kfold_split function creates a fold-array. import numpy as np from ivory.utils.fold import kfold_split kfold_split(np.arange(10), n_splits=3) [12] 2020-05-27 23:18:20 ( 4.00ms ) python3 ( 1.29s ) array([2, 1, 0, 2, 0, 2, 1, 1, 0, 0], dtype=int8) In Ivory, fold number = -1 means their samples are test data. Now, we can get a Data instance. data = rectangle.data.Data() data [13] 2020-05-27 23:18:20 ( 5.00ms ) python3 ( 1.29s ) Data(train_size=800, test_size=200) data.get(0) # get data of index = 0. [14] 2020-05-27 23:18:20 ( 3.00ms ) python3 ( 1.29s ) [0, array([2.5822766, 1.8416597], dtype=float32), array([4.844128], dtype=float32)] This returned value is a list of [index, input, target]. Ivory always keeps data index so that we can know where a sample comes from.","title":"Set of Data classes"},{"location":"quickstart/#define-a-model","text":"We use a simple MLP model here. Code 3 rectangle.torch.Model class Model(nn.Module): def __init__(self, hidden_sizes): super().__init__() layers = [] for in_features, out_features in zip([2] + hidden_sizes, hidden_sizes + [1]): layers.append(nn.Linear(in_features, out_features)) self.layers = nn.ModuleList(layers) def forward(self, x): for layer in self.layers[:-1]: x = F.relu(layer(x)) return self.layers[-1](x)","title":"Define a model"},{"location":"quickstart/#parameter-file-for-run","text":"Ivory configures a run using a YAML file. Here is a full example. File 2 torch.yaml library: torch dataloaders: data: class: rectangle.data.Data n_splits: 4 dataset: batch_size: 10 fold: 0 model: class: rectangle.torch.Model hidden_sizes: [100, 100] optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 1e-3 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: metrics: criterion: def: torch.nn.functional.mse_loss monitor: metric: val_loss early_stopping: patience: 10 trainer: epochs: 10 verbose: 2 Let's create a run by Client.create_run() run = client.create_run('torch') run [17] 2020-05-27 23:18:20 ( 286ms ) python3 ( 1.87s ) [I 200527 23:18:20 tracker:48] A new experiment created with name: 'torch' Run(id='8ec2d61a8fec4bbb829bcda2cbe04406', name='run#0', num_objects=12) Note Client.create_run(<name>) creates an experiment named <name> if it hasn't existed yet. By cliking an icon ( ) in the above cell, you can see the log. Or you can directly create an experiment then make the experiment create a run: experiment = client . create_experiment ( 'torch' ) run = experiment . create_run () A Run instance have a params attribute that holds the parameters for the run. import yaml print(yaml.dump(run.params, sort_keys=False)) [18] 2020-05-27 23:18:21 ( 6.00ms ) python3 ( 1.87s ) run: dataloaders: data: class: rectangle.data.Data n_splits: 4 dataset: def: ivory.torch.data.Dataset batch_size: 10 fold: 0 class: ivory.torch.data.DataLoaders model: class: rectangle.torch.Model hidden_sizes: - 100 - 100 optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 0.001 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: class: ivory.torch.results.Results metrics: criterion: def: torch.nn.functional.mse_loss class: ivory.torch.metrics.Metrics monitor: metric: val_loss class: ivory.callbacks.monitor.Monitor early_stopping: patience: 10 class: ivory.callbacks.early_stopping.EarlyStopping trainer: epochs: 10 verbose: 2 class: ivory.torch.trainer.Trainer class: ivory.torch.run.Run name: run#0 id: 8ec2d61a8fec4bbb829bcda2cbe04406 experiment: name: torch class: ivory.core.base.Experiment id: '1' This is similar to the YAML file we read before, but is slightly changed by the Ivory Client. Run and experiment sections are inserted. ExperimentID and RunID are assigned by the MLFlow Tracking. Default classes are specified, for example ivory.torch.trainer.Trainer for a trainer instance. The Client.create_run() method takes keyword arguments to modify these parameters: run = client.create_run( 'torch', batch_size=20, hidden_sizes=[40, 50, 60], ) print('[dataloaders]') print(yaml.dump(run.params['run']['dataloaders'], sort_keys=False)) print('[model]') print(yaml.dump(run.params['run']['model'], sort_keys=False)) [19] 2020-05-27 23:18:21 ( 48.0ms ) python3 ( 1.92s ) [dataloaders] data: class: rectangle.data.Data n_splits: 4 dataset: def: ivory.torch.data.Dataset batch_size: 20 fold: 0 class: ivory.torch.data.DataLoaders [model] class: rectangle.torch.Model hidden_sizes: - 40 - 50 - 60","title":"Parameter file for Run"},{"location":"quickstart/#train-a-model","text":"Once you got a run instance, then all you need is to start it. run = client.create_run('torch') # Back to the default settings. run.start() [20] 2020-05-27 23:18:21 ( 1.41s ) python3 ( 3.33s ) [epoch#0] loss=15.64 val_loss=6.735 lr=0.001 best [epoch#1] loss=6.861 val_loss=4.826 lr=0.001 best [epoch#2] loss=5.091 val_loss=3.203 lr=0.001 best [epoch#3] loss=3.27 val_loss=1.885 lr=0.001 best [epoch#4] loss=1.876 val_loss=0.9849 lr=0.001 best [epoch#5] loss=1.024 val_loss=0.8851 lr=0.001 best [epoch#6] loss=0.7397 val_loss=0.8339 lr=0.001 best [epoch#7] loss=0.7215 val_loss=0.5174 lr=0.001 best [epoch#8] loss=0.6436 val_loss=0.4298 lr=0.001 best [epoch#9] loss=0.6339 val_loss=0.562 lr=0.001 The history of metrics is saved as the history attribute of a run.metrics instance. run.metrics.history [21] 2020-05-27 23:18:22 ( 4.00ms ) python3 ( 3.34s ) Dict('loss', 'val_loss', 'lr') Also the model output and target are automatically collected in a run.results instance. run.results [22] 2020-05-27 23:18:22 ( 4.00ms ) python3 ( 3.34s ) Results('train', 'val') run.results.val.output[:5] [23] 2020-05-27 23:18:22 ( 4.00ms ) python3 ( 3.34s ) array([[14.95174 ], [ 6.051064 ], [17.12607 ], [ 7.2004786], [13.265303 ]], dtype=float32) run.results.val.target[:5] [24] 2020-05-27 23:18:22 ( 4.00ms ) python3 ( 3.35s ) array([[14.530574 ], [ 5.1734476], [16.429028 ], [ 7.05365 ], [12.901388 ]], dtype=float32)","title":"Train a model"},{"location":"quickstart/#test-a-model","text":"Testing a model is as simple as training. Just call run.start('test') instead of (default) 'train' . run.start('test') run.results [25] 2020-05-27 23:18:22 ( 43.0ms ) python3 ( 3.39s ) Results('train', 'val', 'test') As you can see, test results were added. run.results.test.output[:5] [26] 2020-05-27 23:18:22 ( 4.00ms ) python3 ( 3.39s ) array([[15.120237 ], [ 7.131886 ], [ 3.9118407], [ 8.292936 ], [ 5.343852 ]], dtype=float32) Off course the target values for the test data are np.nan . run.results.test.target[:5] [27] 2020-05-27 23:18:22 ( 4.00ms ) python3 ( 3.40s ) array([[nan], [nan], [nan], [nan], [nan]], dtype=float32)","title":"Test a model"},{"location":"quickstart/#task-for-multiple-runs","text":"Ivory implements a special run type called Task which controls multiple nested runs. A task is useful for parameter search or cross validation. task = client.create_task('torch') task [28] 2020-05-27 23:18:22 ( 57.0ms ) python3 ( 3.46s ) Task(id='bd4766908c184d14b30d5f601e235069', name='task#0', num_objects=3) The Task class has two methods to generate multiple runs: prodcut() and chain() . These two methods have the same functionality as itertools of Python starndard library. Let's try to perform cross validation. runs = task.product(fold=range(4), verbose=0, epochs=3) runs [29] 2020-05-27 23:18:22 ( 4.00ms ) python3 ( 3.46s ) <generator object Task.product at 0x000001FA1A694D48> Like itertools 's functions, Task.prodcut() and Task.chain() return a generator, which yields runs that are configured by different parameters you specified. In this case, this generator will yield 4 runs with a fold number ranging from 0 to 4 for each. A task instance doesn't start any training by itself. In addtion, you can pass fixed parameters to update the original parameters in the YAML file. Then start 4 runs by a for loop including run.start('both') . Here 'both' means execution of test after training. for run in runs: run.start('both') [30] 2020-05-27 23:18:22 ( 2.38s ) python3 ( 5.83s ) [run#3] epochs=3 fold=0 [run#4] epochs=3 fold=1 [run#5] epochs=3 fold=2 [run#6] epochs=3 fold=3","title":"Task for multiple runs"},{"location":"quickstart/#collect-runs","text":"Our client has a Tracker instance. It stores the state of runs in background using the MLFlow Tracking. The Client class provides several methods to access the stored runs. For example, Client.search_run_ids() returns a generator which yields RunID created by the MLFlow Tracking. # A helper function def print_run_info(run_ids): for run_id in run_ids: print(run_id[:5], client.get_run_name(run_id)) [31] 2020-05-27 23:18:25 ( 4.00ms ) python3 ( 5.84s ) run_ids = client.search_run_ids('torch') # Yields all runs of `torch`. print_run_info(run_ids) [32] 2020-05-27 23:18:25 ( 73.5ms ) python3 ( 5.91s ) 79ae8 run#6 a6e05 run#5 7b35e run#4 c8254 run#3 bd476 task#0 2ea29 run#2 3f798 run#1 8ec2d run#0 For filtering, add key-value pairs. # If `exclude_parent` is True, parent runs are excluded. run_ids = client.search_run_ids('torch', fold=0, exclude_parent=True) print_run_info(run_ids) [33] 2020-05-27 23:18:25 ( 161ms ) python3 ( 6.07s ) c8254 run#3 2ea29 run#2 3f798 run#1 8ec2d run#0 # If `parent_run_id` is specified, nested runs having the parent are returned. run_ids = client.search_run_ids('torch', parent_run_id=task.id) print_run_info(run_ids) [34] 2020-05-27 23:18:25 ( 47.0ms ) python3 ( 6.12s ) 79ae8 run#6 a6e05 run#5 7b35e run#4 c8254 run#3 Client.get_run_id() and Client.get_run_ids() fetch RunID from run name, more strictly, (run class name in lower case) plus (run number). run_ids = [client.get_run_id('torch', run=0), client.get_run_id('torch', task=0)] print_run_info(run_ids) [35] 2020-05-27 23:18:25 ( 54.0ms ) python3 ( 6.17s ) 8ec2d run#0 bd476 task#0 run_ids = client.get_run_ids('torch', run=range(2, 4)) print_run_info(run_ids) [36] 2020-05-27 23:18:25 ( 57.0ms ) python3 ( 6.23s ) 2ea29 run#2 c8254 run#3","title":"Collect runs"},{"location":"quickstart/#load-runs-and-results","text":"The Ivory Client class can load runs. First select RunID(s) to load. We want to perform cross validation here, so that we need a run collection created by the task#0 . In this case, we can use Client.get_nested_run_ids() . Why don't we use Client.search_run_ids() as we did above? Because we don't have an easy way to get a very long RunID after we restart a Python session and lose the Task instance. On the ohter hand, a run name is easy to manage and write. # Assume that we restart a session so we have no run instances. run_ids = list(client.get_nested_run_ids('torch', task=0)) print_run_info(run_ids) [37] 2020-05-27 23:18:25 ( 66.0ms ) python3 ( 6.30s ) 79ae8 run#6 a6e05 run#5 7b35e run#4 c8254 run#3 Let's load the latest run. run = client.load_run(run_ids[0]) run [38] 2020-05-27 23:18:25 ( 50.0ms ) python3 ( 6.35s ) Run(id='79ae8979b27b4398ba0c6460059c51d3', name='run#6', num_objects=11) Note that the Client.load_run() function doesn't require an experiment name because RunID is UUID . As you expected, the fold number is 3. run.dataloaders.fold [39] 2020-05-27 23:18:25 ( 4.00ms ) python3 ( 6.35s ) 3 By loading a run, we obtained the trained model. run.model.eval() [40] 2020-05-27 23:18:25 ( 5.00ms ) python3 ( 6.36s ) Model( (layers): ModuleList( (0): Linear(in_features=2, out_features=100, bias=True) (1): Linear(in_features=100, out_features=100, bias=True) (2): Linear(in_features=100, out_features=1, bias=True) ) ) import torch index, input, target = next(iter(run.dataloaders.val)) with torch.no_grad(): output = run.model(input) print('[output]') print(output[:5]) print('[target]') print(target[:5]) [41] 2020-05-27 23:18:25 ( 11.0ms ) python3 ( 6.37s ) [output] tensor([[ 9.2734], [ 9.5633], [11.0113], [14.3928], [ 4.0253]]) [target] tensor([[ 9.1201], [ 9.5565], [12.3574], [18.1897], [ 2.1280]]) If you don't need a whole run instance, Client.load_instance() is a better choice to save time and memory. results = client.load_instance(run_ids[0], 'results') results [42] 2020-05-27 23:18:25 ( 25.0ms ) python3 ( 6.39s ) Results('train', 'val', 'test') for mode in ['train', 'val', 'test']: print(mode, results[mode].output.shape) [43] 2020-05-27 23:18:25 ( 7.00ms ) python3 ( 6.40s ) train (600, 1) val (200, 1) test (200, 1) For cross validation, we need 4 runs. To load multiple run's results, the Ivory Client provides a convenient method. results = client.load_results(run_ids, verbose=False) # No progress bar. results [44] 2020-05-27 23:18:25 ( 90.0ms ) python3 ( 6.49s ) Results('val', 'test') for mode in ['val', 'test']: print(mode, results[mode].output.shape) [45] 2020-05-27 23:18:25 ( 6.00ms ) python3 ( 6.50s ) val (800, 1) test (800, 1) Note Client.load_results() drops train data for saving memory. The lengths of validation data and test data are both 800 (200 times 4). But be careful about the test data. The length of unique samples is 200 (one fold size). import numpy as np len(np.unique(results.val.index)), len(np.unique(results.test.index)) [46] 2020-05-27 23:18:25 ( 4.00ms ) python3 ( 6.50s ) (800, 200) Usually, duplicated samples are averaged for ensembling. Results.mean() method performs this mean reduction and returns a newly created Rusults instance. reduced_results = results.mean() for mode in ['val', 'test']: print(mode, reduced_results[mode].output.shape) [47] 2020-05-27 23:18:25 ( 14.0ms ) python3 ( 6.51s ) val (800, 1) test (200, 1) Compare the results. index = results.test.index index_0 = index[0] x = results.test.output[index == index_0] print('[results]') print(x) print(\"-> mean:\", np.mean(x)) index = reduced_results.test.index x = reduced_results.test.output[index == index_0] print('[reduced_results]') print(x) [48] 2020-05-27 23:18:25 ( 9.00ms ) python3 ( 6.52s ) [results] [[12.487465] [13.379925] [13.132174] [12.502523]] -> mean: 12.875523 [reduced_results] [[12.875522]] For convenience, Client.load_results() has a reduction keyword argument. results = client.load_results(run_ids, reduction='mean', verbose=False) results [49] 2020-05-27 23:18:25 ( 86.0ms ) python3 ( 6.61s ) Results('val', 'test') for mode in ['val', 'test']: print(mode, results[mode].output.shape) [50] 2020-05-27 23:18:26 ( 6.00ms ) python3 ( 6.61s ) val (800, 1) test (200, 1) A cross validation (CV) score can be calculated as follows: pred = results.val.output true = results.val.target np.mean(np.sqrt((pred - true) ** 2)) # Use any function for your metric. [51] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.62s ) 1.687068 And we got a prediction for the test data using 4 MLP models. results.test.output[:5] [52] 2020-05-27 23:18:26 ( 5.00ms ) python3 ( 6.62s ) array([[12.875522 ], [ 7.7887363], [ 5.632531 ], [ 8.772461 ], [ 7.1976414]], dtype=float32)","title":"Load runs and results"},{"location":"quickstart/#summary","text":"In this quickstart, we learned how to use the Ivory library to perform machine learning workflow. For more details see the tutorial section.","title":"Summary"},{"location":"api/data/","text":"Skipped.","title":"Data"},{"location":"tutorial/callbacks/","text":"Callbacks Base System Ivory implements a simple but powerful callback system. Here is the list of callback functions: import ivory.core.base ivory.core.base.Callback.METHODS [2] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.88s ) ['on_init_begin', 'on_init_end', 'on_fit_begin', 'on_epoch_begin', 'on_train_begin', 'on_train_end', 'on_val_begin', 'on_val_end', 'on_epoch_end', 'on_fit_end', 'on_test_begin', 'on_test_end'] Any class that defines these functions can be a callback instance. class SimpleCallback: # No base class is needed. # You don't have to define all of the callback functions def on_fit_begin(self, run): # Must have a `run` argument. print(f'on_fit_begin is called from id={id(run)}') # Do something with `run`. [3] 2020-05-27 23:18:26 ( 3.00ms ) python3 ( 6.89s ) To invoke callback functions, create a CallbackCaller instance. caller = ivory.core.base.CallbackCaller(simple=SimpleCallback()) caller [4] 2020-05-27 23:18:26 ( 3.00ms ) python3 ( 6.89s ) CallbackCaller(num_objects=1) The number of registerd objects is 1. list(caller) [5] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.89s ) ['simple'] Then call the CallbackCaller.create_callbacks() method to build a callback network. caller.create_callbacks() caller [6] 2020-05-27 23:18:26 ( 3.00ms ) python3 ( 6.90s ) CallbackCaller(num_objects=13) The number of objects increased up to 13. list(caller) [7] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.90s ) ['simple', 'on_init_begin', 'on_init_end', 'on_fit_begin', 'on_epoch_begin', 'on_train_begin', 'on_train_end', 'on_val_begin', 'on_val_end', 'on_epoch_end', 'on_fit_end', 'on_test_begin', 'on_test_end'] Callback functions are added to the caller instance. Inspect each callback funtion. caller.on_init_begin [8] 2020-05-27 23:18:26 ( 3.00ms ) python3 ( 6.90s ) Callback([]) This is an empty callback because the caller has no objects that define the on_init_begin() function. On the other hand, caller.on_fit_begin [9] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.91s ) Callback(['simple']) The simple object is registerd as a receiver for the on_fit_begin() function. We can call this. caller.on_fit_begin() [10] 2020-05-27 23:18:26 ( 3.00ms ) python3 ( 6.91s ) on_fit_begin is called from id=2173798106696 id(caller) [11] 2020-05-27 23:18:26 ( 3.00ms ) python3 ( 6.91s ) 2173798106696 This caller-receiver network among arbitrary object collection builds a complex machine learning workflow. The Run class is a subclass of the CallbackCaller class and performs more library-specific process. We uses this Run class below. Example Preparation To work with the callbacks, we create data and model set that we have used. For more details about the following code, see Creating Instance section. import yaml # A helper function. def create(doc, name, **kwargs): params = yaml.safe_load(doc) return create_instance(params, name, **kwargs) doc = \"\"\" library: torch dataloaders: data: class: rectangle.data.Data n_splits: 5 dataset: fold: 0 batch_size: 4 model: class: rectangle.torch.Model hidden_sizes: [3, 4, 5] \"\"\" dataloaders = create(doc, 'dataloaders') model = create(doc, 'model') [12] 2020-05-27 23:18:26 ( 9.00ms ) python3 ( 6.92s ) Results The Results callback stores index, output, and target data. To save memory, a Results instance ignores input data. # import ivory.callbacks.results # For Scikit-learn or TensorFlow. import ivory.torch.results results = ivory.torch.results.Results() results [13] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.93s ) Results() import ivory.core.run run = ivory.core.run.Run( dataloaders=dataloaders, model=model, results=results ) run.create_callbacks() run [14] 2020-05-27 23:18:26 ( 5.00ms ) python3 ( 6.93s ) Run(num_objects=15) # A helper function def print_callbacks(obj): for func in ivory.core.base.Callback.METHODS: if hasattr(obj, func) and callable(getattr(obj, func)): print(func) print_callbacks(results) [15] 2020-05-27 23:18:26 ( 8.00ms ) python3 ( 6.94s ) on_train_begin on_train_end on_val_end on_test_begin on_test_end Let's play with the Results callback. The Results.step() method records the current index, output, and target. # For simplicity, just one epoch with some batches. run.on_train_begin() data_iter = iter(run.dataloaders.train) for _ in range(3): index, input, target = next(data_iter) output = model(input) run.results.step(index, output, target) # Do something for example parameter update or early stopping. run.on_train_end() run.on_val_begin() # Can call even if there is no callback. data_iter = iter(run.dataloaders.val) for _ in range(2): index, input, target = next(data_iter) output = run.model(input) run.results.step(index, output, target) run.on_val_end() run.on_epoch_end() results [16] 2020-05-27 23:18:26 ( 8.00ms ) python3 ( 6.95s ) Results('train', 'val') We performed a train and validation loop so that the Results instance has these data, but doesn't have test data. We can get data by nested dot-notation. results.train [17] 2020-05-27 23:18:26 ( 3.00ms ) python3 ( 6.95s ) Dict('index', 'output', 'target') results.train.index # Shuffled. The length is batch_size (4) x 3. [18] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.96s ) array([940, 460, 346, 433, 730, 989, 166, 842, 145, 686, 419, 402]) results.val.index # Not shuffled. The length is batch_size (4) x 2. [19] 2020-05-27 23:18:26 ( 3.00ms ) python3 ( 6.96s ) array([ 1, 8, 14, 27, 30, 31, 34, 45]) results.val.output # Actually, no learning. [20] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.96s ) array([[-0.04234976], [-0.05683768], [-0.0305914 ], [-0.03906339], [-0.0390932 ], [-0.0305914 ], [-0.0305914 ], [-0.07992584]], dtype=float32) results.val.target [21] 2020-05-27 23:18:26 ( 3.00ms ) python3 ( 6.97s ) array([[14.530574 ], [16.429028 ], [ 7.05365 ], [12.901388 ], [ 4.232388 ], [ 1.188243 ], [ 3.8026145], [ 7.906225 ]], dtype=float32) Other Callback There are several callback such as Metrics , Monitor , etc . We will learn about them in next 'Training a Model' section.","title":"<span class=\"pheasant-header\"><span class=\"header\"><span class=\"title\">Callbacks</span></span></span>"},{"location":"tutorial/callbacks/#callbacks","text":"","title":"Callbacks"},{"location":"tutorial/callbacks/#base-system","text":"Ivory implements a simple but powerful callback system. Here is the list of callback functions: import ivory.core.base ivory.core.base.Callback.METHODS [2] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.88s ) ['on_init_begin', 'on_init_end', 'on_fit_begin', 'on_epoch_begin', 'on_train_begin', 'on_train_end', 'on_val_begin', 'on_val_end', 'on_epoch_end', 'on_fit_end', 'on_test_begin', 'on_test_end'] Any class that defines these functions can be a callback instance. class SimpleCallback: # No base class is needed. # You don't have to define all of the callback functions def on_fit_begin(self, run): # Must have a `run` argument. print(f'on_fit_begin is called from id={id(run)}') # Do something with `run`. [3] 2020-05-27 23:18:26 ( 3.00ms ) python3 ( 6.89s ) To invoke callback functions, create a CallbackCaller instance. caller = ivory.core.base.CallbackCaller(simple=SimpleCallback()) caller [4] 2020-05-27 23:18:26 ( 3.00ms ) python3 ( 6.89s ) CallbackCaller(num_objects=1) The number of registerd objects is 1. list(caller) [5] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.89s ) ['simple'] Then call the CallbackCaller.create_callbacks() method to build a callback network. caller.create_callbacks() caller [6] 2020-05-27 23:18:26 ( 3.00ms ) python3 ( 6.90s ) CallbackCaller(num_objects=13) The number of objects increased up to 13. list(caller) [7] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.90s ) ['simple', 'on_init_begin', 'on_init_end', 'on_fit_begin', 'on_epoch_begin', 'on_train_begin', 'on_train_end', 'on_val_begin', 'on_val_end', 'on_epoch_end', 'on_fit_end', 'on_test_begin', 'on_test_end'] Callback functions are added to the caller instance. Inspect each callback funtion. caller.on_init_begin [8] 2020-05-27 23:18:26 ( 3.00ms ) python3 ( 6.90s ) Callback([]) This is an empty callback because the caller has no objects that define the on_init_begin() function. On the other hand, caller.on_fit_begin [9] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.91s ) Callback(['simple']) The simple object is registerd as a receiver for the on_fit_begin() function. We can call this. caller.on_fit_begin() [10] 2020-05-27 23:18:26 ( 3.00ms ) python3 ( 6.91s ) on_fit_begin is called from id=2173798106696 id(caller) [11] 2020-05-27 23:18:26 ( 3.00ms ) python3 ( 6.91s ) 2173798106696 This caller-receiver network among arbitrary object collection builds a complex machine learning workflow. The Run class is a subclass of the CallbackCaller class and performs more library-specific process. We uses this Run class below.","title":"Base System"},{"location":"tutorial/callbacks/#example-preparation","text":"To work with the callbacks, we create data and model set that we have used. For more details about the following code, see Creating Instance section. import yaml # A helper function. def create(doc, name, **kwargs): params = yaml.safe_load(doc) return create_instance(params, name, **kwargs) doc = \"\"\" library: torch dataloaders: data: class: rectangle.data.Data n_splits: 5 dataset: fold: 0 batch_size: 4 model: class: rectangle.torch.Model hidden_sizes: [3, 4, 5] \"\"\" dataloaders = create(doc, 'dataloaders') model = create(doc, 'model') [12] 2020-05-27 23:18:26 ( 9.00ms ) python3 ( 6.92s )","title":"Example Preparation"},{"location":"tutorial/callbacks/#results","text":"The Results callback stores index, output, and target data. To save memory, a Results instance ignores input data. # import ivory.callbacks.results # For Scikit-learn or TensorFlow. import ivory.torch.results results = ivory.torch.results.Results() results [13] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.93s ) Results() import ivory.core.run run = ivory.core.run.Run( dataloaders=dataloaders, model=model, results=results ) run.create_callbacks() run [14] 2020-05-27 23:18:26 ( 5.00ms ) python3 ( 6.93s ) Run(num_objects=15) # A helper function def print_callbacks(obj): for func in ivory.core.base.Callback.METHODS: if hasattr(obj, func) and callable(getattr(obj, func)): print(func) print_callbacks(results) [15] 2020-05-27 23:18:26 ( 8.00ms ) python3 ( 6.94s ) on_train_begin on_train_end on_val_end on_test_begin on_test_end Let's play with the Results callback. The Results.step() method records the current index, output, and target. # For simplicity, just one epoch with some batches. run.on_train_begin() data_iter = iter(run.dataloaders.train) for _ in range(3): index, input, target = next(data_iter) output = model(input) run.results.step(index, output, target) # Do something for example parameter update or early stopping. run.on_train_end() run.on_val_begin() # Can call even if there is no callback. data_iter = iter(run.dataloaders.val) for _ in range(2): index, input, target = next(data_iter) output = run.model(input) run.results.step(index, output, target) run.on_val_end() run.on_epoch_end() results [16] 2020-05-27 23:18:26 ( 8.00ms ) python3 ( 6.95s ) Results('train', 'val') We performed a train and validation loop so that the Results instance has these data, but doesn't have test data. We can get data by nested dot-notation. results.train [17] 2020-05-27 23:18:26 ( 3.00ms ) python3 ( 6.95s ) Dict('index', 'output', 'target') results.train.index # Shuffled. The length is batch_size (4) x 3. [18] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.96s ) array([940, 460, 346, 433, 730, 989, 166, 842, 145, 686, 419, 402]) results.val.index # Not shuffled. The length is batch_size (4) x 2. [19] 2020-05-27 23:18:26 ( 3.00ms ) python3 ( 6.96s ) array([ 1, 8, 14, 27, 30, 31, 34, 45]) results.val.output # Actually, no learning. [20] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.96s ) array([[-0.04234976], [-0.05683768], [-0.0305914 ], [-0.03906339], [-0.0390932 ], [-0.0305914 ], [-0.0305914 ], [-0.07992584]], dtype=float32) results.val.target [21] 2020-05-27 23:18:26 ( 3.00ms ) python3 ( 6.97s ) array([[14.530574 ], [16.429028 ], [ 7.05365 ], [12.901388 ], [ 4.232388 ], [ 1.188243 ], [ 3.8026145], [ 7.906225 ]], dtype=float32)","title":"Results"},{"location":"tutorial/callbacks/#other-callback","text":"There are several callback such as Metrics , Monitor , etc . We will learn about them in next 'Training a Model' section.","title":"Other Callback"},{"location":"tutorial/core/","text":"Ivory Core Entities Client Ivory has the Client class that manages the workflow of machine learning. In this tutorial, we are working with data and model to predict rectangle area. The source module exists under the examples directory. First, create a Client instance. import ivory client = ivory.create_client(\"examples\") # Set the working directory client [3] 2020-05-27 23:18:27 ( 9.00ms ) python3 ( 7.97s ) Client(num_objects=2) list(client) [4] 2020-05-27 23:18:27 ( 4.00ms ) python3 ( 7.98s ) ['tracker', 'tuner'] The first object is a Tracker instance which connects Ivory to MLFlow Tracking . The second objects is named tuner . A Tuner instance connects Ivory to Optuna: A hyperparameter optimization framework . Show the files in the working directory examples . import os os.listdir('examples') [5] 2020-05-27 23:18:27 ( 4.00ms ) python3 ( 7.98s ) ['client.yml', 'mlruns', 'rectangle', 'torch.yml', '__pycache__'] rectangle is a Python package that contains our examples. YAML files with extension of .yml or possibly .yaml are parameter files to define a machine learning workflow. Basically, one YAML file is corresponding to one Experiment as discussed later, except the client.yml file. A YAML file name without the extension becomes an experiment name. mlruns is a directory automatically created by the MLFlow Tracking in which our trained model and callbacks instances are saved. The client.yml is a configuration file for a Client instance. In our case, the file just contains the minimum settings. File 5 client.yml client: tracker: tuner: Note A YAML file for client is not required. If there is no file for client, Ivory creates a default client with a tracker and without a tuner. If you don't need a tracker, for example in debugging, use ivory.create_client(tracker=False) . Experiment The Client.create_experiment() function creates an Experiment instance. If the Client instance has a tracker , an experiment of the MLFlow Tracking is also created at the same time if it hasn't existed yet. By cliking an icon ( ) in the below cell, you can see the log. experiment = client.create_experiment('torch') # Read torch.yml as params. experiment [6] 2020-05-27 23:18:27 ( 14.0ms ) python3 ( 8.00s ) [I 200527 23:18:27 tracker:48] A new experiment created with name: 'torch' Experiment(id='1', name='torch', num_objects=1) The ID for this experiment was given by the MLFlow Tracking. The Client.create_experiment() function loads a corresponding YAML file to the first argument from the working directory. File 6 torch.yml library: torch dataloaders: data: class: rectangle.data.Data n_splits: 4 dataset: batch_size: 10 fold: 0 model: class: rectangle.torch.Model hidden_sizes: [100, 100] optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 1e-3 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: metrics: criterion: def: torch.nn.functional.mse_loss monitor: metric: val_loss early_stopping: patience: 10 trainer: epochs: 10 verbose: 2 After loading, the Experiment instance setups the parameters for creating runs later. The parameters are stored in the params attribute. experiment.params [7] 2020-05-27 23:18:27 ( 6.00ms ) python3 ( 8.00s ) {'run': {'dataloaders': {'data': {'class': 'rectangle.data.Data', 'n_splits': 4}, 'dataset': {'def': 'ivory.torch.data.Dataset'}, 'batch_size': 10, 'fold': 0, 'class': 'ivory.torch.data.DataLoaders'}, 'model': {'class': 'rectangle.torch.Model', 'hidden_sizes': [100, 100]}, 'optimizer': {'class': 'torch.optim.SGD', 'params': '$.model.parameters()', 'lr': 0.001}, 'scheduler': {'class': 'torch.optim.lr_scheduler.ReduceLROnPlateau', 'optimizer': '$', 'factor': 0.5, 'patience': 4}, 'results': {'class': 'ivory.torch.results.Results'}, 'metrics': {'criterion': {'def': 'torch.nn.functional.mse_loss'}, 'class': 'ivory.torch.metrics.Metrics'}, 'monitor': {'metric': 'val_loss', 'class': 'ivory.callbacks.monitor.Monitor'}, 'early_stopping': {'patience': 10, 'class': 'ivory.callbacks.early_stopping.EarlyStopping'}, 'trainer': {'epochs': 10, 'verbose': 2, 'class': 'ivory.torch.trainer.Trainer'}, 'class': 'ivory.torch.run.Run'}, 'experiment': {'name': 'torch', 'class': 'ivory.core.base.Experiment', 'id': '1'}} This is similar to the YAML file, but is slightly changed by the Ivory Client. Run and experiment sections are inserted. ExperimentID and RunID are assigned by the MLFlow Tracking. Default classes are specified, for example ivory.torch.trainer.Trainer for a trainer instance. Run After setting up an Experiment instance, you can create runs with various parameters. Ivory provides several way to configure them as below. Default parameters Calling without arguments creates a run with default parameters. run = experiment.create_run() run [8] 2020-05-27 23:18:27 ( 45.0ms ) python3 ( 8.05s ) Run(id='aac9fd7b48104a1f8bf3dc2d7a0eb7b7', name='run#0', num_objects=12) Here, the ID for this run was given by the MLFlow Tracking. On the other hand, the name is given by Ivory as a form of \" (run class name in lower case)#(run number) \". Simple literal (int, float, str) Passing key-value pairs, you can change the parameters. run = experiment.create_run(fold=1) run.dataloaders.fold [9] 2020-05-27 23:18:27 ( 40.0ms ) python3 ( 8.09s ) 1 But the type of parameter must be equal, otherwise a ValueError is raised. run = experiment.create_run(fold=0.5) run.dataloaders.fold [10] 2020-05-27 23:18:27 ( 131ms ) python3 ( 8.22s ) ValueError: different type: <class 'int'> != <class 'float'> ValueError Traceback (most recent call last) <ipython-input-162-689904ca4a89> in <module> ----> 1 run = experiment.create_run(fold=0.5) 2 run.dataloaders.fold ~\\Documents\\github\\ivory\\ivory\\core\\base.py in create_run(self, args, name, **kwargs) 55 56 def create_run(self, args=None, name: str = \"run\", **kwargs): ---> 57 params, args = self.create_params(args, name, **kwargs) 58 run = instance.create_base_instance(params, name, self.source_name) 59 if self.tracker: ~\\Documents\\github\\ivory\\ivory\\core\\base.py in create_params(self, args, name, **kwargs) 51 params.update(default.get(name)) 52 update, args = utils.params.create_update(params[name], args, **kwargs) ---> 53 utils.params.update_dict(params[name], update) 54 return params, args 55 ~\\Documents\\github\\ivory\\ivory\\utils\\params.py in update_dict(org, update) 28 x[k] = value 29 elif type(x[k]) is not type(value) and x[k] is not None: ---> 30 raise ValueError(f\"different type: {type(x[k])} != {type(value)}\") 31 else: 32 if isinstance(x[k], dict): List A list parameter can be overwritten by passing a new list. Off course you can change the lengh of the list. The original hidden_sizes was [100, 100] . run = experiment.create_run(hidden_sizes=[2, 3, 4]) run.model [11] 2020-05-27 23:18:27 ( 138ms ) python3 ( 8.36s ) Model( (layers): ModuleList( (0): Linear(in_features=2, out_features=2, bias=True) (1): Linear(in_features=2, out_features=3, bias=True) (2): Linear(in_features=3, out_features=4, bias=True) (3): Linear(in_features=4, out_features=1, bias=True) ) ) As an alternative way, you can use 0-indexed colon-notation like below. In this case, pass a dictionary to the first argument, because a colon ( : ) can't be in keyword arguments. params = { \"hidden_sizes:0\": 10, # Order is important. \"hidden_sizes:1\": 20, # Start from 0. \"hidden_sizes:2\": 30, # No skip. No reverse. } run = experiment.create_run(params) run.model [12] 2020-05-27 23:18:28 ( 46.0ms ) python3 ( 8.40s ) Model( (layers): ModuleList( (0): Linear(in_features=2, out_features=10, bias=True) (1): Linear(in_features=10, out_features=20, bias=True) (2): Linear(in_features=20, out_features=30, bias=True) (3): Linear(in_features=30, out_features=1, bias=True) ) ) Do you feel this method is unnecessary? This method is prepared for hyperparameter tuning . In some case, you may want to change a part of list. Use 0-indexed dot-notation . params = {\"hidden_sizes.1\": 5} run = experiment.create_run(params) run.model [13] 2020-05-27 23:18:28 ( 45.0ms ) python3 ( 8.45s ) Model( (layers): ModuleList( (0): Linear(in_features=2, out_features=100, bias=True) (1): Linear(in_features=100, out_features=5, bias=True) (2): Linear(in_features=5, out_features=1, bias=True) ) ) Duplicated parameter name Duplicated parameters with the same name are updated together. run = experiment.create_run(patience=5) run.scheduler.patience, run.early_stopping.patience [14] 2020-05-27 23:18:28 ( 45.0ms ) python3 ( 8.49s ) (5, 5) This behavior is natural to update the parameters with the same meaning. But in the above example, the patience of early stopping becomes equal to that of scheduler, so the scheduler doesn't work at all. Scoping by dots To specify an individual parameter even if there are other parameters with the same name, use scoping by dots, or parameter fullname . params = {'scheduler.patience': 8, 'early_stopping.patience': 20} run = experiment.create_run(params) run.scheduler.patience, run.early_stopping.patience [15] 2020-05-27 23:18:28 ( 47.0ms ) python3 ( 8.54s ) (8, 20) Object type Parameters are not limited to a literal such as int , float , or str . For example, run = experiment.create_run() run.optimizer [16] 2020-05-27 23:18:28 ( 52.0ms ) python3 ( 8.59s ) SGD ( Parameter Group 0 dampening: 0 lr: 0.001 momentum: 0 nesterov: False weight_decay: 0 ) run = experiment.create_run({'optimizer.class': 'torch.optim.Adam'}) run.optimizer [17] 2020-05-27 23:18:28 ( 51.0ms ) python3 ( 8.64s ) Adam ( Parameter Group 0 amsgrad: False betas: (0.9, 0.999) eps: 1e-08 lr: 0.001 weight_decay: 0 ) This means that you can compare optimizer algorithms easily through multiple runs with minimul effort. Creating a run from a client In the above examples, we created runs using the experiment.create_run() method. In addtion, you can do the same thing by client.create_run() with an experiment name as the first argument. The following code blocks are equivalent. Code 4 experiment = client.create_experiment('torch') run = experiment.create_run(fold=3) Code 5 run = client.create_run('torch', fold=3)","title":"<span class=\"pheasant-header\"><span class=\"header\"><span class=\"title\">Ivory Core Entities</span></span></span>"},{"location":"tutorial/core/#ivory-core-entities","text":"","title":"Ivory Core Entities"},{"location":"tutorial/core/#client","text":"Ivory has the Client class that manages the workflow of machine learning. In this tutorial, we are working with data and model to predict rectangle area. The source module exists under the examples directory. First, create a Client instance. import ivory client = ivory.create_client(\"examples\") # Set the working directory client [3] 2020-05-27 23:18:27 ( 9.00ms ) python3 ( 7.97s ) Client(num_objects=2) list(client) [4] 2020-05-27 23:18:27 ( 4.00ms ) python3 ( 7.98s ) ['tracker', 'tuner'] The first object is a Tracker instance which connects Ivory to MLFlow Tracking . The second objects is named tuner . A Tuner instance connects Ivory to Optuna: A hyperparameter optimization framework . Show the files in the working directory examples . import os os.listdir('examples') [5] 2020-05-27 23:18:27 ( 4.00ms ) python3 ( 7.98s ) ['client.yml', 'mlruns', 'rectangle', 'torch.yml', '__pycache__'] rectangle is a Python package that contains our examples. YAML files with extension of .yml or possibly .yaml are parameter files to define a machine learning workflow. Basically, one YAML file is corresponding to one Experiment as discussed later, except the client.yml file. A YAML file name without the extension becomes an experiment name. mlruns is a directory automatically created by the MLFlow Tracking in which our trained model and callbacks instances are saved. The client.yml is a configuration file for a Client instance. In our case, the file just contains the minimum settings. File 5 client.yml client: tracker: tuner: Note A YAML file for client is not required. If there is no file for client, Ivory creates a default client with a tracker and without a tuner. If you don't need a tracker, for example in debugging, use ivory.create_client(tracker=False) .","title":"Client"},{"location":"tutorial/core/#experiment","text":"The Client.create_experiment() function creates an Experiment instance. If the Client instance has a tracker , an experiment of the MLFlow Tracking is also created at the same time if it hasn't existed yet. By cliking an icon ( ) in the below cell, you can see the log. experiment = client.create_experiment('torch') # Read torch.yml as params. experiment [6] 2020-05-27 23:18:27 ( 14.0ms ) python3 ( 8.00s ) [I 200527 23:18:27 tracker:48] A new experiment created with name: 'torch' Experiment(id='1', name='torch', num_objects=1) The ID for this experiment was given by the MLFlow Tracking. The Client.create_experiment() function loads a corresponding YAML file to the first argument from the working directory. File 6 torch.yml library: torch dataloaders: data: class: rectangle.data.Data n_splits: 4 dataset: batch_size: 10 fold: 0 model: class: rectangle.torch.Model hidden_sizes: [100, 100] optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 1e-3 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: metrics: criterion: def: torch.nn.functional.mse_loss monitor: metric: val_loss early_stopping: patience: 10 trainer: epochs: 10 verbose: 2 After loading, the Experiment instance setups the parameters for creating runs later. The parameters are stored in the params attribute. experiment.params [7] 2020-05-27 23:18:27 ( 6.00ms ) python3 ( 8.00s ) {'run': {'dataloaders': {'data': {'class': 'rectangle.data.Data', 'n_splits': 4}, 'dataset': {'def': 'ivory.torch.data.Dataset'}, 'batch_size': 10, 'fold': 0, 'class': 'ivory.torch.data.DataLoaders'}, 'model': {'class': 'rectangle.torch.Model', 'hidden_sizes': [100, 100]}, 'optimizer': {'class': 'torch.optim.SGD', 'params': '$.model.parameters()', 'lr': 0.001}, 'scheduler': {'class': 'torch.optim.lr_scheduler.ReduceLROnPlateau', 'optimizer': '$', 'factor': 0.5, 'patience': 4}, 'results': {'class': 'ivory.torch.results.Results'}, 'metrics': {'criterion': {'def': 'torch.nn.functional.mse_loss'}, 'class': 'ivory.torch.metrics.Metrics'}, 'monitor': {'metric': 'val_loss', 'class': 'ivory.callbacks.monitor.Monitor'}, 'early_stopping': {'patience': 10, 'class': 'ivory.callbacks.early_stopping.EarlyStopping'}, 'trainer': {'epochs': 10, 'verbose': 2, 'class': 'ivory.torch.trainer.Trainer'}, 'class': 'ivory.torch.run.Run'}, 'experiment': {'name': 'torch', 'class': 'ivory.core.base.Experiment', 'id': '1'}} This is similar to the YAML file, but is slightly changed by the Ivory Client. Run and experiment sections are inserted. ExperimentID and RunID are assigned by the MLFlow Tracking. Default classes are specified, for example ivory.torch.trainer.Trainer for a trainer instance.","title":"Experiment"},{"location":"tutorial/core/#run","text":"After setting up an Experiment instance, you can create runs with various parameters. Ivory provides several way to configure them as below.","title":"Run"},{"location":"tutorial/core/#default-parameters","text":"Calling without arguments creates a run with default parameters. run = experiment.create_run() run [8] 2020-05-27 23:18:27 ( 45.0ms ) python3 ( 8.05s ) Run(id='aac9fd7b48104a1f8bf3dc2d7a0eb7b7', name='run#0', num_objects=12) Here, the ID for this run was given by the MLFlow Tracking. On the other hand, the name is given by Ivory as a form of \" (run class name in lower case)#(run number) \".","title":"Default parameters"},{"location":"tutorial/core/#simple-literal-int-float-str","text":"Passing key-value pairs, you can change the parameters. run = experiment.create_run(fold=1) run.dataloaders.fold [9] 2020-05-27 23:18:27 ( 40.0ms ) python3 ( 8.09s ) 1 But the type of parameter must be equal, otherwise a ValueError is raised. run = experiment.create_run(fold=0.5) run.dataloaders.fold [10] 2020-05-27 23:18:27 ( 131ms ) python3 ( 8.22s ) ValueError: different type: <class 'int'> != <class 'float'> ValueError Traceback (most recent call last) <ipython-input-162-689904ca4a89> in <module> ----> 1 run = experiment.create_run(fold=0.5) 2 run.dataloaders.fold ~\\Documents\\github\\ivory\\ivory\\core\\base.py in create_run(self, args, name, **kwargs) 55 56 def create_run(self, args=None, name: str = \"run\", **kwargs): ---> 57 params, args = self.create_params(args, name, **kwargs) 58 run = instance.create_base_instance(params, name, self.source_name) 59 if self.tracker: ~\\Documents\\github\\ivory\\ivory\\core\\base.py in create_params(self, args, name, **kwargs) 51 params.update(default.get(name)) 52 update, args = utils.params.create_update(params[name], args, **kwargs) ---> 53 utils.params.update_dict(params[name], update) 54 return params, args 55 ~\\Documents\\github\\ivory\\ivory\\utils\\params.py in update_dict(org, update) 28 x[k] = value 29 elif type(x[k]) is not type(value) and x[k] is not None: ---> 30 raise ValueError(f\"different type: {type(x[k])} != {type(value)}\") 31 else: 32 if isinstance(x[k], dict):","title":"Simple literal (int, float, str)"},{"location":"tutorial/core/#list","text":"A list parameter can be overwritten by passing a new list. Off course you can change the lengh of the list. The original hidden_sizes was [100, 100] . run = experiment.create_run(hidden_sizes=[2, 3, 4]) run.model [11] 2020-05-27 23:18:27 ( 138ms ) python3 ( 8.36s ) Model( (layers): ModuleList( (0): Linear(in_features=2, out_features=2, bias=True) (1): Linear(in_features=2, out_features=3, bias=True) (2): Linear(in_features=3, out_features=4, bias=True) (3): Linear(in_features=4, out_features=1, bias=True) ) ) As an alternative way, you can use 0-indexed colon-notation like below. In this case, pass a dictionary to the first argument, because a colon ( : ) can't be in keyword arguments. params = { \"hidden_sizes:0\": 10, # Order is important. \"hidden_sizes:1\": 20, # Start from 0. \"hidden_sizes:2\": 30, # No skip. No reverse. } run = experiment.create_run(params) run.model [12] 2020-05-27 23:18:28 ( 46.0ms ) python3 ( 8.40s ) Model( (layers): ModuleList( (0): Linear(in_features=2, out_features=10, bias=True) (1): Linear(in_features=10, out_features=20, bias=True) (2): Linear(in_features=20, out_features=30, bias=True) (3): Linear(in_features=30, out_features=1, bias=True) ) ) Do you feel this method is unnecessary? This method is prepared for hyperparameter tuning . In some case, you may want to change a part of list. Use 0-indexed dot-notation . params = {\"hidden_sizes.1\": 5} run = experiment.create_run(params) run.model [13] 2020-05-27 23:18:28 ( 45.0ms ) python3 ( 8.45s ) Model( (layers): ModuleList( (0): Linear(in_features=2, out_features=100, bias=True) (1): Linear(in_features=100, out_features=5, bias=True) (2): Linear(in_features=5, out_features=1, bias=True) ) )","title":"List"},{"location":"tutorial/core/#duplicated-parameter-name","text":"Duplicated parameters with the same name are updated together. run = experiment.create_run(patience=5) run.scheduler.patience, run.early_stopping.patience [14] 2020-05-27 23:18:28 ( 45.0ms ) python3 ( 8.49s ) (5, 5) This behavior is natural to update the parameters with the same meaning. But in the above example, the patience of early stopping becomes equal to that of scheduler, so the scheduler doesn't work at all.","title":"Duplicated parameter name"},{"location":"tutorial/core/#scoping-by-dots","text":"To specify an individual parameter even if there are other parameters with the same name, use scoping by dots, or parameter fullname . params = {'scheduler.patience': 8, 'early_stopping.patience': 20} run = experiment.create_run(params) run.scheduler.patience, run.early_stopping.patience [15] 2020-05-27 23:18:28 ( 47.0ms ) python3 ( 8.54s ) (8, 20)","title":"Scoping by dots"},{"location":"tutorial/core/#object-type","text":"Parameters are not limited to a literal such as int , float , or str . For example, run = experiment.create_run() run.optimizer [16] 2020-05-27 23:18:28 ( 52.0ms ) python3 ( 8.59s ) SGD ( Parameter Group 0 dampening: 0 lr: 0.001 momentum: 0 nesterov: False weight_decay: 0 ) run = experiment.create_run({'optimizer.class': 'torch.optim.Adam'}) run.optimizer [17] 2020-05-27 23:18:28 ( 51.0ms ) python3 ( 8.64s ) Adam ( Parameter Group 0 amsgrad: False betas: (0.9, 0.999) eps: 1e-08 lr: 0.001 weight_decay: 0 ) This means that you can compare optimizer algorithms easily through multiple runs with minimul effort.","title":"Object type"},{"location":"tutorial/core/#creating-a-run-from-a-client","text":"In the above examples, we created runs using the experiment.create_run() method. In addtion, you can do the same thing by client.create_run() with an experiment name as the first argument. The following code blocks are equivalent. Code 4 experiment = client.create_experiment('torch') run = experiment.create_run(fold=3) Code 5 run = client.create_run('torch', fold=3)","title":"Creating a run from a client"},{"location":"tutorial/data/","text":"Set of Data classes Ivory uses four classes for data presentation: Data , Dataset , Datasets , and DataLoaders . In this tutorial, we use the following Python module to explain about them. File 3 rectangle/data.py from dataclasses import dataclass import numpy as np import ivory.core.data from ivory.utils.fold import kfold_split def create_data(num_samples=1000): xy = 4 * np.random.rand(num_samples, 2) + 1 xy = xy.astype(np.float32) dx = 0.1 * (np.random.rand(num_samples) - 0.5) dy = 0.1 * (np.random.rand(num_samples) - 0.5) z = ((xy[:, 0] + dx) * (xy[:, 1] + dy)).astype(np.float32) return xy, z @dataclass(repr=False) class Data(ivory.core.data.Data): n_splits: int = 4 DATA = create_data(1000) # Shared by each run. def init(self): # Called from self.__post_init__() self.input, self.target = self.DATA self.index = np.arange(len(self.input)) # Extra fold for test data. self.fold = kfold_split(self.input, n_splits=self.n_splits + 1) # Creating dummy test data just for demonstration. is_test = self.fold == self.n_splits # Use an extra fold. self.fold[is_test] = -1 # -1 for test data. self.target = self.target.copy() # n_splits may be different among runs. self.target[is_test] = np.nan # Delete target for test data. self.target = self.target.reshape(-1, 1) # (sample, class) Data First import the module and check the basic behavior. import rectangle.data data = rectangle.data.Data() data [2] 2020-05-27 23:18:26 ( 5.00ms ) python3 ( 6.64s ) Data(train_size=800, test_size=200) In the Data.init() method, we need to define 4 attributes: index : Index of samples. input : Input data. target : Target data. fold : Fold number. A Data.get() method returns a list of [ index , input , target ]. This method is called from the Dataset instance when the dataset is indexed. data.get(0) # Integer index. [3] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.65s ) [0, array([2.5822766, 1.8416597], dtype=float32), array([4.844128], dtype=float32)] data.get([0, 10, 20]) # Array-like index. list or np.ndarray [4] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.65s ) [array([ 0, 10, 20]), array([[2.5822766, 1.8416597], [4.0087214, 2.7256494], [1.4196029, 3.1013453]], dtype=float32), array([[ 4.844128 ], [11.264139 ], [ 4.4585967]], dtype=float32)] Dataset An instance of the Dataset class holds one of train, validation, and test dataset. We use the Ivory's default Dataset class here instead of defining a subclass. The Dataset() initializer requires three arguments: A Data instance, mode , and fold . import ivory.core.data dataset = ivory.core.data.Dataset(data, 'train', 0) dataset [5] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.65s ) Dataset(mode='train', num_samples=600) ivory.core.data.Dataset(data, 'val', 1) # Another mode is `test`. [6] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.66s ) Dataset(mode='val', num_samples=200) As the Data class, the Dataset class has a init() method without any arguments and no returned value. You can define any code to modify data. To get sample from an dataset. use normal indexing dataset[0] # Integer index. [7] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.66s ) [0, array([2.5822766, 1.8416597], dtype=float32), array([4.844128], dtype=float32)] dataset[[0, 10, 20]] # Array-like index. list or np.ndarray [8] 2020-05-27 23:18:26 ( 5.00ms ) python3 ( 6.67s ) [array([ 0, 16, 33]), array([[2.5822766, 1.8416597], [4.395951 , 2.777363 ], [1.9857726, 4.36225 ]], dtype=float32), array([[ 4.844128], [12.357417], [ 8.939154]], dtype=float32)] index, *_ = dataset[:] print(len(index)) index[:10] [9] 2020-05-27 23:18:26 ( 6.00ms ) python3 ( 6.67s ) 600 array([ 0, 2, 3, 4, 6, 7, 10, 12, 13, 15]) These data come from a subset of the data instance according to the mode and fold. The Dataset class takes an opptional argument: transform . def transform(mode:str, input, target): if mode == 'train': input = input * 2 target = target * 2 return input, target dataset_transformed = ivory.core.data.Dataset(data, 'train', 0, transform) dataset_transformed[0] [10] 2020-05-27 23:18:26 ( 5.00ms ) python3 ( 6.68s ) [0, array([5.164553 , 3.6833193], dtype=float32), array([9.688256], dtype=float32)] [2 * dataset[0][1], 2 * dataset[0][2]] [11] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.68s ) [array([5.164553 , 3.6833193], dtype=float32), array([9.688256], dtype=float32)] Usually, we don't instantiate the Dataset object directly. Instead, the next Datasets class manages the dataset. Datasets An instance of the Datasets class holds a set of train, validation, and test dataset. We use the Ivory's default Datasets class here instead of defining a subclass. The Datasets() initializer requires three arguments: A Data instance, Dataset factory, and fold . from ivory.core.data import Dataset datasets = ivory.core.data.Datasets(data, Dataset, 0) datasets [12] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.69s ) Datasets(data=Data(train_size=800, test_size=200), dataset=<class 'ivory.core.data.Dataset'>, fold=0) Note The second argument ( dataset ) is not a Dataset instance but its factory that returns a Dataset instance. It may be a Dataset class itself or any function. A Datasets instance is a dict-like object: for dataset in datasets.items(): print(dataset) [13] 2020-05-27 23:18:26 ( 5.00ms ) python3 ( 6.69s ) ('train', Dataset(mode='train', num_samples=600)) ('val', Dataset(mode='val', num_samples=200)) ('test', Dataset(mode='test', num_samples=200)) Each dataset can be accessed by indexing or attributes. datasets['train'], datasets.val [14] 2020-05-27 23:18:26 ( 3.00ms ) python3 ( 6.69s ) (Dataset(mode='train', num_samples=600), Dataset(mode='val', num_samples=200)) Using the Datasets class, we can easily split a whole data stored in a Data instance into three train, validation, and test dataset. DataLoaders The last class is the DataLoaders . This class is prepared for loading batches from a dataset. For example, assume that we are going to use PyTorch. from ivory.torch.data import DataLoaders dataloaders = DataLoaders(data, Dataset, fold=0, batch_size=4) dataloaders [15] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.70s ) DataLoaders(data=Data(train_size=800, test_size=200), dataset=<class 'ivory.core.data.Dataset'>, fold=0, batch_size=4) Note The second argument ( dataset ) is not a Dataset instance but its factory that returns a Dataset instance. It may be a Dataset class itself or any function. for dataloader in dataloaders.items(): print(dataloader) [16] 2020-05-27 23:18:26 ( 5.00ms ) python3 ( 6.70s ) ('train', <torch.utils.data.dataloader.DataLoader object at 0x000001FA20740548>) ('val', <torch.utils.data.dataloader.DataLoader object at 0x000001FA20740648>) ('test', <torch.utils.data.dataloader.DataLoader object at 0x000001FA20740708>) As you can see an ivory.torch.data.DataLoaders instance creates PyTorch's DataLoader. Check the samples. next(iter(dataloaders.train)) [17] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.71s ) [tensor([863, 934, 344, 921], dtype=torch.int32), tensor([[4.2536, 4.2360], [4.4070, 2.2437], [3.2638, 4.8974], [1.5204, 1.1074]]), tensor([[18.0138], [ 9.6532], [15.9436], [ 1.6779]])] Returned samples are torch.Tensor instead of np.ndarray . We can use these tensors as inputs of a model.","title":"<span class=\"pheasant-header\"><span class=\"header\"><span class=\"title\">Set of Data classes</span></span></span>"},{"location":"tutorial/data/#set-of-data-classes","text":"Ivory uses four classes for data presentation: Data , Dataset , Datasets , and DataLoaders . In this tutorial, we use the following Python module to explain about them. File 3 rectangle/data.py from dataclasses import dataclass import numpy as np import ivory.core.data from ivory.utils.fold import kfold_split def create_data(num_samples=1000): xy = 4 * np.random.rand(num_samples, 2) + 1 xy = xy.astype(np.float32) dx = 0.1 * (np.random.rand(num_samples) - 0.5) dy = 0.1 * (np.random.rand(num_samples) - 0.5) z = ((xy[:, 0] + dx) * (xy[:, 1] + dy)).astype(np.float32) return xy, z @dataclass(repr=False) class Data(ivory.core.data.Data): n_splits: int = 4 DATA = create_data(1000) # Shared by each run. def init(self): # Called from self.__post_init__() self.input, self.target = self.DATA self.index = np.arange(len(self.input)) # Extra fold for test data. self.fold = kfold_split(self.input, n_splits=self.n_splits + 1) # Creating dummy test data just for demonstration. is_test = self.fold == self.n_splits # Use an extra fold. self.fold[is_test] = -1 # -1 for test data. self.target = self.target.copy() # n_splits may be different among runs. self.target[is_test] = np.nan # Delete target for test data. self.target = self.target.reshape(-1, 1) # (sample, class)","title":"Set of Data classes"},{"location":"tutorial/data/#data","text":"First import the module and check the basic behavior. import rectangle.data data = rectangle.data.Data() data [2] 2020-05-27 23:18:26 ( 5.00ms ) python3 ( 6.64s ) Data(train_size=800, test_size=200) In the Data.init() method, we need to define 4 attributes: index : Index of samples. input : Input data. target : Target data. fold : Fold number. A Data.get() method returns a list of [ index , input , target ]. This method is called from the Dataset instance when the dataset is indexed. data.get(0) # Integer index. [3] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.65s ) [0, array([2.5822766, 1.8416597], dtype=float32), array([4.844128], dtype=float32)] data.get([0, 10, 20]) # Array-like index. list or np.ndarray [4] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.65s ) [array([ 0, 10, 20]), array([[2.5822766, 1.8416597], [4.0087214, 2.7256494], [1.4196029, 3.1013453]], dtype=float32), array([[ 4.844128 ], [11.264139 ], [ 4.4585967]], dtype=float32)]","title":"Data"},{"location":"tutorial/data/#dataset","text":"An instance of the Dataset class holds one of train, validation, and test dataset. We use the Ivory's default Dataset class here instead of defining a subclass. The Dataset() initializer requires three arguments: A Data instance, mode , and fold . import ivory.core.data dataset = ivory.core.data.Dataset(data, 'train', 0) dataset [5] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.65s ) Dataset(mode='train', num_samples=600) ivory.core.data.Dataset(data, 'val', 1) # Another mode is `test`. [6] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.66s ) Dataset(mode='val', num_samples=200) As the Data class, the Dataset class has a init() method without any arguments and no returned value. You can define any code to modify data. To get sample from an dataset. use normal indexing dataset[0] # Integer index. [7] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.66s ) [0, array([2.5822766, 1.8416597], dtype=float32), array([4.844128], dtype=float32)] dataset[[0, 10, 20]] # Array-like index. list or np.ndarray [8] 2020-05-27 23:18:26 ( 5.00ms ) python3 ( 6.67s ) [array([ 0, 16, 33]), array([[2.5822766, 1.8416597], [4.395951 , 2.777363 ], [1.9857726, 4.36225 ]], dtype=float32), array([[ 4.844128], [12.357417], [ 8.939154]], dtype=float32)] index, *_ = dataset[:] print(len(index)) index[:10] [9] 2020-05-27 23:18:26 ( 6.00ms ) python3 ( 6.67s ) 600 array([ 0, 2, 3, 4, 6, 7, 10, 12, 13, 15]) These data come from a subset of the data instance according to the mode and fold. The Dataset class takes an opptional argument: transform . def transform(mode:str, input, target): if mode == 'train': input = input * 2 target = target * 2 return input, target dataset_transformed = ivory.core.data.Dataset(data, 'train', 0, transform) dataset_transformed[0] [10] 2020-05-27 23:18:26 ( 5.00ms ) python3 ( 6.68s ) [0, array([5.164553 , 3.6833193], dtype=float32), array([9.688256], dtype=float32)] [2 * dataset[0][1], 2 * dataset[0][2]] [11] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.68s ) [array([5.164553 , 3.6833193], dtype=float32), array([9.688256], dtype=float32)] Usually, we don't instantiate the Dataset object directly. Instead, the next Datasets class manages the dataset.","title":"Dataset"},{"location":"tutorial/data/#datasets","text":"An instance of the Datasets class holds a set of train, validation, and test dataset. We use the Ivory's default Datasets class here instead of defining a subclass. The Datasets() initializer requires three arguments: A Data instance, Dataset factory, and fold . from ivory.core.data import Dataset datasets = ivory.core.data.Datasets(data, Dataset, 0) datasets [12] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.69s ) Datasets(data=Data(train_size=800, test_size=200), dataset=<class 'ivory.core.data.Dataset'>, fold=0) Note The second argument ( dataset ) is not a Dataset instance but its factory that returns a Dataset instance. It may be a Dataset class itself or any function. A Datasets instance is a dict-like object: for dataset in datasets.items(): print(dataset) [13] 2020-05-27 23:18:26 ( 5.00ms ) python3 ( 6.69s ) ('train', Dataset(mode='train', num_samples=600)) ('val', Dataset(mode='val', num_samples=200)) ('test', Dataset(mode='test', num_samples=200)) Each dataset can be accessed by indexing or attributes. datasets['train'], datasets.val [14] 2020-05-27 23:18:26 ( 3.00ms ) python3 ( 6.69s ) (Dataset(mode='train', num_samples=600), Dataset(mode='val', num_samples=200)) Using the Datasets class, we can easily split a whole data stored in a Data instance into three train, validation, and test dataset.","title":"Datasets"},{"location":"tutorial/data/#dataloaders","text":"The last class is the DataLoaders . This class is prepared for loading batches from a dataset. For example, assume that we are going to use PyTorch. from ivory.torch.data import DataLoaders dataloaders = DataLoaders(data, Dataset, fold=0, batch_size=4) dataloaders [15] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.70s ) DataLoaders(data=Data(train_size=800, test_size=200), dataset=<class 'ivory.core.data.Dataset'>, fold=0, batch_size=4) Note The second argument ( dataset ) is not a Dataset instance but its factory that returns a Dataset instance. It may be a Dataset class itself or any function. for dataloader in dataloaders.items(): print(dataloader) [16] 2020-05-27 23:18:26 ( 5.00ms ) python3 ( 6.70s ) ('train', <torch.utils.data.dataloader.DataLoader object at 0x000001FA20740548>) ('val', <torch.utils.data.dataloader.DataLoader object at 0x000001FA20740648>) ('test', <torch.utils.data.dataloader.DataLoader object at 0x000001FA20740708>) As you can see an ivory.torch.data.DataLoaders instance creates PyTorch's DataLoader. Check the samples. next(iter(dataloaders.train)) [17] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.71s ) [tensor([863, 934, 344, 921], dtype=torch.int32), tensor([[4.2536, 4.2360], [4.4070, 2.2437], [3.2638, 4.8974], [1.5204, 1.1074]]), tensor([[18.0138], [ 9.6532], [15.9436], [ 1.6779]])] Returned samples are torch.Tensor instead of np.ndarray . We can use these tensors as inputs of a model.","title":"DataLoaders"},{"location":"tutorial/instance/","text":"Creating Instance In this tutorial, we will learn about Ivory's internal instance creation system. This is worth to understand the way of writing a YAML file for machine learning. We creates a DataLoaders described in the previous section . Basic idea A syntax to create an instance is similar to a dictionary. example = ExampleCalss(arg1=123, arg2='abc') can be equivalently written as {'example': {'class': 'ExampleCalss', 'args1': 123, 'arg2': 'abc'}} Ivory excactly uses this relationship. We call this dictionary params . from ivory.core.instance import create_instance params = {'data': {'class': 'rectangle.data.Data', 'n_splits': 5}} data = create_instance(params, 'data') data [2] 2020-05-27 23:18:26 ( 5.00ms ) python3 ( 6.73s ) Data(train_size=834, test_size=166) Here, create_instance() requires the second parameter name to specify a key because params can have multiple keys. Note that we added n_splits parameter which is different from the default value 5. Let's see unique values of fold. import numpy as np np.unique(data.fold) [3] 2020-05-27 23:18:26 ( 5.00ms ) python3 ( 6.73s ) array([-1, 0, 1, 2, 3, 4], dtype=int8) For writing parmas easily, we use PyYAML library . import yaml # A helper function. def create(doc, name, **kwargs): params = yaml.safe_load(doc) return create_instance(params, name, **kwargs) doc = \"\"\" data: class: rectangle.data.Data n_splits: 5 \"\"\" create(doc, 'data') [4] 2020-05-27 23:18:26 ( 6.00ms ) python3 ( 6.74s ) Data(train_size=834, test_size=166) Hierarchal Structure Next create a Dataset instance. The Dataset class requires a Data instance as the first argument so that the corresponding dictionary have hierarchal structure. doc = \"\"\" dataset: class: ivory.core.data.Dataset data: class: rectangle.data.Data n_splits: 5 mode: train fold: 0 \"\"\" create(doc, 'dataset') [5] 2020-05-27 23:18:26 ( 6.00ms ) python3 ( 6.74s ) Dataset(mode='train', num_samples=667) As you can see, Ivory can treat this hierarchal structure correctly. Furthermore, create a DataLoaders instance for PyTorch. doc = \"\"\" dataloaders: class: ivory.torch.data.DataLoaders data: class: rectangle.data.Data n_splits: 5 dataset: def: ivory.core.data.Dataset fold: 0 batch_size: 4 \"\"\" create(doc, 'dataloaders') [6] 2020-05-27 23:18:26 ( 6.00ms ) python3 ( 6.75s ) DataLoaders(data=Data(train_size=834, test_size=166), dataset=<class 'ivory.core.data.Dataset'>, fold=0, batch_size=4) Remember that the argument dataset for the DataLoaders class is not an instance but a callable that returns a Dataset instance. To describe this behavior, you can use a new def key instead of class . (See the previous section ) Default Class In the above example, the two lines using a class of Ivory seems to be verbose a little bit. Ivory adds a default class if the class or def key is missing. Here is the list of default classes prepared by Ivory: from ivory.core.default import DEFAULT_CLASS for library, values in DEFAULT_CLASS.items(): print(f'library: {library}') for name, value in values.items(): print(\" \", name, \"---\", value) [7] 2020-05-27 23:18:26 ( 68.0ms ) python3 ( 6.82s ) library: core client --- ivory.core.client.Client tracker --- ivory.core.tracker.Tracker tuner --- ivory.core.tuner.Tuner experiment --- ivory.core.base.Experiment objective --- ivory.core.objective.Objective run --- ivory.core.run.Run task --- ivory.core.run.Task study --- ivory.core.run.Study dataset --- ivory.core.data.Dataset datasets --- ivory.core.data.Datasets dataloaders --- ivory.core.data.DataLoaders results --- ivory.callbacks.results.Results metrics --- ivory.callbacks.metrics.Metrics monitor --- ivory.callbacks.monitor.Monitor early_stopping --- ivory.callbacks.early_stopping.EarlyStopping library: torch run --- ivory.torch.run.Run dataloaders --- ivory.torch.data.DataLoaders dataset --- ivory.torch.data.Dataset results --- ivory.torch.results.Results metrics --- ivory.torch.metrics.Metrics trainer --- ivory.torch.trainer.Trainer library: tensorflow run --- ivory.tensorflow.run.Run trainer --- ivory.tensorflow.trainer.Trainer library: sklearn estimator --- ivory.sklearn.estimator.Estimator Therefore, we can omit the lines using default classes like below. Here, the library key is used to overload the default classes of the ivory.core package by the specific library. doc = \"\"\" library: torch dataloaders: data: class: rectangle.data.Data n_splits: 5 dataset: fold: 0 batch_size: 4 \"\"\" create(doc, 'dataloaders') [8] 2020-05-27 23:18:26 ( 6.00ms ) python3 ( 6.82s ) DataLoaders(data=Data(train_size=834, test_size=166), dataset=<class 'ivory.torch.data.Dataset'>, fold=0, batch_size=4)","title":"<span class=\"pheasant-header\"><span class=\"header\"><span class=\"title\">Creating Instance</span></span></span>"},{"location":"tutorial/instance/#creating-instance","text":"In this tutorial, we will learn about Ivory's internal instance creation system. This is worth to understand the way of writing a YAML file for machine learning. We creates a DataLoaders described in the previous section .","title":"Creating Instance"},{"location":"tutorial/instance/#basic-idea","text":"A syntax to create an instance is similar to a dictionary. example = ExampleCalss(arg1=123, arg2='abc') can be equivalently written as {'example': {'class': 'ExampleCalss', 'args1': 123, 'arg2': 'abc'}} Ivory excactly uses this relationship. We call this dictionary params . from ivory.core.instance import create_instance params = {'data': {'class': 'rectangle.data.Data', 'n_splits': 5}} data = create_instance(params, 'data') data [2] 2020-05-27 23:18:26 ( 5.00ms ) python3 ( 6.73s ) Data(train_size=834, test_size=166) Here, create_instance() requires the second parameter name to specify a key because params can have multiple keys. Note that we added n_splits parameter which is different from the default value 5. Let's see unique values of fold. import numpy as np np.unique(data.fold) [3] 2020-05-27 23:18:26 ( 5.00ms ) python3 ( 6.73s ) array([-1, 0, 1, 2, 3, 4], dtype=int8) For writing parmas easily, we use PyYAML library . import yaml # A helper function. def create(doc, name, **kwargs): params = yaml.safe_load(doc) return create_instance(params, name, **kwargs) doc = \"\"\" data: class: rectangle.data.Data n_splits: 5 \"\"\" create(doc, 'data') [4] 2020-05-27 23:18:26 ( 6.00ms ) python3 ( 6.74s ) Data(train_size=834, test_size=166)","title":"Basic idea"},{"location":"tutorial/instance/#hierarchal-structure","text":"Next create a Dataset instance. The Dataset class requires a Data instance as the first argument so that the corresponding dictionary have hierarchal structure. doc = \"\"\" dataset: class: ivory.core.data.Dataset data: class: rectangle.data.Data n_splits: 5 mode: train fold: 0 \"\"\" create(doc, 'dataset') [5] 2020-05-27 23:18:26 ( 6.00ms ) python3 ( 6.74s ) Dataset(mode='train', num_samples=667) As you can see, Ivory can treat this hierarchal structure correctly. Furthermore, create a DataLoaders instance for PyTorch. doc = \"\"\" dataloaders: class: ivory.torch.data.DataLoaders data: class: rectangle.data.Data n_splits: 5 dataset: def: ivory.core.data.Dataset fold: 0 batch_size: 4 \"\"\" create(doc, 'dataloaders') [6] 2020-05-27 23:18:26 ( 6.00ms ) python3 ( 6.75s ) DataLoaders(data=Data(train_size=834, test_size=166), dataset=<class 'ivory.core.data.Dataset'>, fold=0, batch_size=4) Remember that the argument dataset for the DataLoaders class is not an instance but a callable that returns a Dataset instance. To describe this behavior, you can use a new def key instead of class . (See the previous section )","title":"Hierarchal Structure"},{"location":"tutorial/instance/#default-class","text":"In the above example, the two lines using a class of Ivory seems to be verbose a little bit. Ivory adds a default class if the class or def key is missing. Here is the list of default classes prepared by Ivory: from ivory.core.default import DEFAULT_CLASS for library, values in DEFAULT_CLASS.items(): print(f'library: {library}') for name, value in values.items(): print(\" \", name, \"---\", value) [7] 2020-05-27 23:18:26 ( 68.0ms ) python3 ( 6.82s ) library: core client --- ivory.core.client.Client tracker --- ivory.core.tracker.Tracker tuner --- ivory.core.tuner.Tuner experiment --- ivory.core.base.Experiment objective --- ivory.core.objective.Objective run --- ivory.core.run.Run task --- ivory.core.run.Task study --- ivory.core.run.Study dataset --- ivory.core.data.Dataset datasets --- ivory.core.data.Datasets dataloaders --- ivory.core.data.DataLoaders results --- ivory.callbacks.results.Results metrics --- ivory.callbacks.metrics.Metrics monitor --- ivory.callbacks.monitor.Monitor early_stopping --- ivory.callbacks.early_stopping.EarlyStopping library: torch run --- ivory.torch.run.Run dataloaders --- ivory.torch.data.DataLoaders dataset --- ivory.torch.data.Dataset results --- ivory.torch.results.Results metrics --- ivory.torch.metrics.Metrics trainer --- ivory.torch.trainer.Trainer library: tensorflow run --- ivory.tensorflow.run.Run trainer --- ivory.tensorflow.trainer.Trainer library: sklearn estimator --- ivory.sklearn.estimator.Estimator Therefore, we can omit the lines using default classes like below. Here, the library key is used to overload the default classes of the ivory.core package by the specific library. doc = \"\"\" library: torch dataloaders: data: class: rectangle.data.Data n_splits: 5 dataset: fold: 0 batch_size: 4 \"\"\" create(doc, 'dataloaders') [8] 2020-05-27 23:18:26 ( 6.00ms ) python3 ( 6.82s ) DataLoaders(data=Data(train_size=834, test_size=166), dataset=<class 'ivory.torch.data.Dataset'>, fold=0, batch_size=4)","title":"Default Class"},{"location":"tutorial/model/","text":"Model Structure Model We have prepared a DataLoaders instance for PyTorch. Now define a MLP model that works with the DataLoaders . The model is defined in rectangle/torch.py File 4 rectangle/torch.py import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self, hidden_sizes): super().__init__() layers = [] for in_features, out_features in zip([2] + hidden_sizes, hidden_sizes + [1]): layers.append(nn.Linear(in_features, out_features)) self.layers = nn.ModuleList(layers) def forward(self, x): for layer in self.layers[:-1]: x = F.relu(layer(x)) return self.layers[-1](x) We again use Ivory's instance creation system . import yaml # A helper function. def create(doc, name, **kwargs): params = yaml.safe_load(doc) return create_instance(params, name, **kwargs) doc = \"\"\" library: torch dataloaders: data: class: rectangle.data.Data n_splits: 5 dataset: fold: 0 batch_size: 4 model: class: rectangle.torch.Model hidden_sizes: [3, 4, 5] \"\"\" dataloaders = create(doc, 'dataloaders') model = create(doc, 'model') model [2] 2020-05-27 23:18:26 ( 10.0ms ) python3 ( 6.84s ) Model( (layers): ModuleList( (0): Linear(in_features=2, out_features=3, bias=True) (1): Linear(in_features=3, out_features=4, bias=True) (2): Linear(in_features=4, out_features=5, bias=True) (3): Linear(in_features=5, out_features=1, bias=True) ) ) We can uses this model as usual. index, input, target = next(iter(dataloaders.train)) input [3] 2020-05-27 23:18:26 ( 7.00ms ) python3 ( 6.85s ) tensor([[4.3387, 3.4454], [4.7279, 3.9121], [1.2816, 2.5626], [1.5204, 1.1074]]) model(input) [4] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.85s ) tensor([[0.1654], [0.1620], [0.1762], [0.1988]], grad_fn=<AddmmBackward>) Optimizer To train a model, we need an optimizer. For example import torch.optim optimizer = torch.optim.SGD(params=model.parameters(), lr=1e-3) optimizer [5] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.86s ) SGD ( Parameter Group 0 dampening: 0 lr: 0.001 momentum: 0 nesterov: False weight_decay: 0 ) Now try to describe this optimizer in a dictionary style. However, the argument params is not a simple literal but an iterable of learnable parameters. Ivory provides \" $ -notation \" to tackle this problem. doc = \"\"\" optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 0.001 \"\"\" optimizer = create(doc, 'optimizer', globals={'model': model}) optimizer [6] 2020-05-27 23:18:26 ( 5.00ms ) python3 ( 6.86s ) SGD ( Parameter Group 0 dampening: 0 lr: 0.001 momentum: 0 nesterov: False weight_decay: 0 ) A \" $ \" is a starting point to refer other instance stored in a globals dictionary. In this case, $.model is replaced by the model instance in globals , then .parameters() invokes a call of the model.parameters() method. Scheduler A Scheduler controls the learning rate of an optimizer. doc = \"\"\" scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 \"\"\" scheduler = create(doc, 'scheduler', globals={'optimizer': optimizer}) scheduler [7] 2020-05-27 23:18:26 ( 5.00ms ) python3 ( 6.87s ) <torch.optim.lr_scheduler.ReduceLROnPlateau at 0x1fa2075df88> If a $ -notation has no suffix, the value becomes its key itself. The following two example are equivalent: optimizer: $ optimizer: $.optimizer Now we have had both data and model.","title":"<span class=\"pheasant-header\"><span class=\"header\"><span class=\"title\">Model Structure</span></span></span>"},{"location":"tutorial/model/#model-structure","text":"","title":"Model Structure"},{"location":"tutorial/model/#model","text":"We have prepared a DataLoaders instance for PyTorch. Now define a MLP model that works with the DataLoaders . The model is defined in rectangle/torch.py File 4 rectangle/torch.py import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self, hidden_sizes): super().__init__() layers = [] for in_features, out_features in zip([2] + hidden_sizes, hidden_sizes + [1]): layers.append(nn.Linear(in_features, out_features)) self.layers = nn.ModuleList(layers) def forward(self, x): for layer in self.layers[:-1]: x = F.relu(layer(x)) return self.layers[-1](x) We again use Ivory's instance creation system . import yaml # A helper function. def create(doc, name, **kwargs): params = yaml.safe_load(doc) return create_instance(params, name, **kwargs) doc = \"\"\" library: torch dataloaders: data: class: rectangle.data.Data n_splits: 5 dataset: fold: 0 batch_size: 4 model: class: rectangle.torch.Model hidden_sizes: [3, 4, 5] \"\"\" dataloaders = create(doc, 'dataloaders') model = create(doc, 'model') model [2] 2020-05-27 23:18:26 ( 10.0ms ) python3 ( 6.84s ) Model( (layers): ModuleList( (0): Linear(in_features=2, out_features=3, bias=True) (1): Linear(in_features=3, out_features=4, bias=True) (2): Linear(in_features=4, out_features=5, bias=True) (3): Linear(in_features=5, out_features=1, bias=True) ) ) We can uses this model as usual. index, input, target = next(iter(dataloaders.train)) input [3] 2020-05-27 23:18:26 ( 7.00ms ) python3 ( 6.85s ) tensor([[4.3387, 3.4454], [4.7279, 3.9121], [1.2816, 2.5626], [1.5204, 1.1074]]) model(input) [4] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.85s ) tensor([[0.1654], [0.1620], [0.1762], [0.1988]], grad_fn=<AddmmBackward>)","title":"Model"},{"location":"tutorial/model/#optimizer","text":"To train a model, we need an optimizer. For example import torch.optim optimizer = torch.optim.SGD(params=model.parameters(), lr=1e-3) optimizer [5] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 6.86s ) SGD ( Parameter Group 0 dampening: 0 lr: 0.001 momentum: 0 nesterov: False weight_decay: 0 ) Now try to describe this optimizer in a dictionary style. However, the argument params is not a simple literal but an iterable of learnable parameters. Ivory provides \" $ -notation \" to tackle this problem. doc = \"\"\" optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 0.001 \"\"\" optimizer = create(doc, 'optimizer', globals={'model': model}) optimizer [6] 2020-05-27 23:18:26 ( 5.00ms ) python3 ( 6.86s ) SGD ( Parameter Group 0 dampening: 0 lr: 0.001 momentum: 0 nesterov: False weight_decay: 0 ) A \" $ \" is a starting point to refer other instance stored in a globals dictionary. In this case, $.model is replaced by the model instance in globals , then .parameters() invokes a call of the model.parameters() method.","title":"Optimizer"},{"location":"tutorial/model/#scheduler","text":"A Scheduler controls the learning rate of an optimizer. doc = \"\"\" scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 \"\"\" scheduler = create(doc, 'scheduler', globals={'optimizer': optimizer}) scheduler [7] 2020-05-27 23:18:26 ( 5.00ms ) python3 ( 6.87s ) <torch.optim.lr_scheduler.ReduceLROnPlateau at 0x1fa2075df88> If a $ -notation has no suffix, the value becomes its key itself. The following two example are equivalent: optimizer: $ optimizer: $.optimizer Now we have had both data and model.","title":"Scheduler"},{"location":"tutorial/task/","text":"Multiple Runs Task Ivory implements a special run type called Task which controls multiple nested runs. A task is useful for parameter search or cross validation. import ivory client = ivory.create_client(\"examples\") # Set the working directory task = client.create_task('torch') # Or, experiment.create_task() task [3] 2020-05-27 23:18:28 ( 46.0ms ) python3 ( 8.72s ) [I 200527 23:18:28 tracker:48] A new experiment created with name: 'torch' Task(id='8a47595d5c5d4c5e9be561f6ee0369ed', name='task#0', num_objects=3) The Task class has two methods to generate multiple runs: prodcut() and chain() . These two methods have the same functionality as itertools of Python starndard library. Product The Task.prodcut() makes an iterator that returns runs from cartesian product of input parameters. task = client.create_task('torch') # verbose=0: No progress bar. runs = task.product(fold=range(2), factor=[0.5, 0.7], verbose=0) runs [4] 2020-05-27 23:18:28 ( 43.0ms ) python3 ( 8.76s ) <generator object Task.product at 0x000001FA218745C8> for run in runs: pass # Do somthing, for example, run.start() [5] 2020-05-27 23:18:28 ( 417ms ) python3 ( 9.18s ) [run#0] fold=0 factor=0.5 [run#1] fold=0 factor=0.7 [run#2] fold=1 factor=0.5 [run#3] fold=1 factor=0.7 You can specify other parameters which don't change during iteration. task = client.create_task('torch') runs = task.product(fold=range(2), factor=[0.5, 0.7], lr=1e-4, verbose=0) for run in runs: pass # Do somthing, for example, run.start() [6] 2020-05-27 23:18:28 ( 515ms ) python3 ( 9.69s ) [run#4] lr=0.0001 fold=0 factor=0.5 [run#5] lr=0.0001 fold=0 factor=0.7 [run#6] lr=0.0001 fold=1 factor=0.5 [run#7] lr=0.0001 fold=1 factor=0.7 Chain The Task.chain() maks an iterator that returns runs from the first input paramter until it is exhausted, then proceeds to the next parameter, until all of the parameters are exhausted. Other parameters have default values if they don't be specified by additional key-value pairs. task = client.create_task('torch') runs = task.chain( fold=range(2), factor=[0.5, 0.7], lr=[1e-4, 1e-3], batch_size=32, use_best_param=False, verbose=0) runs [7] 2020-05-27 23:18:29 ( 72.0ms ) python3 ( 9.77s ) <generator object Task.chain at 0x000001FA218741C8> for run in runs: pass # Do somthing, for example, run.start() [8] 2020-05-27 23:18:29 ( 777ms ) python3 ( 10.5s ) [run#8] batch_size=32 fold=0 [run#9] batch_size=32 fold=1 [run#10] batch_size=32 factor=0.5 [run#11] batch_size=32 factor=0.7 [run#12] batch_size=32 lr=0.0001 [run#13] batch_size=32 lr=0.001 The use_best_param keyword argument is useful for dynamic updating of parameters. If True (default), the parameter which got the best score is used during the following iterations. task = client.create_task('torch') runs = task.chain( fold=range(2), factor=[0.5, 0.7], lr=[1e-4, 1e-3], use_best_param=True, verbose=0) for run in runs: pass # Do somthing, for example, run.start() # We do nothing, so the first values are used. [9] 2020-05-27 23:18:30 ( 951ms ) python3 ( 11.5s ) [run#14] fold=0 [run#15] fold=1 [run#16] factor=0.5 fold=0 [run#17] factor=0.7 fold=0 [run#18] lr=0.0001 fold=0 factor=0.5 [run#19] lr=0.001 fold=0 factor=0.5 Tracking If the Client instace has a Tracker instance, the multiple runs created by the tasks can be tracked. The client.search_parent_run_ids() method makes an iterator that returns RunIDs of runs that have nested runs. In this case, parent runs are some tasks we made above. # A helper function def print_run_info(run_ids): for run_id in run_ids: print(run_id[:5], client.get_run_name(run_id)) run_ids = client.search_parent_run_ids('torch') print_run_info(run_ids) [10] 2020-05-27 23:18:31 ( 84.0ms ) python3 ( 11.6s ) 2c3eb task#4 a00d2 task#3 0c7a3 task#2 087e8 task#1 Note task#0 that we made first hasn't yielded any runs yet, so that the task has not been a parent run. The client.get_run_ids() makes an iterator that returns RunIDs of runs you select by run names. run_ids = client.get_run_ids('torch', task=range(2,4)) print_run_info(run_ids) [11] 2020-05-27 23:18:31 ( 128ms ) python3 ( 11.7s ) 0c7a3 task#2 a00d2 task#3 The client.get_nested_run_ids() makes an iterator that returns RunIDs of runs that have a parent you select by run names. run_ids = client.get_nested_run_ids('torch', task=range(3, 5)) print_run_info(run_ids) [12] 2020-05-27 23:18:31 ( 280ms ) python3 ( 12.0s ) 6bfe3 run#13 b9e98 run#12 29f5f run#11 5efca run#10 6fa94 run#9 ca494 run#8 7e6be run#19 85ef4 run#18 f4e58 run#17 66d83 run#16 8b7be run#15 2ae7b run#14 On the other hand, the client.get_parent_run_id() returns a RunID of a run that is refered by a nested run. run_id = client.get_parent_run_id('torch', run=14) print_run_info([run_id]) [13] 2020-05-27 23:18:31 ( 65.0ms ) python3 ( 12.1s ) 2c3eb task#4 Range Ivory provides the ivory.utils.range.Range class for parameter setting. This class can be used as the standard range , but more flexible, expecially for float type. from ivory.utils.range import Range # Normal usage list(Range(3, 6)) # The stop value is included. [14] 2020-05-27 23:18:31 ( 5.00ms ) python3 ( 12.1s ) [3, 4, 5, 6] list(Range(3, 10, 2)) # Step size. [15] 2020-05-27 23:18:31 ( 3.00ms ) python3 ( 12.1s ) [3, 5, 7, 9] list(Range(3, 10, num=4)) # Sampling size. [16] 2020-05-27 23:18:31 ( 3.00ms ) python3 ( 12.1s ) [3, 5, 8, 10] list(Range(0.0, 1.0, 0.25)) # float type. [17] 2020-05-27 23:18:31 ( 5.00ms ) python3 ( 12.1s ) [0.0, 0.25, 0.5, 0.75, 1.0] list(Range(0.0, 1.0, num=5)) # Sampling size [18] 2020-05-27 23:18:31 ( 5.00ms ) python3 ( 12.1s ) [0.0, 0.25, 0.5, 0.75, 1.0] list(Range(1e-3, 1e2, num=6, log=True)) # Log scale [19] 2020-05-27 23:18:31 ( 4.00ms ) python3 ( 12.1s ) [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]","title":"<span class=\"pheasant-header\"><span class=\"header\"><span class=\"title\">Multiple Runs</span></span></span>"},{"location":"tutorial/task/#multiple-runs","text":"","title":"Multiple Runs"},{"location":"tutorial/task/#task","text":"Ivory implements a special run type called Task which controls multiple nested runs. A task is useful for parameter search or cross validation. import ivory client = ivory.create_client(\"examples\") # Set the working directory task = client.create_task('torch') # Or, experiment.create_task() task [3] 2020-05-27 23:18:28 ( 46.0ms ) python3 ( 8.72s ) [I 200527 23:18:28 tracker:48] A new experiment created with name: 'torch' Task(id='8a47595d5c5d4c5e9be561f6ee0369ed', name='task#0', num_objects=3) The Task class has two methods to generate multiple runs: prodcut() and chain() . These two methods have the same functionality as itertools of Python starndard library.","title":"Task"},{"location":"tutorial/task/#product","text":"The Task.prodcut() makes an iterator that returns runs from cartesian product of input parameters. task = client.create_task('torch') # verbose=0: No progress bar. runs = task.product(fold=range(2), factor=[0.5, 0.7], verbose=0) runs [4] 2020-05-27 23:18:28 ( 43.0ms ) python3 ( 8.76s ) <generator object Task.product at 0x000001FA218745C8> for run in runs: pass # Do somthing, for example, run.start() [5] 2020-05-27 23:18:28 ( 417ms ) python3 ( 9.18s ) [run#0] fold=0 factor=0.5 [run#1] fold=0 factor=0.7 [run#2] fold=1 factor=0.5 [run#3] fold=1 factor=0.7 You can specify other parameters which don't change during iteration. task = client.create_task('torch') runs = task.product(fold=range(2), factor=[0.5, 0.7], lr=1e-4, verbose=0) for run in runs: pass # Do somthing, for example, run.start() [6] 2020-05-27 23:18:28 ( 515ms ) python3 ( 9.69s ) [run#4] lr=0.0001 fold=0 factor=0.5 [run#5] lr=0.0001 fold=0 factor=0.7 [run#6] lr=0.0001 fold=1 factor=0.5 [run#7] lr=0.0001 fold=1 factor=0.7","title":"Product"},{"location":"tutorial/task/#chain","text":"The Task.chain() maks an iterator that returns runs from the first input paramter until it is exhausted, then proceeds to the next parameter, until all of the parameters are exhausted. Other parameters have default values if they don't be specified by additional key-value pairs. task = client.create_task('torch') runs = task.chain( fold=range(2), factor=[0.5, 0.7], lr=[1e-4, 1e-3], batch_size=32, use_best_param=False, verbose=0) runs [7] 2020-05-27 23:18:29 ( 72.0ms ) python3 ( 9.77s ) <generator object Task.chain at 0x000001FA218741C8> for run in runs: pass # Do somthing, for example, run.start() [8] 2020-05-27 23:18:29 ( 777ms ) python3 ( 10.5s ) [run#8] batch_size=32 fold=0 [run#9] batch_size=32 fold=1 [run#10] batch_size=32 factor=0.5 [run#11] batch_size=32 factor=0.7 [run#12] batch_size=32 lr=0.0001 [run#13] batch_size=32 lr=0.001 The use_best_param keyword argument is useful for dynamic updating of parameters. If True (default), the parameter which got the best score is used during the following iterations. task = client.create_task('torch') runs = task.chain( fold=range(2), factor=[0.5, 0.7], lr=[1e-4, 1e-3], use_best_param=True, verbose=0) for run in runs: pass # Do somthing, for example, run.start() # We do nothing, so the first values are used. [9] 2020-05-27 23:18:30 ( 951ms ) python3 ( 11.5s ) [run#14] fold=0 [run#15] fold=1 [run#16] factor=0.5 fold=0 [run#17] factor=0.7 fold=0 [run#18] lr=0.0001 fold=0 factor=0.5 [run#19] lr=0.001 fold=0 factor=0.5","title":"Chain"},{"location":"tutorial/task/#tracking","text":"If the Client instace has a Tracker instance, the multiple runs created by the tasks can be tracked. The client.search_parent_run_ids() method makes an iterator that returns RunIDs of runs that have nested runs. In this case, parent runs are some tasks we made above. # A helper function def print_run_info(run_ids): for run_id in run_ids: print(run_id[:5], client.get_run_name(run_id)) run_ids = client.search_parent_run_ids('torch') print_run_info(run_ids) [10] 2020-05-27 23:18:31 ( 84.0ms ) python3 ( 11.6s ) 2c3eb task#4 a00d2 task#3 0c7a3 task#2 087e8 task#1 Note task#0 that we made first hasn't yielded any runs yet, so that the task has not been a parent run. The client.get_run_ids() makes an iterator that returns RunIDs of runs you select by run names. run_ids = client.get_run_ids('torch', task=range(2,4)) print_run_info(run_ids) [11] 2020-05-27 23:18:31 ( 128ms ) python3 ( 11.7s ) 0c7a3 task#2 a00d2 task#3 The client.get_nested_run_ids() makes an iterator that returns RunIDs of runs that have a parent you select by run names. run_ids = client.get_nested_run_ids('torch', task=range(3, 5)) print_run_info(run_ids) [12] 2020-05-27 23:18:31 ( 280ms ) python3 ( 12.0s ) 6bfe3 run#13 b9e98 run#12 29f5f run#11 5efca run#10 6fa94 run#9 ca494 run#8 7e6be run#19 85ef4 run#18 f4e58 run#17 66d83 run#16 8b7be run#15 2ae7b run#14 On the other hand, the client.get_parent_run_id() returns a RunID of a run that is refered by a nested run. run_id = client.get_parent_run_id('torch', run=14) print_run_info([run_id]) [13] 2020-05-27 23:18:31 ( 65.0ms ) python3 ( 12.1s ) 2c3eb task#4","title":"Tracking"},{"location":"tutorial/task/#range","text":"Ivory provides the ivory.utils.range.Range class for parameter setting. This class can be used as the standard range , but more flexible, expecially for float type. from ivory.utils.range import Range # Normal usage list(Range(3, 6)) # The stop value is included. [14] 2020-05-27 23:18:31 ( 5.00ms ) python3 ( 12.1s ) [3, 4, 5, 6] list(Range(3, 10, 2)) # Step size. [15] 2020-05-27 23:18:31 ( 3.00ms ) python3 ( 12.1s ) [3, 5, 7, 9] list(Range(3, 10, num=4)) # Sampling size. [16] 2020-05-27 23:18:31 ( 3.00ms ) python3 ( 12.1s ) [3, 5, 8, 10] list(Range(0.0, 1.0, 0.25)) # float type. [17] 2020-05-27 23:18:31 ( 5.00ms ) python3 ( 12.1s ) [0.0, 0.25, 0.5, 0.75, 1.0] list(Range(0.0, 1.0, num=5)) # Sampling size [18] 2020-05-27 23:18:31 ( 5.00ms ) python3 ( 12.1s ) [0.0, 0.25, 0.5, 0.75, 1.0] list(Range(1e-3, 1e2, num=6, log=True)) # Log scale [19] 2020-05-27 23:18:31 ( 4.00ms ) python3 ( 12.1s ) [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]","title":"Range"},{"location":"tutorial/trainer/","text":"Training a Model Example Preparation First, create data and model set. For more details about the following code, see Creating Instance section . import yaml params = yaml.safe_load(\"\"\" library: torch run: dataloaders: data: class: rectangle.data.Data n_splits: 4 dataset: batch_size: 10 fold: 0 model: class: rectangle.torch.Model hidden_sizes: [100, 100] optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 0.001 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: metrics: criterion: def: torch.nn.functional.mse_loss monitor: metric: val_loss early_stopping: patience: 10 trainer: epochs: 10 verbose: 2 \"\"\") params [2] 2020-05-27 23:18:26 ( 8.00ms ) python3 ( 6.98s ) {'library': 'torch', 'run': {'dataloaders': {'data': {'class': 'rectangle.data.Data', 'n_splits': 4}, 'dataset': None, 'batch_size': 10, 'fold': 0}, 'model': {'class': 'rectangle.torch.Model', 'hidden_sizes': [100, 100]}, 'optimizer': {'class': 'torch.optim.SGD', 'params': '$.model.parameters()', 'lr': 0.001}, 'scheduler': {'class': 'torch.optim.lr_scheduler.ReduceLROnPlateau', 'optimizer': '$', 'factor': 0.5, 'patience': 4}, 'results': None, 'metrics': {'criterion': {'def': 'torch.nn.functional.mse_loss'}}, 'monitor': {'metric': 'val_loss'}, 'early_stopping': {'patience': 10}, 'trainer': {'epochs': 10, 'verbose': 2}}} Note Key-order in the params dictionary is meaningful, because the callback functions are called by this order. For example, Monitor uses the results of Metrics so that Monitor should appear later than Metrics . The ivory.core.instance.create_base_instance() function is more useful to create a run from a dictionary than the ivory.core.instance.create_instance() function because it can create multiple objects by one step. import ivory.core.instance run = ivory.core.instance.create_base_instance(params, 'run') list(run) [3] 2020-05-27 23:18:26 ( 8.00ms ) python3 ( 6.99s ) ['dataloaders', 'model', 'optimizer', 'scheduler', 'results', 'metrics', 'monitor', 'early_stopping', 'trainer'] Callbacks Check callbacks of the Run instance. import ivory.core.base # A helper function def print_callbacks(obj): for func in ivory.core.base.Callback.METHODS: if hasattr(obj, func) and callable(getattr(obj, func)): print(' ', func) for name, obj in run.items(): print(f'[{name}]') print_callbacks(obj) [4] 2020-05-27 23:18:26 ( 36.0ms ) python3 ( 7.03s ) [dataloaders] [model] [optimizer] [scheduler] [results] on_train_begin on_train_end on_val_end on_test_begin on_test_end [metrics] on_epoch_begin on_train_begin on_train_end on_val_begin on_val_end on_epoch_end [monitor] on_epoch_end [early_stopping] on_epoch_end [trainer] on_fit_begin on_train_begin on_val_begin on_epoch_end on_test_begin Metrics The role of Metrics class is to record a set of metric for evaluation of model performance. The metirics are updated at each epoch end. run.metrics # Now, metrics are empty. [5] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 7.03s ) Metrics() The Metrics class for PyTorch has a criterion callable object to calculate loss. run.metrics.criterion [6] 2020-05-27 23:18:26 ( 3.00ms ) python3 ( 7.04s ) <function torch.nn.functional.mse_loss(input, target, size_average=None, reduce=None, reduction='mean')> Monitor The Monitor class is monitoring the most important metric to measure the model score or to determine the training logic (early stopping or pruning). run.monitor # Monitoring `val_loss`. Lower is better. [7] 2020-05-27 23:18:26 ( 3.00ms ) python3 ( 7.04s ) Monitor(metric='val_loss', mode='min') EarlyStopping The EarlyStopping class is to stop the training loop when a monitored metric has stopped improving. run.early_stopping # Early stopping occurs when `wait` > `patience`. [8] 2020-05-27 23:18:26 ( 3.00ms ) python3 ( 7.04s ) EarlyStopping(patience=10, wait=0) Trainer The Tainer class controls the model training. This is a callback, but at the same time, invokes callback functions at each step of training, validation, and test loop. run.trainer # Training hasn't started yet, so epoch = -1. [9] 2020-05-27 23:18:26 ( 3.00ms ) python3 ( 7.04s ) Trainer(epoch=-1, epochs=10, global_step=-1, verbose=2, gpu=False, precision=32, amp_level='O1', scheduler_step_mode='epoch') Using a Trainer A Run instance invokes its trainer by Run.start() method. run.start() # create_callbacks() is called automatically. [10] 2020-05-27 23:18:26 ( 568ms ) python3 ( 7.61s ) [epoch#0] loss=14.33 val_loss=7.678 lr=0.001 best [epoch#1] loss=6.471 val_loss=4.784 lr=0.001 best [epoch#2] loss=4.622 val_loss=3.529 lr=0.001 best [epoch#3] loss=3.138 val_loss=1.925 lr=0.001 best [epoch#4] loss=1.918 val_loss=1.231 lr=0.001 best [epoch#5] loss=1.114 val_loss=0.7421 lr=0.001 best [epoch#6] loss=0.8192 val_loss=0.5551 lr=0.001 best [epoch#7] loss=0.66 val_loss=0.5371 lr=0.001 best [epoch#8] loss=0.5739 val_loss=0.9463 lr=0.001 [epoch#9] loss=0.5761 val_loss=0.4626 lr=0.001 best You can update attributes of run's objects at any time. run.trainer.epochs = 5 run.start() [11] 2020-05-27 23:18:27 ( 271ms ) python3 ( 7.88s ) [epoch#10] loss=0.4669 val_loss=0.4525 lr=0.001 best [epoch#11] loss=0.5089 val_loss=0.4185 lr=0.001 best [epoch#12] loss=0.4345 val_loss=0.5825 lr=0.001 [epoch#13] loss=0.4439 val_loss=0.5079 lr=0.001 [epoch#14] loss=0.4541 val_loss=0.5108 lr=0.001 Note The Run.start() method doesn't reset the trainer's epoch. Callbacks after Training After training, the callbacks changes their states. run.metrics # Show metrics at current epoch. [12] 2020-05-27 23:18:27 ( 4.00ms ) python3 ( 7.89s ) Metrics(loss=0.4541, val_loss=0.5108, lr=0.001) run.metrics.history.val_loss # Totally, trained for 15 epochs. [13] 2020-05-27 23:18:27 ( 4.00ms ) python3 ( 7.89s ) {0: 7.677663850784302, 1: 4.784095406532288, 2: 3.528976446390152, 3: 1.9249225169420243, 4: 1.2307796716690063, 5: 0.742050689458847, 6: 0.555112437158823, 7: 0.5370654486119747, 8: 0.9462536528706551, 9: 0.46260746344923975, 10: 0.45252719335258007, 11: 0.4185343522578478, 12: 0.5824831679463387, 13: 0.5078927498310805, 14: 0.510826489329338} run.monitor # Store the best score and its epoch. [14] 2020-05-27 23:18:27 ( 4.00ms ) python3 ( 7.90s ) Monitor(metric='val_loss', mode='min', best_score=0.419, best_epoch=11) run.early_stopping # Current `wait`. [15] 2020-05-27 23:18:27 ( 4.00ms ) python3 ( 7.90s ) EarlyStopping(patience=10, wait=3) run.trainer # Current epoch is 14 (0-indexed). [16] 2020-05-27 23:18:27 ( 4.00ms ) python3 ( 7.90s ) Trainer(epoch=14, epochs=5, global_step=899, verbose=2, gpu=False, precision=32, amp_level='O1', scheduler_step_mode='epoch')","title":"<span class=\"pheasant-header\"><span class=\"header\"><span class=\"title\">Training a Model</span></span></span>"},{"location":"tutorial/trainer/#training-a-model","text":"","title":"Training a Model"},{"location":"tutorial/trainer/#example-preparation","text":"First, create data and model set. For more details about the following code, see Creating Instance section . import yaml params = yaml.safe_load(\"\"\" library: torch run: dataloaders: data: class: rectangle.data.Data n_splits: 4 dataset: batch_size: 10 fold: 0 model: class: rectangle.torch.Model hidden_sizes: [100, 100] optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 0.001 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: metrics: criterion: def: torch.nn.functional.mse_loss monitor: metric: val_loss early_stopping: patience: 10 trainer: epochs: 10 verbose: 2 \"\"\") params [2] 2020-05-27 23:18:26 ( 8.00ms ) python3 ( 6.98s ) {'library': 'torch', 'run': {'dataloaders': {'data': {'class': 'rectangle.data.Data', 'n_splits': 4}, 'dataset': None, 'batch_size': 10, 'fold': 0}, 'model': {'class': 'rectangle.torch.Model', 'hidden_sizes': [100, 100]}, 'optimizer': {'class': 'torch.optim.SGD', 'params': '$.model.parameters()', 'lr': 0.001}, 'scheduler': {'class': 'torch.optim.lr_scheduler.ReduceLROnPlateau', 'optimizer': '$', 'factor': 0.5, 'patience': 4}, 'results': None, 'metrics': {'criterion': {'def': 'torch.nn.functional.mse_loss'}}, 'monitor': {'metric': 'val_loss'}, 'early_stopping': {'patience': 10}, 'trainer': {'epochs': 10, 'verbose': 2}}} Note Key-order in the params dictionary is meaningful, because the callback functions are called by this order. For example, Monitor uses the results of Metrics so that Monitor should appear later than Metrics . The ivory.core.instance.create_base_instance() function is more useful to create a run from a dictionary than the ivory.core.instance.create_instance() function because it can create multiple objects by one step. import ivory.core.instance run = ivory.core.instance.create_base_instance(params, 'run') list(run) [3] 2020-05-27 23:18:26 ( 8.00ms ) python3 ( 6.99s ) ['dataloaders', 'model', 'optimizer', 'scheduler', 'results', 'metrics', 'monitor', 'early_stopping', 'trainer']","title":"Example Preparation"},{"location":"tutorial/trainer/#callbacks","text":"Check callbacks of the Run instance. import ivory.core.base # A helper function def print_callbacks(obj): for func in ivory.core.base.Callback.METHODS: if hasattr(obj, func) and callable(getattr(obj, func)): print(' ', func) for name, obj in run.items(): print(f'[{name}]') print_callbacks(obj) [4] 2020-05-27 23:18:26 ( 36.0ms ) python3 ( 7.03s ) [dataloaders] [model] [optimizer] [scheduler] [results] on_train_begin on_train_end on_val_end on_test_begin on_test_end [metrics] on_epoch_begin on_train_begin on_train_end on_val_begin on_val_end on_epoch_end [monitor] on_epoch_end [early_stopping] on_epoch_end [trainer] on_fit_begin on_train_begin on_val_begin on_epoch_end on_test_begin","title":"Callbacks"},{"location":"tutorial/trainer/#metrics","text":"The role of Metrics class is to record a set of metric for evaluation of model performance. The metirics are updated at each epoch end. run.metrics # Now, metrics are empty. [5] 2020-05-27 23:18:26 ( 4.00ms ) python3 ( 7.03s ) Metrics() The Metrics class for PyTorch has a criterion callable object to calculate loss. run.metrics.criterion [6] 2020-05-27 23:18:26 ( 3.00ms ) python3 ( 7.04s ) <function torch.nn.functional.mse_loss(input, target, size_average=None, reduce=None, reduction='mean')>","title":"Metrics"},{"location":"tutorial/trainer/#monitor","text":"The Monitor class is monitoring the most important metric to measure the model score or to determine the training logic (early stopping or pruning). run.monitor # Monitoring `val_loss`. Lower is better. [7] 2020-05-27 23:18:26 ( 3.00ms ) python3 ( 7.04s ) Monitor(metric='val_loss', mode='min')","title":"Monitor"},{"location":"tutorial/trainer/#earlystopping","text":"The EarlyStopping class is to stop the training loop when a monitored metric has stopped improving. run.early_stopping # Early stopping occurs when `wait` > `patience`. [8] 2020-05-27 23:18:26 ( 3.00ms ) python3 ( 7.04s ) EarlyStopping(patience=10, wait=0)","title":"EarlyStopping"},{"location":"tutorial/trainer/#trainer","text":"The Tainer class controls the model training. This is a callback, but at the same time, invokes callback functions at each step of training, validation, and test loop. run.trainer # Training hasn't started yet, so epoch = -1. [9] 2020-05-27 23:18:26 ( 3.00ms ) python3 ( 7.04s ) Trainer(epoch=-1, epochs=10, global_step=-1, verbose=2, gpu=False, precision=32, amp_level='O1', scheduler_step_mode='epoch')","title":"Trainer"},{"location":"tutorial/trainer/#using-a-trainer","text":"A Run instance invokes its trainer by Run.start() method. run.start() # create_callbacks() is called automatically. [10] 2020-05-27 23:18:26 ( 568ms ) python3 ( 7.61s ) [epoch#0] loss=14.33 val_loss=7.678 lr=0.001 best [epoch#1] loss=6.471 val_loss=4.784 lr=0.001 best [epoch#2] loss=4.622 val_loss=3.529 lr=0.001 best [epoch#3] loss=3.138 val_loss=1.925 lr=0.001 best [epoch#4] loss=1.918 val_loss=1.231 lr=0.001 best [epoch#5] loss=1.114 val_loss=0.7421 lr=0.001 best [epoch#6] loss=0.8192 val_loss=0.5551 lr=0.001 best [epoch#7] loss=0.66 val_loss=0.5371 lr=0.001 best [epoch#8] loss=0.5739 val_loss=0.9463 lr=0.001 [epoch#9] loss=0.5761 val_loss=0.4626 lr=0.001 best You can update attributes of run's objects at any time. run.trainer.epochs = 5 run.start() [11] 2020-05-27 23:18:27 ( 271ms ) python3 ( 7.88s ) [epoch#10] loss=0.4669 val_loss=0.4525 lr=0.001 best [epoch#11] loss=0.5089 val_loss=0.4185 lr=0.001 best [epoch#12] loss=0.4345 val_loss=0.5825 lr=0.001 [epoch#13] loss=0.4439 val_loss=0.5079 lr=0.001 [epoch#14] loss=0.4541 val_loss=0.5108 lr=0.001 Note The Run.start() method doesn't reset the trainer's epoch.","title":"Using a Trainer"},{"location":"tutorial/trainer/#callbacks-after-training","text":"After training, the callbacks changes their states. run.metrics # Show metrics at current epoch. [12] 2020-05-27 23:18:27 ( 4.00ms ) python3 ( 7.89s ) Metrics(loss=0.4541, val_loss=0.5108, lr=0.001) run.metrics.history.val_loss # Totally, trained for 15 epochs. [13] 2020-05-27 23:18:27 ( 4.00ms ) python3 ( 7.89s ) {0: 7.677663850784302, 1: 4.784095406532288, 2: 3.528976446390152, 3: 1.9249225169420243, 4: 1.2307796716690063, 5: 0.742050689458847, 6: 0.555112437158823, 7: 0.5370654486119747, 8: 0.9462536528706551, 9: 0.46260746344923975, 10: 0.45252719335258007, 11: 0.4185343522578478, 12: 0.5824831679463387, 13: 0.5078927498310805, 14: 0.510826489329338} run.monitor # Store the best score and its epoch. [14] 2020-05-27 23:18:27 ( 4.00ms ) python3 ( 7.90s ) Monitor(metric='val_loss', mode='min', best_score=0.419, best_epoch=11) run.early_stopping # Current `wait`. [15] 2020-05-27 23:18:27 ( 4.00ms ) python3 ( 7.90s ) EarlyStopping(patience=10, wait=3) run.trainer # Current epoch is 14 (0-indexed). [16] 2020-05-27 23:18:27 ( 4.00ms ) python3 ( 7.90s ) Trainer(epoch=14, epochs=5, global_step=899, verbose=2, gpu=False, precision=32, amp_level='O1', scheduler_step_mode='epoch')","title":"Callbacks after Training"},{"location":"tutorial/tuning/","text":"Hyperparameter Tuning Suggest Function To optimize a set of hyperparameters, define a suggest function . Here are example functions. File 7 rectangle/suggest.py def suggest_lr(trial, min, max): trial.suggest_loguniform(\"lr\", min, max) def suggest_hidden_sizes(trial, max_num_layers, min_size=10, max_size=30): num_layers = trial.suggest_int(\"num_layers\", 2, max_num_layers) for k in range(num_layers): trial.suggest_int(f\"hidden_sizes:{k}\", min_size, max_size) A suggest function must take a trial as the first argument but you can add arbitrary arguments if you need. See also the Optuna offical documentation for more details. Note In the suggest_hidden_sizes() function, we use 0-indexed colon-notation , because Optuna doesn't suggest a list itself but its element. These suggest functions don't return any parameters. The only work of suggest functions is to make the Trial instance suggest parameters. Suggested parameters are stored in the Trial instance, so that nothing is needed from suggest functions. Note that the objective function in Optuna has only one trial argument, so that we have to use the functools.partial() function that returns a pure suggest function. from functools import partial from rectangle.suggest import suggest_lr, suggest_hidden_sizes lr = partial(suggest_lr, min=1e-5, max=1e-2) hidden_sizes = partial(suggest_hidden_sizes, max_num_layers=3) [2] 2020-05-27 23:18:31 ( 3.00ms ) python3 ( 12.1s ) Study Ivory implements a special run type called Study which controls hyperparameter tuning using Optuna . The Study class is a subclass of the Task class so that the same tracking system can be used. import ivory client = ivory.create_client(\"examples\") # Set the working directory study_lr = client.create_study('torch', lr=lr) study_hs = client.create_study('torch', hidden_sizes=hidden_sizes) study_lr [3] 2020-05-27 23:18:31 ( 83.0ms ) python3 ( 12.2s ) [I 200527 23:18:31 tracker:48] A new experiment created with name: 'torch' Study(id='130ec196c34f44cbb0478e19ac95e053', name='study#0', num_objects=5) Objective The ivory.core.objective.Objective class provides objective functions that return a score to minimize or maximize. But you don't need to know about the Objective class in details. Ivory builds an objective function from a suggest function and provides it to Optuna so that Optuna can optimize the parameters. A Study instance has an Objective instance. study_lr.objective [4] 2020-05-27 23:18:31 ( 4.00ms ) python3 ( 12.2s ) Objective(suggests=['lr']) study_hs.objective [5] 2020-05-27 23:18:31 ( 5.00ms ) python3 ( 12.2s ) Objective(suggests=['hidden_sizes']) Optimization Then \"optimize\" the learning rate and hidden sizes just for fun. optuna_study_lr = study_lr.optimize(n_trials=3, fold=3, epochs=3) [6] 2020-05-27 23:18:31 ( 1.90s ) python3 ( 14.1s ) [I 2020-05-27 23:18:32,007] A new study created with name: torch.lr.study#0 [run#0] lr=0.005467 fold=3 epochs=3 [epoch#0] loss=35.15 val_loss=6.169 lr=0.005467 best [epoch#1] loss=25.38 val_loss=12.47 lr=0.005467 [epoch#2] loss=8.913 val_loss=8.321 lr=0.005467 [I 2020-05-27 23:18:32,605] Finished trial#0 with value: 6.1692323088645935 with parameters: {'lr': 0.00546700761536697}. Best is trial#0 with value: 6.1692323088645935. [run#1] lr=2.048e-05 fold=3 epochs=3 [epoch#0] loss=99.59 val_loss=89.16 lr=2.048e-05 best [epoch#1] loss=73.5 val_loss=63.15 lr=2.048e-05 best [epoch#2] loss=48.44 val_loss=39.14 lr=2.048e-05 best [I 2020-05-27 23:18:33,260] Finished trial#1 with value: 39.13609299659729 with parameters: {'lr': 2.047791487362893e-05}. Best is trial#0 with value: 6.1692323088645935. [run#2] lr=1.934e-05 fold=3 epochs=3 [epoch#0] loss=105.7 val_loss=97.99 lr=1.934e-05 best [epoch#1] loss=85.05 val_loss=77.67 lr=1.934e-05 best [epoch#2] loss=64.52 val_loss=56.65 lr=1.934e-05 best [I 2020-05-27 23:18:33,861] Finished trial#2 with value: 56.652531433105466 with parameters: {'lr': 1.934042439130678e-05}. Best is trial#0 with value: 6.1692323088645935. optuna_study_hs = study_hs.optimize(n_trials=3, epochs=3) [7] 2020-05-27 23:18:33 ( 1.95s ) python3 ( 16.1s ) [I 2020-05-27 23:18:33,894] A new study created with name: torch.hidden_sizes.study#1 [run#3] hidden_sizes:0=10 hidden_sizes:1=12 hidden_sizes:2=18 num_layers=3 epochs=3 [epoch#0] loss=43.89 val_loss=8.516 lr=0.001 best [epoch#1] loss=9.464 val_loss=8.018 lr=0.001 best [epoch#2] loss=8.187 val_loss=6.489 lr=0.001 best [I 2020-05-27 23:18:34,537] Finished trial#0 with value: 6.489188611507416 with parameters: {'hidden_sizes:0': 10, 'hidden_sizes:1': 12, 'hidden_sizes:2': 18, 'num_layers': 3}. Best is trial#0 with value: 6.489188611507416. [run#4] hidden_sizes:0=18 hidden_sizes:1=20 hidden_sizes:2=13 num_layers=3 epochs=3 [epoch#0] loss=41.8 val_loss=8.217 lr=0.001 best [epoch#1] loss=8.612 val_loss=6.373 lr=0.001 best [epoch#2] loss=6.862 val_loss=4.805 lr=0.001 best [I 2020-05-27 23:18:35,168] Finished trial#1 with value: 4.804597091674805 with parameters: {'hidden_sizes:0': 18, 'hidden_sizes:1': 20, 'hidden_sizes:2': 13, 'num_layers': 3}. Best is trial#1 with value: 4.804597091674805. [run#5] hidden_sizes:0=22 hidden_sizes:1=15 hidden_sizes:2=22 num_layers=3 epochs=3 [epoch#0] loss=27.76 val_loss=8.74 lr=0.001 best [epoch#1] loss=8.866 val_loss=6.881 lr=0.001 best [epoch#2] loss=7.158 val_loss=5.326 lr=0.001 best [I 2020-05-27 23:18:35,814] Finished trial#2 with value: 5.32561604976654 with parameters: {'hidden_sizes:0': 22, 'hidden_sizes:1': 15, 'hidden_sizes:2': 22, 'num_layers': 3}. Best is trial#1 with value: 4.804597091674805. Note By cliking an icon ( ) in the above cells, you can see the Optuna's log. The returned value of the study.optimize() is an Optuna's Study instance (not Ivory's one). optuna_study_lr [8] 2020-05-27 23:18:35 ( 3.00ms ) python3 ( 16.1s ) <optuna.study.Study at 0x1fa195e4c48> The Study instance is named after the experiment name, suggest name, and run name. optuna_study_lr.study_name [9] 2020-05-27 23:18:35 ( 4.00ms ) python3 ( 16.1s ) 'torch.lr.study#0' In user attributes that Optuna's Study and Trial instances provide, RunID is saved. optuna_study_lr.user_attrs [10] 2020-05-27 23:18:35 ( 6.00ms ) python3 ( 16.1s ) {'run_id': '130ec196c34f44cbb0478e19ac95e053'} optuna_study_lr.trials[0].user_attrs [11] 2020-05-27 23:18:35 ( 6.00ms ) python3 ( 16.1s ) {'run_id': '700633cfbdca43caa4888cfd0f7529ab'} On the other hand, MLFlow Tracking's run (not Ivory's one) has a tag to refer Optuna's study and trial. mlflow_client = client.tracker.client mlflow_client [12] 2020-05-27 23:18:35 ( 5.00ms ) python3 ( 16.1s ) <mlflow.tracking.client.MlflowClient at 0x1fa206f1408> run_id = optuna_study_lr.user_attrs['run_id'] run = mlflow_client.get_run(run_id) run.data.tags['study_name'] [13] 2020-05-27 23:18:35 ( 8.00ms ) python3 ( 16.1s ) 'torch.lr.study#0' run_id = optuna_study_lr.trials[0].user_attrs['run_id'] run = mlflow_client.get_run(run_id) run.data.tags['trial_number'] [14] 2020-05-27 23:18:35 ( 10.0ms ) python3 ( 16.1s ) '0' You may have a question. How does Optuna optimize the parameters without any score? The answer is the Monitor instance. An Objective instance gets the monitoring score from run.monitor and sends it to Optuna so that Optuna can determine the next suggestion. All you need is to make your Run instance have a Monitor instance. Check the YAML parameter file: File 8 torch.yml library: torch dataloaders: data: class: rectangle.data.Data n_splits: 4 dataset: batch_size: 10 fold: 0 model: class: rectangle.torch.Model hidden_sizes: [100, 100] optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 1e-3 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: metrics: criterion: def: torch.nn.functional.mse_loss monitor: metric: val_loss early_stopping: patience: 10 trainer: epochs: 10 verbose: 2 The Monitor instance monitors val_loss and the default mode is min (smaller is better). If your monitor is accuracy, for example, set the monitor like this: monitor: metric: accuracy mode: max Parametric Optimization Again read the suggest functions. File 9 rectangle/suggest.py def suggest_lr(trial, min, max): trial.suggest_loguniform(\"lr\", min, max) def suggest_hidden_sizes(trial, max_num_layers, min_size=10, max_size=30): num_layers = trial.suggest_int(\"num_layers\", 2, max_num_layers) for k in range(num_layers): trial.suggest_int(f\"hidden_sizes:{k}\", min_size, max_size) The suggest_hidden_sizes() function has some logic but the suggest_lr() function is too simple to define a function. You may not want to write such a function. Ivory can do that for you. You can pass iterable(s) to the client.create_study() function instead of a callable study = client.create_study('torch', lr=(1e-3, 1e-2)) # `tuple` for range _ = study.optimize(n_trials=5, epochs=1, verbose=0) [15] 2020-05-27 23:18:35 ( 1.95s ) python3 ( 18.1s ) [I 2020-05-27 23:18:35,965] A new study created with name: torch.lr.study#2 [run#6] lr=0.004916 epochs=1 [I 2020-05-27 23:18:36,334] Finished trial#0 with value: 8.1303279876709 with parameters: {'lr': 0.004916395615500159}. Best is trial#0 with value: 8.1303279876709. [run#7] lr=0.00945 epochs=1 [I 2020-05-27 23:18:36,702] Finished trial#1 with value: 53.275264739990234 with parameters: {'lr': 0.009450143323053647}. Best is trial#0 with value: 8.1303279876709. [run#8] lr=0.00302 epochs=1 [I 2020-05-27 23:18:37,071] Finished trial#2 with value: 6.67906551361084 with parameters: {'lr': 0.0030202464293425063}. Best is trial#2 with value: 6.67906551361084. [run#9] lr=0.0036 epochs=1 [I 2020-05-27 23:18:37,444] Finished trial#3 with value: 8.580164682865142 with parameters: {'lr': 0.0036000147052569474}. Best is trial#2 with value: 6.67906551361084. [run#10] lr=0.006506 epochs=1 [I 2020-05-27 23:18:37,819] Finished trial#4 with value: 14.026474809646606 with parameters: {'lr': 0.006506403843828701}. Best is trial#2 with value: 6.67906551361084. from ivory.utils.range import Range # `Range` for log scale. study = client.create_study('torch', lr=Range(1e-3, 1e-2, log=True)) _ = study.optimize(n_trials=5, epochs=1, verbose=0) [16] 2020-05-27 23:18:37 ( 2.07s ) python3 ( 20.1s ) [I 2020-05-27 23:18:37,930] A new study created with name: torch.lr.study#3 [run#11] lr=0.003453 epochs=1 [I 2020-05-27 23:18:38,326] Finished trial#0 with value: 3.6390544891357424 with parameters: {'lr': 0.0034526824809447266}. Best is trial#0 with value: 3.6390544891357424. [run#12] lr=0.001207 epochs=1 [I 2020-05-27 23:18:38,712] Finished trial#1 with value: 8.67589328289032 with parameters: {'lr': 0.0012073069446639684}. Best is trial#0 with value: 3.6390544891357424. [run#13] lr=0.008521 epochs=1 [I 2020-05-27 23:18:39,103] Finished trial#2 with value: 25.55988073348999 with parameters: {'lr': 0.008521333301403564}. Best is trial#0 with value: 3.6390544891357424. [run#14] lr=0.008273 epochs=1 [I 2020-05-27 23:18:39,502] Finished trial#3 with value: 17.10937180519104 with parameters: {'lr': 0.00827291966567971}. Best is trial#0 with value: 3.6390544891357424. [run#15] lr=0.006441 epochs=1 [I 2020-05-27 23:18:39,894] Finished trial#4 with value: 8.192878890037537 with parameters: {'lr': 0.006441058869084448}. Best is trial#0 with value: 3.6390544891357424. params = {'hidden_sizes.0': range(10, 20)} # `range` for integer range. study = client.create_study('torch', params) _ = study.optimize(n_trials=5, epochs=1, verbose=0) [17] 2020-05-27 23:18:39 ( 2.12s ) python3 ( 22.3s ) [I 2020-05-27 23:18:40,022] A new study created with name: torch.hidden_sizes.0.study#4 [run#16] hidden_sizes.0=13 epochs=1 [I 2020-05-27 23:18:40,428] Finished trial#0 with value: 7.1854283809661865 with parameters: {'hidden_sizes.0': 13}. Best is trial#0 with value: 7.1854283809661865. [run#17] hidden_sizes.0=14 epochs=1 [I 2020-05-27 23:18:40,814] Finished trial#1 with value: 7.350173377990723 with parameters: {'hidden_sizes.0': 14}. Best is trial#0 with value: 7.1854283809661865. [run#18] hidden_sizes.0=10 epochs=1 [I 2020-05-27 23:18:41,206] Finished trial#2 with value: 10.32146692276001 with parameters: {'hidden_sizes.0': 10}. Best is trial#0 with value: 7.1854283809661865. [run#19] hidden_sizes.0=17 epochs=1 [I 2020-05-27 23:18:41,603] Finished trial#3 with value: 7.983546113967895 with parameters: {'hidden_sizes.0': 17}. Best is trial#0 with value: 7.1854283809661865. [run#20] hidden_sizes.0=17 epochs=1 [I 2020-05-27 23:18:42,012] Finished trial#4 with value: 6.464250636100769 with parameters: {'hidden_sizes.0': 17}. Best is trial#4 with value: 6.464250636100769. params = {'hidden_sizes.0': [10, 20, 30]} # `list` for choice. study = client.create_study('torch', params) _ = study.optimize(n_trials=5, epochs=1, verbose=0) [18] 2020-05-27 23:18:42 ( 2.22s ) python3 ( 24.5s ) [I 2020-05-27 23:18:42,160] A new study created with name: torch.hidden_sizes.0.study#5 [run#21] hidden_sizes.0=30 epochs=1 [I 2020-05-27 23:18:42,575] Finished trial#0 with value: 8.409550452232361 with parameters: {'hidden_sizes.0': 30}. Best is trial#0 with value: 8.409550452232361. [run#22] hidden_sizes.0=10 epochs=1 [I 2020-05-27 23:18:42,987] Finished trial#1 with value: 8.021909594535828 with parameters: {'hidden_sizes.0': 10}. Best is trial#1 with value: 8.021909594535828. [run#23] hidden_sizes.0=20 epochs=1 [I 2020-05-27 23:18:43,403] Finished trial#2 with value: 5.9946791410446165 with parameters: {'hidden_sizes.0': 20}. Best is trial#2 with value: 5.9946791410446165. [run#24] hidden_sizes.0=10 epochs=1 [I 2020-05-27 23:18:43,816] Finished trial#3 with value: 7.373862290382386 with parameters: {'hidden_sizes.0': 10}. Best is trial#2 with value: 5.9946791410446165. [run#25] hidden_sizes.0=30 epochs=1 [I 2020-05-27 23:18:44,233] Finished trial#4 with value: 6.880675101280213 with parameters: {'hidden_sizes.0': 30}. Best is trial#2 with value: 5.9946791410446165. # Product params = {('hidden_sizes.1', 'lr'): (range(10, 20), Range(1e-4, 1e-3))} study = client.create_study('torch', params) _ = study.optimize(n_trials=10, epochs=1, verbose=0) [19] 2020-05-27 23:18:44 ( 4.73s ) python3 ( 29.2s ) [I 2020-05-27 23:18:44,394] A new study created with name: torch.hidden_sizes.1.lr.study#6 [run#26] hidden_sizes.1=15 lr=0.0002087 epochs=1 [I 2020-05-27 23:18:44,853] Finished trial#0 with value: 8.60243787765503 with parameters: {'hidden_sizes.1': 15, 'lr': 0.00020871489914846107}. Best is trial#0 with value: 8.60243787765503. [run#27] hidden_sizes.1=18 lr=0.0004512 epochs=1 [I 2020-05-27 23:18:45,291] Finished trial#1 with value: 8.43991515636444 with parameters: {'hidden_sizes.1': 18, 'lr': 0.0004511662908058376}. Best is trial#1 with value: 8.43991515636444. [run#28] hidden_sizes.1=18 lr=0.0009713 epochs=1 [I 2020-05-27 23:18:45,746] Finished trial#2 with value: 8.1032723903656 with parameters: {'hidden_sizes.1': 18, 'lr': 0.0009712610284500879}. Best is trial#2 with value: 8.1032723903656. [run#29] hidden_sizes.1=16 lr=0.0002713 epochs=1 [I 2020-05-27 23:18:46,197] Finished trial#3 with value: 9.227974724769592 with parameters: {'hidden_sizes.1': 16, 'lr': 0.0002713478088943698}. Best is trial#2 with value: 8.1032723903656. [run#30] hidden_sizes.1=15 lr=0.0004924 epochs=1 [I 2020-05-27 23:18:46,643] Finished trial#4 with value: 7.1845251560211185 with parameters: {'hidden_sizes.1': 15, 'lr': 0.0004924391509012955}. Best is trial#4 with value: 7.1845251560211185. [run#31] hidden_sizes.1=16 lr=0.00087 epochs=1 [I 2020-05-27 23:18:47,096] Finished trial#5 with value: 6.9051319599151615 with parameters: {'hidden_sizes.1': 16, 'lr': 0.0008700252641573457}. Best is trial#5 with value: 6.9051319599151615. [run#32] hidden_sizes.1=16 lr=0.0008246 epochs=1 [I 2020-05-27 23:18:47,565] Finished trial#6 with value: 6.356077587604522 with parameters: {'hidden_sizes.1': 16, 'lr': 0.0008246110788854809}. Best is trial#6 with value: 6.356077587604522. [run#33] hidden_sizes.1=11 lr=0.0006999 epochs=1 [I 2020-05-27 23:18:48,020] Finished trial#7 with value: 7.070446789264679 with parameters: {'hidden_sizes.1': 11, 'lr': 0.0006998930854986198}. Best is trial#6 with value: 6.356077587604522. [run#34] hidden_sizes.1=11 lr=0.0003002 epochs=1 [I 2020-05-27 23:18:48,494] Finished trial#8 with value: 7.815711319446564 with parameters: {'hidden_sizes.1': 11, 'lr': 0.00030017495997032275}. Best is trial#6 with value: 6.356077587604522. [run#35] hidden_sizes.1=15 lr=0.0003322 epochs=1 [I 2020-05-27 23:18:48,963] Finished trial#9 with value: 7.837040793895722 with parameters: {'hidden_sizes.1': 15, 'lr': 0.00033218750069177185}. Best is trial#6 with value: 6.356077587604522. Note You may feel that \" params = {'hidden_sizes.1': range(10, 20), 'lr': Range(1e-4, 1e-3)} \" must be better, but the above style is intentional.","title":"<span class=\"pheasant-header\"><span class=\"header\"><span class=\"title\">Hyperparameter Tuning</span></span></span>"},{"location":"tutorial/tuning/#hyperparameter-tuning","text":"","title":"Hyperparameter Tuning"},{"location":"tutorial/tuning/#suggest-function","text":"To optimize a set of hyperparameters, define a suggest function . Here are example functions. File 7 rectangle/suggest.py def suggest_lr(trial, min, max): trial.suggest_loguniform(\"lr\", min, max) def suggest_hidden_sizes(trial, max_num_layers, min_size=10, max_size=30): num_layers = trial.suggest_int(\"num_layers\", 2, max_num_layers) for k in range(num_layers): trial.suggest_int(f\"hidden_sizes:{k}\", min_size, max_size) A suggest function must take a trial as the first argument but you can add arbitrary arguments if you need. See also the Optuna offical documentation for more details. Note In the suggest_hidden_sizes() function, we use 0-indexed colon-notation , because Optuna doesn't suggest a list itself but its element. These suggest functions don't return any parameters. The only work of suggest functions is to make the Trial instance suggest parameters. Suggested parameters are stored in the Trial instance, so that nothing is needed from suggest functions. Note that the objective function in Optuna has only one trial argument, so that we have to use the functools.partial() function that returns a pure suggest function. from functools import partial from rectangle.suggest import suggest_lr, suggest_hidden_sizes lr = partial(suggest_lr, min=1e-5, max=1e-2) hidden_sizes = partial(suggest_hidden_sizes, max_num_layers=3) [2] 2020-05-27 23:18:31 ( 3.00ms ) python3 ( 12.1s )","title":"Suggest Function"},{"location":"tutorial/tuning/#study","text":"Ivory implements a special run type called Study which controls hyperparameter tuning using Optuna . The Study class is a subclass of the Task class so that the same tracking system can be used. import ivory client = ivory.create_client(\"examples\") # Set the working directory study_lr = client.create_study('torch', lr=lr) study_hs = client.create_study('torch', hidden_sizes=hidden_sizes) study_lr [3] 2020-05-27 23:18:31 ( 83.0ms ) python3 ( 12.2s ) [I 200527 23:18:31 tracker:48] A new experiment created with name: 'torch' Study(id='130ec196c34f44cbb0478e19ac95e053', name='study#0', num_objects=5)","title":"Study"},{"location":"tutorial/tuning/#objective","text":"The ivory.core.objective.Objective class provides objective functions that return a score to minimize or maximize. But you don't need to know about the Objective class in details. Ivory builds an objective function from a suggest function and provides it to Optuna so that Optuna can optimize the parameters. A Study instance has an Objective instance. study_lr.objective [4] 2020-05-27 23:18:31 ( 4.00ms ) python3 ( 12.2s ) Objective(suggests=['lr']) study_hs.objective [5] 2020-05-27 23:18:31 ( 5.00ms ) python3 ( 12.2s ) Objective(suggests=['hidden_sizes'])","title":"Objective"},{"location":"tutorial/tuning/#optimization","text":"Then \"optimize\" the learning rate and hidden sizes just for fun. optuna_study_lr = study_lr.optimize(n_trials=3, fold=3, epochs=3) [6] 2020-05-27 23:18:31 ( 1.90s ) python3 ( 14.1s ) [I 2020-05-27 23:18:32,007] A new study created with name: torch.lr.study#0 [run#0] lr=0.005467 fold=3 epochs=3 [epoch#0] loss=35.15 val_loss=6.169 lr=0.005467 best [epoch#1] loss=25.38 val_loss=12.47 lr=0.005467 [epoch#2] loss=8.913 val_loss=8.321 lr=0.005467 [I 2020-05-27 23:18:32,605] Finished trial#0 with value: 6.1692323088645935 with parameters: {'lr': 0.00546700761536697}. Best is trial#0 with value: 6.1692323088645935. [run#1] lr=2.048e-05 fold=3 epochs=3 [epoch#0] loss=99.59 val_loss=89.16 lr=2.048e-05 best [epoch#1] loss=73.5 val_loss=63.15 lr=2.048e-05 best [epoch#2] loss=48.44 val_loss=39.14 lr=2.048e-05 best [I 2020-05-27 23:18:33,260] Finished trial#1 with value: 39.13609299659729 with parameters: {'lr': 2.047791487362893e-05}. Best is trial#0 with value: 6.1692323088645935. [run#2] lr=1.934e-05 fold=3 epochs=3 [epoch#0] loss=105.7 val_loss=97.99 lr=1.934e-05 best [epoch#1] loss=85.05 val_loss=77.67 lr=1.934e-05 best [epoch#2] loss=64.52 val_loss=56.65 lr=1.934e-05 best [I 2020-05-27 23:18:33,861] Finished trial#2 with value: 56.652531433105466 with parameters: {'lr': 1.934042439130678e-05}. Best is trial#0 with value: 6.1692323088645935. optuna_study_hs = study_hs.optimize(n_trials=3, epochs=3) [7] 2020-05-27 23:18:33 ( 1.95s ) python3 ( 16.1s ) [I 2020-05-27 23:18:33,894] A new study created with name: torch.hidden_sizes.study#1 [run#3] hidden_sizes:0=10 hidden_sizes:1=12 hidden_sizes:2=18 num_layers=3 epochs=3 [epoch#0] loss=43.89 val_loss=8.516 lr=0.001 best [epoch#1] loss=9.464 val_loss=8.018 lr=0.001 best [epoch#2] loss=8.187 val_loss=6.489 lr=0.001 best [I 2020-05-27 23:18:34,537] Finished trial#0 with value: 6.489188611507416 with parameters: {'hidden_sizes:0': 10, 'hidden_sizes:1': 12, 'hidden_sizes:2': 18, 'num_layers': 3}. Best is trial#0 with value: 6.489188611507416. [run#4] hidden_sizes:0=18 hidden_sizes:1=20 hidden_sizes:2=13 num_layers=3 epochs=3 [epoch#0] loss=41.8 val_loss=8.217 lr=0.001 best [epoch#1] loss=8.612 val_loss=6.373 lr=0.001 best [epoch#2] loss=6.862 val_loss=4.805 lr=0.001 best [I 2020-05-27 23:18:35,168] Finished trial#1 with value: 4.804597091674805 with parameters: {'hidden_sizes:0': 18, 'hidden_sizes:1': 20, 'hidden_sizes:2': 13, 'num_layers': 3}. Best is trial#1 with value: 4.804597091674805. [run#5] hidden_sizes:0=22 hidden_sizes:1=15 hidden_sizes:2=22 num_layers=3 epochs=3 [epoch#0] loss=27.76 val_loss=8.74 lr=0.001 best [epoch#1] loss=8.866 val_loss=6.881 lr=0.001 best [epoch#2] loss=7.158 val_loss=5.326 lr=0.001 best [I 2020-05-27 23:18:35,814] Finished trial#2 with value: 5.32561604976654 with parameters: {'hidden_sizes:0': 22, 'hidden_sizes:1': 15, 'hidden_sizes:2': 22, 'num_layers': 3}. Best is trial#1 with value: 4.804597091674805. Note By cliking an icon ( ) in the above cells, you can see the Optuna's log. The returned value of the study.optimize() is an Optuna's Study instance (not Ivory's one). optuna_study_lr [8] 2020-05-27 23:18:35 ( 3.00ms ) python3 ( 16.1s ) <optuna.study.Study at 0x1fa195e4c48> The Study instance is named after the experiment name, suggest name, and run name. optuna_study_lr.study_name [9] 2020-05-27 23:18:35 ( 4.00ms ) python3 ( 16.1s ) 'torch.lr.study#0' In user attributes that Optuna's Study and Trial instances provide, RunID is saved. optuna_study_lr.user_attrs [10] 2020-05-27 23:18:35 ( 6.00ms ) python3 ( 16.1s ) {'run_id': '130ec196c34f44cbb0478e19ac95e053'} optuna_study_lr.trials[0].user_attrs [11] 2020-05-27 23:18:35 ( 6.00ms ) python3 ( 16.1s ) {'run_id': '700633cfbdca43caa4888cfd0f7529ab'} On the other hand, MLFlow Tracking's run (not Ivory's one) has a tag to refer Optuna's study and trial. mlflow_client = client.tracker.client mlflow_client [12] 2020-05-27 23:18:35 ( 5.00ms ) python3 ( 16.1s ) <mlflow.tracking.client.MlflowClient at 0x1fa206f1408> run_id = optuna_study_lr.user_attrs['run_id'] run = mlflow_client.get_run(run_id) run.data.tags['study_name'] [13] 2020-05-27 23:18:35 ( 8.00ms ) python3 ( 16.1s ) 'torch.lr.study#0' run_id = optuna_study_lr.trials[0].user_attrs['run_id'] run = mlflow_client.get_run(run_id) run.data.tags['trial_number'] [14] 2020-05-27 23:18:35 ( 10.0ms ) python3 ( 16.1s ) '0' You may have a question. How does Optuna optimize the parameters without any score? The answer is the Monitor instance. An Objective instance gets the monitoring score from run.monitor and sends it to Optuna so that Optuna can determine the next suggestion. All you need is to make your Run instance have a Monitor instance. Check the YAML parameter file: File 8 torch.yml library: torch dataloaders: data: class: rectangle.data.Data n_splits: 4 dataset: batch_size: 10 fold: 0 model: class: rectangle.torch.Model hidden_sizes: [100, 100] optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 1e-3 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: metrics: criterion: def: torch.nn.functional.mse_loss monitor: metric: val_loss early_stopping: patience: 10 trainer: epochs: 10 verbose: 2 The Monitor instance monitors val_loss and the default mode is min (smaller is better). If your monitor is accuracy, for example, set the monitor like this: monitor: metric: accuracy mode: max","title":"Optimization"},{"location":"tutorial/tuning/#parametric-optimization","text":"Again read the suggest functions. File 9 rectangle/suggest.py def suggest_lr(trial, min, max): trial.suggest_loguniform(\"lr\", min, max) def suggest_hidden_sizes(trial, max_num_layers, min_size=10, max_size=30): num_layers = trial.suggest_int(\"num_layers\", 2, max_num_layers) for k in range(num_layers): trial.suggest_int(f\"hidden_sizes:{k}\", min_size, max_size) The suggest_hidden_sizes() function has some logic but the suggest_lr() function is too simple to define a function. You may not want to write such a function. Ivory can do that for you. You can pass iterable(s) to the client.create_study() function instead of a callable study = client.create_study('torch', lr=(1e-3, 1e-2)) # `tuple` for range _ = study.optimize(n_trials=5, epochs=1, verbose=0) [15] 2020-05-27 23:18:35 ( 1.95s ) python3 ( 18.1s ) [I 2020-05-27 23:18:35,965] A new study created with name: torch.lr.study#2 [run#6] lr=0.004916 epochs=1 [I 2020-05-27 23:18:36,334] Finished trial#0 with value: 8.1303279876709 with parameters: {'lr': 0.004916395615500159}. Best is trial#0 with value: 8.1303279876709. [run#7] lr=0.00945 epochs=1 [I 2020-05-27 23:18:36,702] Finished trial#1 with value: 53.275264739990234 with parameters: {'lr': 0.009450143323053647}. Best is trial#0 with value: 8.1303279876709. [run#8] lr=0.00302 epochs=1 [I 2020-05-27 23:18:37,071] Finished trial#2 with value: 6.67906551361084 with parameters: {'lr': 0.0030202464293425063}. Best is trial#2 with value: 6.67906551361084. [run#9] lr=0.0036 epochs=1 [I 2020-05-27 23:18:37,444] Finished trial#3 with value: 8.580164682865142 with parameters: {'lr': 0.0036000147052569474}. Best is trial#2 with value: 6.67906551361084. [run#10] lr=0.006506 epochs=1 [I 2020-05-27 23:18:37,819] Finished trial#4 with value: 14.026474809646606 with parameters: {'lr': 0.006506403843828701}. Best is trial#2 with value: 6.67906551361084. from ivory.utils.range import Range # `Range` for log scale. study = client.create_study('torch', lr=Range(1e-3, 1e-2, log=True)) _ = study.optimize(n_trials=5, epochs=1, verbose=0) [16] 2020-05-27 23:18:37 ( 2.07s ) python3 ( 20.1s ) [I 2020-05-27 23:18:37,930] A new study created with name: torch.lr.study#3 [run#11] lr=0.003453 epochs=1 [I 2020-05-27 23:18:38,326] Finished trial#0 with value: 3.6390544891357424 with parameters: {'lr': 0.0034526824809447266}. Best is trial#0 with value: 3.6390544891357424. [run#12] lr=0.001207 epochs=1 [I 2020-05-27 23:18:38,712] Finished trial#1 with value: 8.67589328289032 with parameters: {'lr': 0.0012073069446639684}. Best is trial#0 with value: 3.6390544891357424. [run#13] lr=0.008521 epochs=1 [I 2020-05-27 23:18:39,103] Finished trial#2 with value: 25.55988073348999 with parameters: {'lr': 0.008521333301403564}. Best is trial#0 with value: 3.6390544891357424. [run#14] lr=0.008273 epochs=1 [I 2020-05-27 23:18:39,502] Finished trial#3 with value: 17.10937180519104 with parameters: {'lr': 0.00827291966567971}. Best is trial#0 with value: 3.6390544891357424. [run#15] lr=0.006441 epochs=1 [I 2020-05-27 23:18:39,894] Finished trial#4 with value: 8.192878890037537 with parameters: {'lr': 0.006441058869084448}. Best is trial#0 with value: 3.6390544891357424. params = {'hidden_sizes.0': range(10, 20)} # `range` for integer range. study = client.create_study('torch', params) _ = study.optimize(n_trials=5, epochs=1, verbose=0) [17] 2020-05-27 23:18:39 ( 2.12s ) python3 ( 22.3s ) [I 2020-05-27 23:18:40,022] A new study created with name: torch.hidden_sizes.0.study#4 [run#16] hidden_sizes.0=13 epochs=1 [I 2020-05-27 23:18:40,428] Finished trial#0 with value: 7.1854283809661865 with parameters: {'hidden_sizes.0': 13}. Best is trial#0 with value: 7.1854283809661865. [run#17] hidden_sizes.0=14 epochs=1 [I 2020-05-27 23:18:40,814] Finished trial#1 with value: 7.350173377990723 with parameters: {'hidden_sizes.0': 14}. Best is trial#0 with value: 7.1854283809661865. [run#18] hidden_sizes.0=10 epochs=1 [I 2020-05-27 23:18:41,206] Finished trial#2 with value: 10.32146692276001 with parameters: {'hidden_sizes.0': 10}. Best is trial#0 with value: 7.1854283809661865. [run#19] hidden_sizes.0=17 epochs=1 [I 2020-05-27 23:18:41,603] Finished trial#3 with value: 7.983546113967895 with parameters: {'hidden_sizes.0': 17}. Best is trial#0 with value: 7.1854283809661865. [run#20] hidden_sizes.0=17 epochs=1 [I 2020-05-27 23:18:42,012] Finished trial#4 with value: 6.464250636100769 with parameters: {'hidden_sizes.0': 17}. Best is trial#4 with value: 6.464250636100769. params = {'hidden_sizes.0': [10, 20, 30]} # `list` for choice. study = client.create_study('torch', params) _ = study.optimize(n_trials=5, epochs=1, verbose=0) [18] 2020-05-27 23:18:42 ( 2.22s ) python3 ( 24.5s ) [I 2020-05-27 23:18:42,160] A new study created with name: torch.hidden_sizes.0.study#5 [run#21] hidden_sizes.0=30 epochs=1 [I 2020-05-27 23:18:42,575] Finished trial#0 with value: 8.409550452232361 with parameters: {'hidden_sizes.0': 30}. Best is trial#0 with value: 8.409550452232361. [run#22] hidden_sizes.0=10 epochs=1 [I 2020-05-27 23:18:42,987] Finished trial#1 with value: 8.021909594535828 with parameters: {'hidden_sizes.0': 10}. Best is trial#1 with value: 8.021909594535828. [run#23] hidden_sizes.0=20 epochs=1 [I 2020-05-27 23:18:43,403] Finished trial#2 with value: 5.9946791410446165 with parameters: {'hidden_sizes.0': 20}. Best is trial#2 with value: 5.9946791410446165. [run#24] hidden_sizes.0=10 epochs=1 [I 2020-05-27 23:18:43,816] Finished trial#3 with value: 7.373862290382386 with parameters: {'hidden_sizes.0': 10}. Best is trial#2 with value: 5.9946791410446165. [run#25] hidden_sizes.0=30 epochs=1 [I 2020-05-27 23:18:44,233] Finished trial#4 with value: 6.880675101280213 with parameters: {'hidden_sizes.0': 30}. Best is trial#2 with value: 5.9946791410446165. # Product params = {('hidden_sizes.1', 'lr'): (range(10, 20), Range(1e-4, 1e-3))} study = client.create_study('torch', params) _ = study.optimize(n_trials=10, epochs=1, verbose=0) [19] 2020-05-27 23:18:44 ( 4.73s ) python3 ( 29.2s ) [I 2020-05-27 23:18:44,394] A new study created with name: torch.hidden_sizes.1.lr.study#6 [run#26] hidden_sizes.1=15 lr=0.0002087 epochs=1 [I 2020-05-27 23:18:44,853] Finished trial#0 with value: 8.60243787765503 with parameters: {'hidden_sizes.1': 15, 'lr': 0.00020871489914846107}. Best is trial#0 with value: 8.60243787765503. [run#27] hidden_sizes.1=18 lr=0.0004512 epochs=1 [I 2020-05-27 23:18:45,291] Finished trial#1 with value: 8.43991515636444 with parameters: {'hidden_sizes.1': 18, 'lr': 0.0004511662908058376}. Best is trial#1 with value: 8.43991515636444. [run#28] hidden_sizes.1=18 lr=0.0009713 epochs=1 [I 2020-05-27 23:18:45,746] Finished trial#2 with value: 8.1032723903656 with parameters: {'hidden_sizes.1': 18, 'lr': 0.0009712610284500879}. Best is trial#2 with value: 8.1032723903656. [run#29] hidden_sizes.1=16 lr=0.0002713 epochs=1 [I 2020-05-27 23:18:46,197] Finished trial#3 with value: 9.227974724769592 with parameters: {'hidden_sizes.1': 16, 'lr': 0.0002713478088943698}. Best is trial#2 with value: 8.1032723903656. [run#30] hidden_sizes.1=15 lr=0.0004924 epochs=1 [I 2020-05-27 23:18:46,643] Finished trial#4 with value: 7.1845251560211185 with parameters: {'hidden_sizes.1': 15, 'lr': 0.0004924391509012955}. Best is trial#4 with value: 7.1845251560211185. [run#31] hidden_sizes.1=16 lr=0.00087 epochs=1 [I 2020-05-27 23:18:47,096] Finished trial#5 with value: 6.9051319599151615 with parameters: {'hidden_sizes.1': 16, 'lr': 0.0008700252641573457}. Best is trial#5 with value: 6.9051319599151615. [run#32] hidden_sizes.1=16 lr=0.0008246 epochs=1 [I 2020-05-27 23:18:47,565] Finished trial#6 with value: 6.356077587604522 with parameters: {'hidden_sizes.1': 16, 'lr': 0.0008246110788854809}. Best is trial#6 with value: 6.356077587604522. [run#33] hidden_sizes.1=11 lr=0.0006999 epochs=1 [I 2020-05-27 23:18:48,020] Finished trial#7 with value: 7.070446789264679 with parameters: {'hidden_sizes.1': 11, 'lr': 0.0006998930854986198}. Best is trial#6 with value: 6.356077587604522. [run#34] hidden_sizes.1=11 lr=0.0003002 epochs=1 [I 2020-05-27 23:18:48,494] Finished trial#8 with value: 7.815711319446564 with parameters: {'hidden_sizes.1': 11, 'lr': 0.00030017495997032275}. Best is trial#6 with value: 6.356077587604522. [run#35] hidden_sizes.1=15 lr=0.0003322 epochs=1 [I 2020-05-27 23:18:48,963] Finished trial#9 with value: 7.837040793895722 with parameters: {'hidden_sizes.1': 15, 'lr': 0.00033218750069177185}. Best is trial#6 with value: 6.356077587604522. Note You may feel that \" params = {'hidden_sizes.1': range(10, 20), 'lr': Range(1e-4, 1e-3)} \" must be better, but the above style is intentional.","title":"Parametric Optimization"}]}