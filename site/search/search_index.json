{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Quickstart Ivory is a lightweight framework for machine learning. It integrates model design, tracking, and hyperparmeter tuning. Ivory uses MLflow Tracking for tracking and Optuna for hyperparmeter tuning. Using Ivory, you can tackle both tracking and tuning workflow at one place. Another key feature of Ivory is its model design. You can write down all of your model structure and tracking/tuning process in one YAML file. It allows us to understand the whole process at a glance. Installation You can install Ivory by a pip command. $ pip install ivory Using a Ivory Client Ivory has the Client class that manages the workflow of any machine learning. Let's create your first Client instance. In this quickstart, we are working with examples under the examples directory. import ivory client = ivory.create_client(\"examples\") client [2] 2020-05-25 08:12:26 ( 1.02s ) python3 ( 1.06s ) Client(num_objects=2) The representation of the client shows that it has two objects. Objects that a client has can be accessed by index notation or dot notation . client[0] # or client['tracker'], or client.tracker [3] 2020-05-25 08:12:27 ( 4.00ms ) python3 ( 1.06s ) Tracker(tracking_uri='file:///C:/Users/daizu/Documents/github/ivory/docs/examples/mlruns', artifact_location=None) The first object is a Tracker instance which connects Ivory to MLFlow Tracking . Because a Client instance is an iterable, you can get all of the objects by applying list() to it. list(client) [4] 2020-05-25 08:12:27 ( 5.00ms ) python3 ( 1.06s ) ['tracker', 'tuner'] The second objects is named tuner . client.tuner [5] 2020-05-25 08:12:27 ( 3.00ms ) python3 ( 1.07s ) Tuner(storage='sqlite://', sampler=None, pruner=None, load_if_exists=True) A Tuner instance connects Ivory to Optuna: A hyperparameter optimization framework . We can customize these objects with a YAML file named client.yml under the woking directory. In our case, the file just contains the minimum settings. File 1 client.yml client: tracker: tuner: Note A YAML file for client is not required. If there is no file for client, Ivory creates a default client with a tracker and without a tuner. If you don't need a tracker, use ivory.create_client(tracker=False) . Create NumPy data In this quickstart, we try to predict rectangles area from thier width and height using PyTorch . First, prepare the data as NumPy arrays. In example.py under the working directory, a create_data() function is defined. The ivory.create_client() function automatically inserts the working directory to sys.path , so that we can import the module regardless of the current directory. import example [6] 2020-05-25 08:12:27 ( 266ms ) python3 ( 1.33s ) Let's check the create_data() function definition and an example output: Code 1 example.create_data def create_data(num_samples=1000): xy = 4 * np.random.rand(num_samples, 2) + 1 xy = xy.astype(np.float32) dx = 0.1 * (np.random.rand(num_samples) - 0.5) dy = 0.1 * (np.random.rand(num_samples) - 0.5) z = ((xy[:, 0] + dx) * (xy[:, 1] + dy)).astype(np.float32) return xy, z xy, z = example.create_data(4) xy [8] 2020-05-25 08:12:27 ( 5.00ms ) python3 ( 1.36s ) array([[4.628753 , 2.6472826], [3.3307068, 4.298735 ], [3.14777 , 1.0443248], [3.1629949, 2.1611164]], dtype=float32) z [9] 2020-05-25 08:12:27 ( 3.00ms ) python3 ( 1.36s ) array([12.045295 , 14.46252 , 3.2317824, 7.073397 ], dtype=float32) Set of Data classes Ivory defines a set of Data classes ( Data , Dataset , Datasets , DataLoaders ). But now, we use the Data class only. Code 2 example.Data @dataclass class Data(ivory.core.data.Data): n_splits: int = 5 DATA = create_data(1000) def init(self): self.input, self.target = self.DATA self.index = np.arange(len(self.input)) self.fold = kfold_split(self.input, n_splits=self.n_splits) # Creating test set just for demonstration. is_test = self.fold == self.n_splits - 1 self.fold = np.where(is_test, -1, self.fold) self.target = np.where(is_test, np.nan, self.target) self.target = self.target.reshape(-1, 1) # (sample, channel) Here, kfold_split function creates a fold-array. import numpy as np from ivory.utils.fold import kfold_split kfold_split(np.arange(10), n_splits=3) [11] 2020-05-25 08:12:27 ( 5.00ms ) python3 ( 1.38s ) array([2, 1, 0, 2, 0, 2, 1, 1, 0, 0], dtype=int8) In Ivory, fold number = -1 means their samples are test data. Now, we can get a Data instance. data = example.Data() data [12] 2020-05-25 08:12:27 ( 4.00ms ) python3 ( 1.38s ) Data(n_splits=5) data.get(0) # get data of index = 0. [13] 2020-05-25 08:12:27 ( 4.00ms ) python3 ( 1.39s ) [0, array([3.5546277, 4.5952773], dtype=float32), array([16.358192], dtype=float32)] This returned value is a list of [index, input, target]. Ivory always keeps data index so that we can know where a sample comes from. Define a model We use a simple MLP model here. Code 3 example.Model class Model(nn.Module): def __init__(self, hidden_sizes): super().__init__() layers = [] for in_features, out_features in zip([2] + hidden_sizes, hidden_sizes + [1]): layers.append(nn.Linear(in_features, out_features)) self.layers = nn.ModuleList(layers) def forward(self, x): for layer in self.layers[:-1]: x = F.relu(layer(x)) return self.layers[-1](x) Parameter file for Run Ivory configures a run using a YAML file. Here is a full example. File 2 torch.yaml library: torch dataloaders: data: class: example.Data n_splits: 5 dataset: batch_size: 10 fold: 0 model: class: example.Model hidden_sizes: [100, 100] optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 1e-3 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: metrics: criterion: def: torch.nn.functional.mse_loss monitor: metric: val_loss early_stopping: patience: 10 trainer: epochs: 10 verbose: 2 Let's create a run by Client.create_run() run = client.create_run('torch') run [15] 2020-05-25 08:12:27 ( 274ms ) python3 ( 1.68s ) [I 200525 08:12:27 tracker:48] A new experiment created with name: torch Run(id='598eaf8e0120434db9f059a562416e18', name='run#0', num_objects=12) Note Client.create_run(<name>) creates an experiment named <name> if it hasn't existed yet. By cliking an icon ( ) in the above cell, you can see the log. Or you can directly create an experiment then make the experiment create a run: experiment = client . create_experiment ( 'torch' ) run = experiment . create_run () A Run instance have a params attribute that holds the parameters for the run. import yaml print(yaml.dump(run.params, sort_keys=False)) [16] 2020-05-25 08:12:28 ( 6.00ms ) python3 ( 1.68s ) run: dataloaders: data: class: example.Data n_splits: 5 dataset: def: ivory.torch.data.Dataset batch_size: 10 fold: 0 class: ivory.torch.data.DataLoaders model: class: example.Model hidden_sizes: - 100 - 100 optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 0.001 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: class: ivory.torch.results.Results metrics: criterion: def: torch.nn.functional.mse_loss class: ivory.torch.metrics.Metrics monitor: metric: val_loss class: ivory.callbacks.monitor.Monitor early_stopping: patience: 10 class: ivory.callbacks.early_stopping.EarlyStopping trainer: epochs: 10 verbose: 2 class: ivory.torch.trainer.Trainer class: ivory.torch.run.Run name: run#0 id: 598eaf8e0120434db9f059a562416e18 experiment: name: torch class: ivory.core.base.Experiment id: '1' This is similar to the YAML file we read before, but is slightly changed by the Ivory Client. Run and experiment sections are inserted. ExperimentID and RunID are assigned by the MLFlow Tracking. Default classes are specified, for example ivory.torch.trainer.Trainer for a trainer instance. The Client.create_run() method takes keyword arguments to modify these parameters: run = client.create_run( 'torch', batch_size=20, hidden_sizes=[40, 50, 60], ) print('[dataloaders]') print(yaml.dump(run.params['run']['dataloaders'], sort_keys=False)) print('[model]') print(yaml.dump(run.params['run']['model'], sort_keys=False)) [17] 2020-05-25 08:12:28 ( 48.0ms ) python3 ( 1.73s ) [dataloaders] data: class: example.Data n_splits: 5 dataset: def: ivory.torch.data.Dataset batch_size: 20 fold: 0 class: ivory.torch.data.DataLoaders [model] class: example.Model hidden_sizes: - 40 - 50 - 60 Train a model Once you got a run instance, then all you need is to start it. run = client.create_run('torch') # Back to the default settings. run.start() [18] 2020-05-25 08:12:28 ( 1.37s ) python3 ( 3.10s ) [epoch#0] loss=12.24 val_loss=8.498 lr=0.001 best [epoch#1] loss=6.555 val_loss=6.277 lr=0.001 best [epoch#2] loss=5.001 val_loss=5.858 lr=0.001 best [epoch#3] loss=3.458 val_loss=2.508 lr=0.001 best [epoch#4] loss=2.213 val_loss=1.501 lr=0.001 best [epoch#5] loss=1.32 val_loss=1.36 lr=0.001 best [epoch#6] loss=1.098 val_loss=1.096 lr=0.001 best [epoch#7] loss=0.8826 val_loss=0.6978 lr=0.001 best [epoch#8] loss=0.9326 val_loss=0.5321 lr=0.001 best [epoch#9] loss=0.7491 val_loss=1.128 lr=0.001 The history of metrics is saved as the history attribute of a run.metrics instance. run.metrics.history [19] 2020-05-25 08:12:29 ( 5.00ms ) python3 ( 3.10s ) {'loss': {0: 12.241463792324065, 1: 6.554965313275655, 2: 5.000564849376678, 3: 3.4583153078953424, 4: 2.213449684282144, 5: 1.3196005828678607, 6: 1.097760977099339, 7: 0.8826028736929099, 8: 0.9326490251968305, 9: 0.749077113221089}, 'val_loss': {0: 8.498352408409119, 1: 6.277046465873719, 2: 5.857835829257965, 3: 2.507568579912186, 4: 1.5011233597993852, 5: 1.3604056045413018, 6: 1.0963490769267081, 7: 0.6978286743164063, 8: 0.5320957466959954, 9: 1.1281802162528038}, 'lr': {0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001}} Also the model output and target are automatically collected in a run.results instance. run.results [20] 2020-05-25 08:12:29 ( 4.00ms ) python3 ( 3.11s ) Results('train', 'val') run.results.val.output[:5] [21] 2020-05-25 08:12:29 ( 4.00ms ) python3 ( 3.11s ) array([[15.22483 ], [ 3.2956257], [13.455274 ], [ 8.64801 ], [ 7.5879283]], dtype=float32) run.results.val.target[:5] [22] 2020-05-25 08:12:29 ( 4.00ms ) python3 ( 3.11s ) array([[14.6351795], [ 3.065638 ], [12.72186 ], [ 7.4222608], [ 6.1824374]], dtype=float32) Test a model Testing a model is as simple as training. Just call run.start() with a test argument in stead of (default) train . run.start('test') run.results [23] 2020-05-25 08:12:29 ( 44.0ms ) python3 ( 3.16s ) Results('train', 'val', 'test') As you can see, test results were added. run.results.test.output[:5] [24] 2020-05-25 08:12:29 ( 5.00ms ) python3 ( 3.16s ) array([[ 2.7136889], [ 8.259468 ], [ 6.3204045], [ 9.698607 ], [17.519829 ]], dtype=float32) Off course the target values for the test data are np.nan . run.results.test.target[:5] [25] 2020-05-25 08:12:29 ( 4.00ms ) python3 ( 3.17s ) array([[nan], [nan], [nan], [nan], [nan]], dtype=float32) Task for multiple runs Ivory implements a special run type called Task which controls multiple nested runs. A task is useful for parameter search or cross validation. task = client.create_task('torch') task [26] 2020-05-25 08:12:29 ( 53.0ms ) python3 ( 3.22s ) Task(id='7adfc6844a5a45ffb155fc2d1c5ddaf1', name='task#0', num_objects=3) The Task class has two methods to generate multiple runs: prodcut() and chain() . These two methods have the same functionality as itertools of Python starndard library. Let's try to perform cross validation. runs = task.product(fold=range(4), verbose=0, epochs=3) runs [27] 2020-05-25 08:12:29 ( 3.00ms ) python3 ( 3.22s ) <generator object Task.product at 0x0000017FB3D26448> Like itertools 's functions, Task.prodcut() and Task.chain() return a generator, which yields runs that are configured by different parameters you specified. In this case, this generator will yield 4 runs with a fold number ranging from 0 to 4 for each. A task instance doesn't start any training by itself. Note You can pass fixed parameters to update the original parameters in the YAML file. Then start 4 runs by a for loop including run.train() . Here a both argument means execution of test after training. for run in runs: run.start('both') [28] 2020-05-25 08:12:29 ( 2.34s ) python3 ( 5.57s ) [run#3] epochs=3 fold=0 [epoch#0] loss=14.95 val_loss=7.605 lr=0.001 best [epoch#1] loss=6.317 val_loss=5.682 lr=0.001 best [epoch#2] loss=4.543 val_loss=3.998 lr=0.001 best [run#4] epochs=3 fold=1 [epoch#0] loss=13.36 val_loss=7.826 lr=0.001 best [epoch#1] loss=7.27 val_loss=6.455 lr=0.001 best [epoch#2] loss=5.719 val_loss=4.938 lr=0.001 best [run#5] epochs=3 fold=2 [epoch#0] loss=13.58 val_loss=6.452 lr=0.001 best [epoch#1] loss=6.487 val_loss=4.378 lr=0.001 best [epoch#2] loss=4.559 val_loss=3.107 lr=0.001 best [run#6] epochs=3 fold=3 [epoch#0] loss=12.63 val_loss=7.419 lr=0.001 best [epoch#1] loss=6.476 val_loss=5.834 lr=0.001 best [epoch#2] loss=4.909 val_loss=4.506 lr=0.001 best Collect runs Our client has a Tracker instance. It stores the state of runs in background using the MLFlow Tracking. The Client class provides several methods to access the stored runs. For example, Client.search_run_ids() returns a generator which yields RunID created by the MLFlow Tracking. # A helper function def print_run_info(run_ids): for run_id in run_ids: print(run_id[:5], client.get_run_name(run_id)) [29] 2020-05-25 08:12:31 ( 5.00ms ) python3 ( 5.57s ) run_ids = client.search_run_ids('torch') print_run_info(run_ids) [30] 2020-05-25 08:12:31 ( 69.0ms ) python3 ( 5.64s ) 7b06b run#6 3e893 run#5 37a01 run#4 708f1 run#3 7adfc task#0 94e71 run#2 40bcf run#1 598ea run#0 For filtering, add key-value pairs. # If `exclude_parent` is True, parent runs are excluded. run_ids = client.search_run_ids('torch', fold=0, exclude_parent=True) print_run_info(run_ids) [31] 2020-05-25 08:12:32 ( 167ms ) python3 ( 5.81s ) 708f1 run#3 94e71 run#2 40bcf run#1 598ea run#0 # If `parent_run_id` is specified, nested runs having the parent are returned. run_ids = client.search_run_ids('torch', parent_run_id=task.id) print_run_info(run_ids) [32] 2020-05-25 08:12:32 ( 46.0ms ) python3 ( 5.85s ) 7b06b run#6 3e893 run#5 37a01 run#4 708f1 run#3 Client.get_run_id() and Client.get_run_ids() fetch RunID from run name, more strictly, (run class name in lower case) plus (run number). run_ids = [client.get_run_id('torch', run=0), client.get_run_id('torch', task=0)] print_run_info(run_ids) [33] 2020-05-25 08:12:32 ( 54.0ms ) python3 ( 5.91s ) 598ea run#0 7adfc task#0 run_ids = client.get_run_ids('torch', run=range(2, 4)) print_run_info(run_ids) [34] 2020-05-25 08:12:32 ( 56.0ms ) python3 ( 5.96s ) 94e71 run#2 708f1 run#3 Load runs and results The Ivory Client class can load runs. First select RunID(s) to load. We want to perform cross validation here, so that we need a run collection created by a task. In this case, we can use Client.get_nested_run_ids() . Why don't we use Client.search_run_ids() as we did above? Because we don't have an easy way to get a very long RunID after we restart a Python session. On the ohter hand, a run name is easy to manage and write. run_ids = list(client.get_nested_run_ids('torch', task=0)) print_run_info(run_ids) [35] 2020-05-25 08:12:32 ( 66.0ms ) python3 ( 6.03s ) 7b06b run#6 3e893 run#5 37a01 run#4 708f1 run#3 Let's load the latest run. run = client.load_run(run_ids[0]) run [36] 2020-05-25 08:12:32 ( 65.0ms ) python3 ( 6.09s ) Run(id='7b06b11d5908411e963023160a912e21', name='run#6', num_objects=11) Note Client.load_run() doesn't require an experiment name, because RunID is unique among the MLFlow Tracking. As you expected, the fold number is 3. run.dataloaders.fold [37] 2020-05-25 08:12:32 ( 3.00ms ) python3 ( 6.10s ) 3 We obtained the trained model. run.model.eval() [38] 2020-05-25 08:12:32 ( 4.00ms ) python3 ( 6.10s ) Model( (layers): ModuleList( (0): Linear(in_features=2, out_features=100, bias=True) (1): Linear(in_features=100, out_features=100, bias=True) (2): Linear(in_features=100, out_features=1, bias=True) ) ) import torch index, input, target = next(iter(run.dataloaders.val)) with torch.no_grad(): output = run.model(input) print('[output]') print(output) print('[target]') print(target) [39] 2020-05-25 08:12:32 ( 10.0ms ) python3 ( 6.11s ) [output] tensor([[12.3252], [ 6.5610], [ 8.2248], [ 4.9248], [10.9631], [ 9.7004], [ 7.6684], [ 5.5870], [ 9.4059], [17.1684]]) [target] tensor([[11.8446], [ 4.0026], [ 6.1003], [ 2.5613], [10.0389], [ 7.9452], [ 4.5900], [ 3.1889], [ 7.4198], [20.9542]]) If you don't need a whole run instance, Client.load_instance() is a better choice to save time and memory. results = client.load_instance(run_ids[0], 'results') results [40] 2020-05-25 08:12:32 ( 24.0ms ) python3 ( 6.14s ) Results('train', 'val', 'test') for mode in ['train', 'val', 'test']: print(mode, results[mode].output.shape) [41] 2020-05-25 08:12:32 ( 8.00ms ) python3 ( 6.14s ) train (600, 1) val (200, 1) test (200, 1) For cross validation, we need 4 runs. (Note that n_splits was 5 but we used the last fold for dummy test data.) To load multiple run's results, the Ivory Client provides a convenient method. results = client.load_results(run_ids, verbose=False) results [42] 2020-05-25 08:12:32 ( 90.0ms ) python3 ( 6.23s ) Results('val', 'test') for mode in ['val', 'test']: print(mode, results[mode].output.shape) [43] 2020-05-25 08:12:32 ( 7.00ms ) python3 ( 6.24s ) val (800, 1) test (800, 1) Note Client.load_results() drops train data for saving memory. The lengths of validation data and test data are both 800 (200 times 4). But be careful about the test data. The length of unique samples is 200 (one fold size). import numpy as np len(np.unique(results.val.index)), len(np.unique(results.test.index)) [44] 2020-05-25 08:12:32 ( 4.00ms ) python3 ( 6.24s ) (800, 200) Usually, duplicated samples are averaged for ensembling. Results.mean() method performs this mean reduction and returns a newly created Rusults instance. reduced_results = results.mean() for mode in ['val', 'test']: print(mode, reduced_results[mode].output.shape) [45] 2020-05-25 08:12:32 ( 13.0ms ) python3 ( 6.26s ) val (800, 1) test (200, 1) Compare the results. index = results.test.index index_0 = index[0] x = results.test.output[index == index_0] print('[results]') print(x) print(np.mean(x)) index = reduced_results.test.index x = reduced_results.test.output[index == index_0] print('[reduced_results]') print(x) [46] 2020-05-25 08:12:32 ( 8.00ms ) python3 ( 6.27s ) [results] [[4.9476857] [4.5589285] [5.215234 ] [4.521692 ]] 4.810885 [reduced_results] [[4.810885]] For convenience, Client.load_results() has reduction keyword argument. results = client.load_results(run_ids, reduction='mean', verbose=False) results [47] 2020-05-25 08:12:32 ( 85.0ms ) python3 ( 6.35s ) Results('val', 'test') for mode in ['val', 'test']: print(mode, results[mode].output.shape) [48] 2020-05-25 08:12:32 ( 7.00ms ) python3 ( 6.36s ) val (800, 1) test (200, 1) A cross validation (CV) score can be calculated as follows: pred = results.val.output true = results.val.target np.mean(np.sqrt((pred - true) ** 2)) # Use any function for your metric. [49] 2020-05-25 08:12:32 ( 4.00ms ) python3 ( 6.36s ) 1.7839103 And we got a prediction for the test data using 4 MLP models. results.test.output[:5] [50] 2020-05-25 08:12:32 ( 4.00ms ) python3 ( 6.37s ) array([[ 4.810885 ], [ 9.129815 ], [ 7.5381155], [10.070408 ], [14.605849 ]], dtype=float32) Summary In this quickstart, we can play with a toy problem that predicts rectangle areas. Through this quickstart, we now understand how to use Ivory roughly.","title":"Quickstart"},{"location":"#quickstart","text":"Ivory is a lightweight framework for machine learning. It integrates model design, tracking, and hyperparmeter tuning. Ivory uses MLflow Tracking for tracking and Optuna for hyperparmeter tuning. Using Ivory, you can tackle both tracking and tuning workflow at one place. Another key feature of Ivory is its model design. You can write down all of your model structure and tracking/tuning process in one YAML file. It allows us to understand the whole process at a glance.","title":"Quickstart"},{"location":"#installation","text":"You can install Ivory by a pip command. $ pip install ivory","title":"Installation"},{"location":"#using-a-ivory-client","text":"Ivory has the Client class that manages the workflow of any machine learning. Let's create your first Client instance. In this quickstart, we are working with examples under the examples directory. import ivory client = ivory.create_client(\"examples\") client [2] 2020-05-25 08:12:26 ( 1.02s ) python3 ( 1.06s ) Client(num_objects=2) The representation of the client shows that it has two objects. Objects that a client has can be accessed by index notation or dot notation . client[0] # or client['tracker'], or client.tracker [3] 2020-05-25 08:12:27 ( 4.00ms ) python3 ( 1.06s ) Tracker(tracking_uri='file:///C:/Users/daizu/Documents/github/ivory/docs/examples/mlruns', artifact_location=None) The first object is a Tracker instance which connects Ivory to MLFlow Tracking . Because a Client instance is an iterable, you can get all of the objects by applying list() to it. list(client) [4] 2020-05-25 08:12:27 ( 5.00ms ) python3 ( 1.06s ) ['tracker', 'tuner'] The second objects is named tuner . client.tuner [5] 2020-05-25 08:12:27 ( 3.00ms ) python3 ( 1.07s ) Tuner(storage='sqlite://', sampler=None, pruner=None, load_if_exists=True) A Tuner instance connects Ivory to Optuna: A hyperparameter optimization framework . We can customize these objects with a YAML file named client.yml under the woking directory. In our case, the file just contains the minimum settings. File 1 client.yml client: tracker: tuner: Note A YAML file for client is not required. If there is no file for client, Ivory creates a default client with a tracker and without a tuner. If you don't need a tracker, use ivory.create_client(tracker=False) .","title":"Using a Ivory Client"},{"location":"#create-numpy-data","text":"In this quickstart, we try to predict rectangles area from thier width and height using PyTorch . First, prepare the data as NumPy arrays. In example.py under the working directory, a create_data() function is defined. The ivory.create_client() function automatically inserts the working directory to sys.path , so that we can import the module regardless of the current directory. import example [6] 2020-05-25 08:12:27 ( 266ms ) python3 ( 1.33s ) Let's check the create_data() function definition and an example output: Code 1 example.create_data def create_data(num_samples=1000): xy = 4 * np.random.rand(num_samples, 2) + 1 xy = xy.astype(np.float32) dx = 0.1 * (np.random.rand(num_samples) - 0.5) dy = 0.1 * (np.random.rand(num_samples) - 0.5) z = ((xy[:, 0] + dx) * (xy[:, 1] + dy)).astype(np.float32) return xy, z xy, z = example.create_data(4) xy [8] 2020-05-25 08:12:27 ( 5.00ms ) python3 ( 1.36s ) array([[4.628753 , 2.6472826], [3.3307068, 4.298735 ], [3.14777 , 1.0443248], [3.1629949, 2.1611164]], dtype=float32) z [9] 2020-05-25 08:12:27 ( 3.00ms ) python3 ( 1.36s ) array([12.045295 , 14.46252 , 3.2317824, 7.073397 ], dtype=float32)","title":"Create NumPy data"},{"location":"#set-of-data-classes","text":"Ivory defines a set of Data classes ( Data , Dataset , Datasets , DataLoaders ). But now, we use the Data class only. Code 2 example.Data @dataclass class Data(ivory.core.data.Data): n_splits: int = 5 DATA = create_data(1000) def init(self): self.input, self.target = self.DATA self.index = np.arange(len(self.input)) self.fold = kfold_split(self.input, n_splits=self.n_splits) # Creating test set just for demonstration. is_test = self.fold == self.n_splits - 1 self.fold = np.where(is_test, -1, self.fold) self.target = np.where(is_test, np.nan, self.target) self.target = self.target.reshape(-1, 1) # (sample, channel) Here, kfold_split function creates a fold-array. import numpy as np from ivory.utils.fold import kfold_split kfold_split(np.arange(10), n_splits=3) [11] 2020-05-25 08:12:27 ( 5.00ms ) python3 ( 1.38s ) array([2, 1, 0, 2, 0, 2, 1, 1, 0, 0], dtype=int8) In Ivory, fold number = -1 means their samples are test data. Now, we can get a Data instance. data = example.Data() data [12] 2020-05-25 08:12:27 ( 4.00ms ) python3 ( 1.38s ) Data(n_splits=5) data.get(0) # get data of index = 0. [13] 2020-05-25 08:12:27 ( 4.00ms ) python3 ( 1.39s ) [0, array([3.5546277, 4.5952773], dtype=float32), array([16.358192], dtype=float32)] This returned value is a list of [index, input, target]. Ivory always keeps data index so that we can know where a sample comes from.","title":"Set of Data classes"},{"location":"#define-a-model","text":"We use a simple MLP model here. Code 3 example.Model class Model(nn.Module): def __init__(self, hidden_sizes): super().__init__() layers = [] for in_features, out_features in zip([2] + hidden_sizes, hidden_sizes + [1]): layers.append(nn.Linear(in_features, out_features)) self.layers = nn.ModuleList(layers) def forward(self, x): for layer in self.layers[:-1]: x = F.relu(layer(x)) return self.layers[-1](x)","title":"Define a model"},{"location":"#parameter-file-for-run","text":"Ivory configures a run using a YAML file. Here is a full example. File 2 torch.yaml library: torch dataloaders: data: class: example.Data n_splits: 5 dataset: batch_size: 10 fold: 0 model: class: example.Model hidden_sizes: [100, 100] optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 1e-3 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: metrics: criterion: def: torch.nn.functional.mse_loss monitor: metric: val_loss early_stopping: patience: 10 trainer: epochs: 10 verbose: 2 Let's create a run by Client.create_run() run = client.create_run('torch') run [15] 2020-05-25 08:12:27 ( 274ms ) python3 ( 1.68s ) [I 200525 08:12:27 tracker:48] A new experiment created with name: torch Run(id='598eaf8e0120434db9f059a562416e18', name='run#0', num_objects=12) Note Client.create_run(<name>) creates an experiment named <name> if it hasn't existed yet. By cliking an icon ( ) in the above cell, you can see the log. Or you can directly create an experiment then make the experiment create a run: experiment = client . create_experiment ( 'torch' ) run = experiment . create_run () A Run instance have a params attribute that holds the parameters for the run. import yaml print(yaml.dump(run.params, sort_keys=False)) [16] 2020-05-25 08:12:28 ( 6.00ms ) python3 ( 1.68s ) run: dataloaders: data: class: example.Data n_splits: 5 dataset: def: ivory.torch.data.Dataset batch_size: 10 fold: 0 class: ivory.torch.data.DataLoaders model: class: example.Model hidden_sizes: - 100 - 100 optimizer: class: torch.optim.SGD params: $.model.parameters() lr: 0.001 scheduler: class: torch.optim.lr_scheduler.ReduceLROnPlateau optimizer: $ factor: 0.5 patience: 4 results: class: ivory.torch.results.Results metrics: criterion: def: torch.nn.functional.mse_loss class: ivory.torch.metrics.Metrics monitor: metric: val_loss class: ivory.callbacks.monitor.Monitor early_stopping: patience: 10 class: ivory.callbacks.early_stopping.EarlyStopping trainer: epochs: 10 verbose: 2 class: ivory.torch.trainer.Trainer class: ivory.torch.run.Run name: run#0 id: 598eaf8e0120434db9f059a562416e18 experiment: name: torch class: ivory.core.base.Experiment id: '1' This is similar to the YAML file we read before, but is slightly changed by the Ivory Client. Run and experiment sections are inserted. ExperimentID and RunID are assigned by the MLFlow Tracking. Default classes are specified, for example ivory.torch.trainer.Trainer for a trainer instance. The Client.create_run() method takes keyword arguments to modify these parameters: run = client.create_run( 'torch', batch_size=20, hidden_sizes=[40, 50, 60], ) print('[dataloaders]') print(yaml.dump(run.params['run']['dataloaders'], sort_keys=False)) print('[model]') print(yaml.dump(run.params['run']['model'], sort_keys=False)) [17] 2020-05-25 08:12:28 ( 48.0ms ) python3 ( 1.73s ) [dataloaders] data: class: example.Data n_splits: 5 dataset: def: ivory.torch.data.Dataset batch_size: 20 fold: 0 class: ivory.torch.data.DataLoaders [model] class: example.Model hidden_sizes: - 40 - 50 - 60","title":"Parameter file for Run"},{"location":"#train-a-model","text":"Once you got a run instance, then all you need is to start it. run = client.create_run('torch') # Back to the default settings. run.start() [18] 2020-05-25 08:12:28 ( 1.37s ) python3 ( 3.10s ) [epoch#0] loss=12.24 val_loss=8.498 lr=0.001 best [epoch#1] loss=6.555 val_loss=6.277 lr=0.001 best [epoch#2] loss=5.001 val_loss=5.858 lr=0.001 best [epoch#3] loss=3.458 val_loss=2.508 lr=0.001 best [epoch#4] loss=2.213 val_loss=1.501 lr=0.001 best [epoch#5] loss=1.32 val_loss=1.36 lr=0.001 best [epoch#6] loss=1.098 val_loss=1.096 lr=0.001 best [epoch#7] loss=0.8826 val_loss=0.6978 lr=0.001 best [epoch#8] loss=0.9326 val_loss=0.5321 lr=0.001 best [epoch#9] loss=0.7491 val_loss=1.128 lr=0.001 The history of metrics is saved as the history attribute of a run.metrics instance. run.metrics.history [19] 2020-05-25 08:12:29 ( 5.00ms ) python3 ( 3.10s ) {'loss': {0: 12.241463792324065, 1: 6.554965313275655, 2: 5.000564849376678, 3: 3.4583153078953424, 4: 2.213449684282144, 5: 1.3196005828678607, 6: 1.097760977099339, 7: 0.8826028736929099, 8: 0.9326490251968305, 9: 0.749077113221089}, 'val_loss': {0: 8.498352408409119, 1: 6.277046465873719, 2: 5.857835829257965, 3: 2.507568579912186, 4: 1.5011233597993852, 5: 1.3604056045413018, 6: 1.0963490769267081, 7: 0.6978286743164063, 8: 0.5320957466959954, 9: 1.1281802162528038}, 'lr': {0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001}} Also the model output and target are automatically collected in a run.results instance. run.results [20] 2020-05-25 08:12:29 ( 4.00ms ) python3 ( 3.11s ) Results('train', 'val') run.results.val.output[:5] [21] 2020-05-25 08:12:29 ( 4.00ms ) python3 ( 3.11s ) array([[15.22483 ], [ 3.2956257], [13.455274 ], [ 8.64801 ], [ 7.5879283]], dtype=float32) run.results.val.target[:5] [22] 2020-05-25 08:12:29 ( 4.00ms ) python3 ( 3.11s ) array([[14.6351795], [ 3.065638 ], [12.72186 ], [ 7.4222608], [ 6.1824374]], dtype=float32)","title":"Train a model"},{"location":"#test-a-model","text":"Testing a model is as simple as training. Just call run.start() with a test argument in stead of (default) train . run.start('test') run.results [23] 2020-05-25 08:12:29 ( 44.0ms ) python3 ( 3.16s ) Results('train', 'val', 'test') As you can see, test results were added. run.results.test.output[:5] [24] 2020-05-25 08:12:29 ( 5.00ms ) python3 ( 3.16s ) array([[ 2.7136889], [ 8.259468 ], [ 6.3204045], [ 9.698607 ], [17.519829 ]], dtype=float32) Off course the target values for the test data are np.nan . run.results.test.target[:5] [25] 2020-05-25 08:12:29 ( 4.00ms ) python3 ( 3.17s ) array([[nan], [nan], [nan], [nan], [nan]], dtype=float32)","title":"Test a model"},{"location":"#task-for-multiple-runs","text":"Ivory implements a special run type called Task which controls multiple nested runs. A task is useful for parameter search or cross validation. task = client.create_task('torch') task [26] 2020-05-25 08:12:29 ( 53.0ms ) python3 ( 3.22s ) Task(id='7adfc6844a5a45ffb155fc2d1c5ddaf1', name='task#0', num_objects=3) The Task class has two methods to generate multiple runs: prodcut() and chain() . These two methods have the same functionality as itertools of Python starndard library. Let's try to perform cross validation. runs = task.product(fold=range(4), verbose=0, epochs=3) runs [27] 2020-05-25 08:12:29 ( 3.00ms ) python3 ( 3.22s ) <generator object Task.product at 0x0000017FB3D26448> Like itertools 's functions, Task.prodcut() and Task.chain() return a generator, which yields runs that are configured by different parameters you specified. In this case, this generator will yield 4 runs with a fold number ranging from 0 to 4 for each. A task instance doesn't start any training by itself. Note You can pass fixed parameters to update the original parameters in the YAML file. Then start 4 runs by a for loop including run.train() . Here a both argument means execution of test after training. for run in runs: run.start('both') [28] 2020-05-25 08:12:29 ( 2.34s ) python3 ( 5.57s ) [run#3] epochs=3 fold=0 [epoch#0] loss=14.95 val_loss=7.605 lr=0.001 best [epoch#1] loss=6.317 val_loss=5.682 lr=0.001 best [epoch#2] loss=4.543 val_loss=3.998 lr=0.001 best [run#4] epochs=3 fold=1 [epoch#0] loss=13.36 val_loss=7.826 lr=0.001 best [epoch#1] loss=7.27 val_loss=6.455 lr=0.001 best [epoch#2] loss=5.719 val_loss=4.938 lr=0.001 best [run#5] epochs=3 fold=2 [epoch#0] loss=13.58 val_loss=6.452 lr=0.001 best [epoch#1] loss=6.487 val_loss=4.378 lr=0.001 best [epoch#2] loss=4.559 val_loss=3.107 lr=0.001 best [run#6] epochs=3 fold=3 [epoch#0] loss=12.63 val_loss=7.419 lr=0.001 best [epoch#1] loss=6.476 val_loss=5.834 lr=0.001 best [epoch#2] loss=4.909 val_loss=4.506 lr=0.001 best","title":"Task for multiple runs"},{"location":"#collect-runs","text":"Our client has a Tracker instance. It stores the state of runs in background using the MLFlow Tracking. The Client class provides several methods to access the stored runs. For example, Client.search_run_ids() returns a generator which yields RunID created by the MLFlow Tracking. # A helper function def print_run_info(run_ids): for run_id in run_ids: print(run_id[:5], client.get_run_name(run_id)) [29] 2020-05-25 08:12:31 ( 5.00ms ) python3 ( 5.57s ) run_ids = client.search_run_ids('torch') print_run_info(run_ids) [30] 2020-05-25 08:12:31 ( 69.0ms ) python3 ( 5.64s ) 7b06b run#6 3e893 run#5 37a01 run#4 708f1 run#3 7adfc task#0 94e71 run#2 40bcf run#1 598ea run#0 For filtering, add key-value pairs. # If `exclude_parent` is True, parent runs are excluded. run_ids = client.search_run_ids('torch', fold=0, exclude_parent=True) print_run_info(run_ids) [31] 2020-05-25 08:12:32 ( 167ms ) python3 ( 5.81s ) 708f1 run#3 94e71 run#2 40bcf run#1 598ea run#0 # If `parent_run_id` is specified, nested runs having the parent are returned. run_ids = client.search_run_ids('torch', parent_run_id=task.id) print_run_info(run_ids) [32] 2020-05-25 08:12:32 ( 46.0ms ) python3 ( 5.85s ) 7b06b run#6 3e893 run#5 37a01 run#4 708f1 run#3 Client.get_run_id() and Client.get_run_ids() fetch RunID from run name, more strictly, (run class name in lower case) plus (run number). run_ids = [client.get_run_id('torch', run=0), client.get_run_id('torch', task=0)] print_run_info(run_ids) [33] 2020-05-25 08:12:32 ( 54.0ms ) python3 ( 5.91s ) 598ea run#0 7adfc task#0 run_ids = client.get_run_ids('torch', run=range(2, 4)) print_run_info(run_ids) [34] 2020-05-25 08:12:32 ( 56.0ms ) python3 ( 5.96s ) 94e71 run#2 708f1 run#3","title":"Collect runs"},{"location":"#load-runs-and-results","text":"The Ivory Client class can load runs. First select RunID(s) to load. We want to perform cross validation here, so that we need a run collection created by a task. In this case, we can use Client.get_nested_run_ids() . Why don't we use Client.search_run_ids() as we did above? Because we don't have an easy way to get a very long RunID after we restart a Python session. On the ohter hand, a run name is easy to manage and write. run_ids = list(client.get_nested_run_ids('torch', task=0)) print_run_info(run_ids) [35] 2020-05-25 08:12:32 ( 66.0ms ) python3 ( 6.03s ) 7b06b run#6 3e893 run#5 37a01 run#4 708f1 run#3 Let's load the latest run. run = client.load_run(run_ids[0]) run [36] 2020-05-25 08:12:32 ( 65.0ms ) python3 ( 6.09s ) Run(id='7b06b11d5908411e963023160a912e21', name='run#6', num_objects=11) Note Client.load_run() doesn't require an experiment name, because RunID is unique among the MLFlow Tracking. As you expected, the fold number is 3. run.dataloaders.fold [37] 2020-05-25 08:12:32 ( 3.00ms ) python3 ( 6.10s ) 3 We obtained the trained model. run.model.eval() [38] 2020-05-25 08:12:32 ( 4.00ms ) python3 ( 6.10s ) Model( (layers): ModuleList( (0): Linear(in_features=2, out_features=100, bias=True) (1): Linear(in_features=100, out_features=100, bias=True) (2): Linear(in_features=100, out_features=1, bias=True) ) ) import torch index, input, target = next(iter(run.dataloaders.val)) with torch.no_grad(): output = run.model(input) print('[output]') print(output) print('[target]') print(target) [39] 2020-05-25 08:12:32 ( 10.0ms ) python3 ( 6.11s ) [output] tensor([[12.3252], [ 6.5610], [ 8.2248], [ 4.9248], [10.9631], [ 9.7004], [ 7.6684], [ 5.5870], [ 9.4059], [17.1684]]) [target] tensor([[11.8446], [ 4.0026], [ 6.1003], [ 2.5613], [10.0389], [ 7.9452], [ 4.5900], [ 3.1889], [ 7.4198], [20.9542]]) If you don't need a whole run instance, Client.load_instance() is a better choice to save time and memory. results = client.load_instance(run_ids[0], 'results') results [40] 2020-05-25 08:12:32 ( 24.0ms ) python3 ( 6.14s ) Results('train', 'val', 'test') for mode in ['train', 'val', 'test']: print(mode, results[mode].output.shape) [41] 2020-05-25 08:12:32 ( 8.00ms ) python3 ( 6.14s ) train (600, 1) val (200, 1) test (200, 1) For cross validation, we need 4 runs. (Note that n_splits was 5 but we used the last fold for dummy test data.) To load multiple run's results, the Ivory Client provides a convenient method. results = client.load_results(run_ids, verbose=False) results [42] 2020-05-25 08:12:32 ( 90.0ms ) python3 ( 6.23s ) Results('val', 'test') for mode in ['val', 'test']: print(mode, results[mode].output.shape) [43] 2020-05-25 08:12:32 ( 7.00ms ) python3 ( 6.24s ) val (800, 1) test (800, 1) Note Client.load_results() drops train data for saving memory. The lengths of validation data and test data are both 800 (200 times 4). But be careful about the test data. The length of unique samples is 200 (one fold size). import numpy as np len(np.unique(results.val.index)), len(np.unique(results.test.index)) [44] 2020-05-25 08:12:32 ( 4.00ms ) python3 ( 6.24s ) (800, 200) Usually, duplicated samples are averaged for ensembling. Results.mean() method performs this mean reduction and returns a newly created Rusults instance. reduced_results = results.mean() for mode in ['val', 'test']: print(mode, reduced_results[mode].output.shape) [45] 2020-05-25 08:12:32 ( 13.0ms ) python3 ( 6.26s ) val (800, 1) test (200, 1) Compare the results. index = results.test.index index_0 = index[0] x = results.test.output[index == index_0] print('[results]') print(x) print(np.mean(x)) index = reduced_results.test.index x = reduced_results.test.output[index == index_0] print('[reduced_results]') print(x) [46] 2020-05-25 08:12:32 ( 8.00ms ) python3 ( 6.27s ) [results] [[4.9476857] [4.5589285] [5.215234 ] [4.521692 ]] 4.810885 [reduced_results] [[4.810885]] For convenience, Client.load_results() has reduction keyword argument. results = client.load_results(run_ids, reduction='mean', verbose=False) results [47] 2020-05-25 08:12:32 ( 85.0ms ) python3 ( 6.35s ) Results('val', 'test') for mode in ['val', 'test']: print(mode, results[mode].output.shape) [48] 2020-05-25 08:12:32 ( 7.00ms ) python3 ( 6.36s ) val (800, 1) test (200, 1) A cross validation (CV) score can be calculated as follows: pred = results.val.output true = results.val.target np.mean(np.sqrt((pred - true) ** 2)) # Use any function for your metric. [49] 2020-05-25 08:12:32 ( 4.00ms ) python3 ( 6.36s ) 1.7839103 And we got a prediction for the test data using 4 MLP models. results.test.output[:5] [50] 2020-05-25 08:12:32 ( 4.00ms ) python3 ( 6.37s ) array([[ 4.810885 ], [ 9.129815 ], [ 7.5381155], [10.070408 ], [14.605849 ]], dtype=float32)","title":"Load runs and results"},{"location":"#summary","text":"In this quickstart, we can play with a toy problem that predicts rectangle areas. Through this quickstart, we now understand how to use Ivory roughly.","title":"Summary"},{"location":"quickstart/","text":"Skipped.","title":"Quickstart"},{"location":"api/data/","text":"Skipped.","title":"Data"},{"location":"examples/example/","text":"Skipped.","title":"Example"},{"location":"tutorial/client_experiment_run/","text":"Skipped.","title":"Client experiment run"},{"location":"tutorial/overview/","text":"Skipped.","title":"Overview"},{"location":"tutorial_old/data/","text":"Skipped.","title":"Data"},{"location":"tutorial_old/metrics/","text":"Skipped.","title":"Metrics"},{"location":"tutorial_old/model/","text":"Skipped.","title":"Model"}]}